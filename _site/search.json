[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "We are responsible for:\n\nData analysis & reporting on key projects\nR package development & maintenance\nOutreach & engagement with the research community\n\n\n\nMeet the team\nClick on photos to view their articles and contributions\n\n\n\n\n\n\n\n\n\n\nMartin Westgate\n\nTeam Leader\n\n\n\n\n\n\n\n\n\n\nShandiya Balasubramaniam\n\nData Analyst\n\n\n\n\n\n\n\n\n\n\nAmanda Buyan\n\nData Analyst\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDax Kellie\n\nData Analyst\n\n\n\n\n\n\n\n\n\n\nOlivia Torresan\n\nSupport Officer\n\n\n\n\n\n\n\n\n\n\nFonti Kar\n\nData Analyst\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMargot Schneider\n\nProject Manager\n\n\n\n\n\n\n\n\n\n\nJuliet Seers\n\nTraining & Outreach Coordinator"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to ALA Labs",
    "section": "",
    "text": "Welcome to ALA Labs\nThis site is a resource for coding projects that use data sourced from the ALA. We hope that users will find interesting content, whether their focus is ecological modelling, data visualisation, or simply investigating the natural world through a digital lens. Enjoy!\n\n\n\n\n\n\n\n\n\n\n\nPosts\n\nHow-to articles for solving scientific problems\n\n\n\n\n\n\n\n\n\nSummaries\n\n\n\n\n\n\n\nMaps\n\n\n\n\n\n\n\nTrees\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nResearch\n\nHighlighting research supported by ALA data\n\n\n\n\n\n\n\n\n\n\nSelected\nhighlights\n\n\n\n\n\n\n\nComplete list\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSoftware\n\nTools supported by the Science & Decision Support Team\n\n\n\n\n\n\n\n\n\nPackages\n\n\n\n\n\n\n\n\n\n\n\n\n We value\n\n\n\n\n\n\n\n\n\n\n\n    Openness\n\nData are most useful when they are widely available and easy to use. We try to encourage the sharing of tools that make data from the Atlas of Living Australia more open and useful for everyone\n\n\n\n\n\n\n    Scientific transparency\n\nTransparency is necessary for reproducible science. We encourage that decisions, methods and deviations are clear and transparent in a workflow from the planning phase, to the retrieval and analysis of data, to the final output\n\n\n\n\n\n\n    Robust methods\n\nNo method or analytic procedure is perfect. We value consideration for strengths and limitations of each method or analysis to help choose the method that provides robust, reliable results"
  },
  {
    "objectID": "people/Balasubramaniam_Shandiya/index.html",
    "href": "people/Balasubramaniam_Shandiya/index.html",
    "title": "Shandiya Balasubramaniam",
    "section": "",
    "text": "Bio\n\n\n\n\n\n\n\n\n\nShandiya is an evolutionary ecologist with interests in conservation genetics and wildlife disease. Her work as a data analyst at the ALA focuses on streamlining reproducible pathways for researchers to access and analyse open data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Posts\nMultiple colour scales in choropleth maps with {ggnewscale} Using multiple colour scales can be a great way to visually differentiate between geographic categories on a map. Here, we demonstrate this by creating a choropleth map to represent the density of plant records from the ALA across bioregions in Australia, and add multiple colour scales to differentiate marine and terrestrial records"
  },
  {
    "objectID": "people/Buyan_Amanda/index.html",
    "href": "people/Buyan_Amanda/index.html",
    "title": "Amanda Buyan",
    "section": "",
    "text": "Bio\n\n\n\n\n\n\n\n\n\nAmanda is a data analyst for EcoCommons, and is based at the Atlas of Living Australia. She completed her PhD in Structural Biology, and uses her extensive Python skills to manage the integration of data within EcoCommons. She also works to optimize the available scientific workflows within the platform.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Posts\nPlotting invasive species distributions with alpha shapes and choropleth maps in Python Invasive and introduced species can expand quickly into new habitats, altering ecosystems. In this post we use Python’s {galah}, {alphashape} and {GeoPandas} packages to visualise the growing distribution of Rhinella marina (cane toads) and the expanding range of Pittisporum undulatum in Australia."
  },
  {
    "objectID": "people/Kar_Fonti/index.html",
    "href": "people/Kar_Fonti/index.html",
    "title": "Fonti Kar",
    "section": "",
    "text": "Bio\n\n\n\n\n\n\n\n\n\nFonti is an evolutionary biologist wearing R developer shoes. Her interests include biostatistics, reproducible science, learning about the latest coding practices and teaching others to enjoy using R. Her work at ALA as a Data Analyst involves streamlining data cleaning workflows.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Posts\nQuantifying species range and overlap with fire-burned areas using concave hulls Calculating range overlap is an efficient way to estimate the impact of natural disasters on biodiversity. Here we’ll use curated datasets to compute concave hulls to visualise the spatial distribution of Apidae (Bees) and Daviesia (Bitterpeas) and their overlap with burned areas of the Black Summer fires of 2019-2020.\nConvex and alpha hulls for conservation mapping Convex hulls and alpha hulls are wonderful alternatives for visualising species distributions when a species has very few existing observations. Here, we will show you how to create these spatial polygons using data from the ALA."
  },
  {
    "objectID": "people/Kellie_Dax/index.html",
    "href": "people/Kellie_Dax/index.html",
    "title": "Dax Kellie",
    "section": "",
    "text": "Bio\n\n\n\n\n\n\n\n\n\nDax is an evolutionary biologist, with a PhD in biological sciences and social psychology. As a data analyst at the ALA, he tries to make data in the ALA accessible for scientists and citizen scientists to use in ways that are scientifically robust and transparent.  Dax is the primary editor of ALA Labs.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Posts\nPlotting invasive species distributions with alpha shapes and choropleth maps in Python Invasive and introduced species can expand quickly into new habitats, altering ecosystems. In this post we use Python’s {galah}, {alphashape} and {GeoPandas} packages to visualise the growing distribution of Rhinella marina (cane toads) and the expanding range of Pittisporum undulatum in Australia.\nMake a highlighted time-series plot Time-series analyses can be handy for seeing trends over time, and exploring how trends relate to major events. Here, we show how to create an exploratory time-series plot comparing observations of waterbirds prior to and during the COVID-19 pandemic.\nAnimated species distribution maps with {gifski} One useful way to see changes in a species’ habitat range over time is by using animation to view multiple distributions in succession. Here we will model the distribution of Nudibranchia across Australia each month to create an animated GIF of its distribution over a year.\nCounting points in multipolygon shapefiles for choropleth mapping Choropleth maps are an excellent way to visualise numbers of observations in each region. When using point data, calculating the number of points in each polygon can be difficult when using shapefiles. Here we demonstrate how to extract and summarise the number of points in each polygon within a shapefile to create a choropleth map.\nQuantify geographic sampling bias with {sampbias} Human biases play a large role in the data we collect about species. Here we show a simple method to quantify the bias of roads, cities, rivers and airports on species observations of legless lizards in the Northern Territory\nDownload plant species data by hexagon to make a 3D hex map Making plots eye-catching can be useful for science communication. Here, we show how to make 3D plots in R with the rayshader package by visualising the number of species identified from ALA observations since 2020"
  },
  {
    "objectID": "people/Schneider_Margot/index.html",
    "href": "people/Schneider_Margot/index.html",
    "title": "Margot Schneider",
    "section": "",
    "text": "Bio\n\n\n\n\n\n\n\n\n\nMargot is a graduate of the Australian National University (ANU) with a Bachelor of Science (Honours) on bushfire chemical ecology. She works to improve data quality in the ALA. Margot is a strong advocate for diversity and inclusion in the STEMM fields.\n\n\n\n\n\n\n\n\n\n\n\n Posts\nQuantifying species range and overlap with fire-burned areas using concave hulls Calculating range overlap is an efficient way to estimate the impact of natural disasters on biodiversity. Here we’ll use curated datasets to compute concave hulls to visualise the spatial distribution of Apidae (Bees) and Daviesia (Bitterpeas) and their overlap with burned areas of the Black Summer fires of 2019-2020.\nConvex and alpha hulls for conservation mapping Convex hulls and alpha hulls are wonderful alternatives for visualising species distributions when a species has very few existing observations. Here, we will show you how to create these spatial polygons using data from the ALA."
  },
  {
    "objectID": "people/Seers_Juliet/index.html",
    "href": "people/Seers_Juliet/index.html",
    "title": "Juliet Seers",
    "section": "",
    "text": "Bio\n\n\n\n\n\n\n\n\n\nJuliet specialises in education and engagement in the environmental sector. Her work as the Training & Outreach Coordinator at the ALA involves identifying and addressing knowledge gaps users have with ALA’s use and functionality, and helping to elevate ALA’s profile with our stakeholders.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Posts"
  },
  {
    "objectID": "people/Torresan_Olivia/index.html",
    "href": "people/Torresan_Olivia/index.html",
    "title": "Olivia Torresan",
    "section": "",
    "text": "Bio\n\n\n\n\n\n\n\n\n\nOlivia is a graduate from the Australian National University (ANU), acquiring an interdisciplinary double degree in philosophy and natural resource management. At the ALA, she works as a support officer with a primary focus on monitoring the research impact of the Atlas. She is passionate about accessibility, environmental justice and diversity in STEMM.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Posts\nCounting points in multipolygon shapefiles for choropleth mapping Choropleth maps are an excellent way to visualise numbers of observations in each region. When using point data, calculating the number of points in each polygon can be difficult when using shapefiles. Here we demonstrate how to extract and summarise the number of points in each polygon within a shapefile to create a choropleth map."
  },
  {
    "objectID": "people/Westgate_Martin/index.html",
    "href": "people/Westgate_Martin/index.html",
    "title": "Martin Westgate",
    "section": "",
    "text": "Bio\n\n\n\n\n\n\n\n\n\nMartin leads the Science & Decision Support Team. He holds a doctorate in landscape ecology and conservation biology from the Australian National University. His work focuses on conceptual, computational and statistical tools to better understand patterns in nature.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Posts\nHex maps for species occurrence data Hex maps are a neat way to represent spatial information. Here, we show how to draw one using the most common species in the ALA database: the iconic Australian Magpie.\nSunburst plots for taxonomic data Since version 1.3.1 of galah, it has been possible to download taxonomic data using a ‘tree’ format from the data.tree package. Here I’ll demonstrate some ideas for plotting these trees using circular diagrams.\nCreating a color palette from an image There are hundreds of color palettes in the R ecosystem, but sometimes we might want to use colors from a specific image. Here I show how to use the paletter package to create a color palette for the 2020 Eucalypt of the Year: the Western Australian Gimlet."
  },
  {
    "objectID": "posts/2021-03-20_creating-a-color-palette-from-an-image/post.html",
    "href": "posts/2021-03-20_creating-a-color-palette-from-an-image/post.html",
    "title": "Creating a color palette from an image",
    "section": "",
    "text": "Author\nMartin Westgate\n\n\nDate\nMarch 2021\n\n\n\n\n\n\n\n\n\n\n\nColors in R\nColor palettes are important to people, and the R ecosystem includes literally hundreds of possible palettes. If you want a “complete” list, go and check out Emil Hvitfeldt’s list of palettes here; but in practice there are only a few that we use routinely. Our default at ALA labs is to use viridis for continuous scales, because (to quote their CRAN page) it’s color-blind friendly, perceptually uniform, and pretty. The default purple-green-yellow color scheme is lovely, but I’m a big fan of ‘magma’, which has a black-purple-orange-yellow scheme\n\nlibrary(galah)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(viridis)\n\n\n# Get field code for states/territories\nsearch_fields(\"state\") # layer: cl22 OR stateProvince\n\n# A tibble: 26 × 4\n   id      description                                               type  link \n   &lt;chr&gt;   &lt;chr&gt;                                                     &lt;chr&gt; &lt;chr&gt;\n 1 cl3     \"Western Australian Biodiversity Science Research Priori… laye… http…\n 2 cl938   \"Fruit Fly Exclusion Zone - Tri State Fruit Fly Exclusio… laye… http…\n 3 cl927   \"States including coastal waters States (including coast… laye… http…\n 4 cl22    \"Australian States and Territories Australian States and… laye… http…\n 5 cl2013  \"ASGS Australian States and Territories Australian Stati… laye… http…\n 6 cl2009  \"National Native Title Register (NNTR, Determinations of… laye… http…\n 7 cl10900 \"Australia's Indigenous forest estate (2013) v2.0 Austra… laye… http…\n 8 cl10902 \"Forests of Australia (2013) v2.0 Forests of Australia (… laye… http…\n 9 cl10903 \"Tenure of Australia's forests (2013) v2.0 Tenure of Aus… laye… http…\n10 cl11033 \"CAPAD 2020 Terrestrial The Collaborative Australian Pro… laye… http…\n# … with 16 more rows\n\n# Download record counts by state/territory\nrecords &lt;- galah_call() %&gt;%\n  galah_group_by(cl22) %&gt;%\n  atlas_counts()\n\n# Add state information back to data frame\nrecords$State &lt;- factor(seq_len(nrow(records)), labels = records$cl22) \n\n# Plot\nggplot(records, aes(x = State, y = log10(count), fill = count)) + \n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  scale_fill_viridis(option = \"magma\", begin = 0.10, end = 0.95) +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\n\n\n\nMy default for categorical color schemes is the ‘dark2’ palette from RColorBrewer; but given the subject matter of our work, it’s worth mentioning the wonderful feather package by Shandiya Balasubramaniam, which gives colors based on Australian bird plumage.\n\n# remotes::install_github(repo = \"shandiya/feathers\")\nlibrary(feathers)\n\nrcfd &lt;- galah_call() %&gt;%\n  galah_identify(\"Rose-crowned Fruit-Dove\") %&gt;%\n  galah_group_by(cl22) %&gt;%\n  atlas_counts()\n  \nrcfd$State &lt;- factor(seq_len(nrow(rcfd)), labels = rcfd$cl22) \n\nggplot(rcfd, aes(x = State, y = log10(count), fill = State)) + \n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  scale_fill_manual(values = get_pal(\"rose_crowned_fruit_dove\")) +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\n\n\n\nAll of this is fine, but what if you have a specific image that you want to take colors from? A logical choice is to pick the colors you want using an image editting program, but if we want to try something automated, there are options in R as well.\n\n\nExtracting colors\nNational Eucalypt Day aims to raise awareness about Eucalypts and celebrate their influence on the lives of Australians. In honour of National Eucalypt day, we wanted to created a plot based on occurrences data held in the Atlas of Living Australia, themed using colours from actual Eucalypts.\nWe used this image from a tweet by Dean Nicolle:\n\n\nHappy 'National Eucalypt Day'!The Western Australian gimlet (Eucalyptus salubris) has just been announced as Eucalypt of the Year for 2021. Renowned for its fluted, smooth, shiny, and colourful trunk & branches. pic.twitter.com/pOsufQtxWS— Dean Nicolle (@DeanNicolle1) March 22, 2021\n\n\n\n\n\n\nImage of Eucalyptus salubris by Dean Nicolle\n\n\nFirst, get observations of the Eucalypt of the Year 2021 from ALA using the galah package. Specifically, we use atlas_counts() to determine how many records of Eucalyptus salubris are held by the ALA:\n\nn_records &lt;- galah_call() %&gt;%\n  galah_identify(\"Eucalyptus salubris\") %&gt;%\n  atlas_counts()\n\nHere is what the data look like:\n\nn_records %&gt;% head()\n\n# A tibble: 1 × 1\n  count\n  &lt;int&gt;\n1   853\n\n\nThen get a color scheme from images of the species in question using the paletter package (which needs to be installed from GitHub) \n\n# remotes::install_github(\"AndreaCirilloAC/paletter\")\nlibrary(paletter)\n\nimage_pal &lt;- create_palette(\n  image_path = \"./data/Dean_Nicolle_Esalubris_image_small.jpeg\",\n  type_of_variable = \"categorical\",\n  number_of_colors = 15)\n\n\n\n\n\n\nNote that we downsized the image before running the paletter code, as large images take much longer to process.\n\n\nCreating a plot\nOnce we have this palette, the obvious question is what kind of plot to draw. We could have done a map, but those can be a bit boring. We decided to try something that represented the number of observations we had of this species at ALA, and included color, but was otherwise just a pretty picture that didn’t need to contain any further information. Rather than have a traditional x and y axis, therefore, we decided to try out the igraph package to plot the points in an interesting way.\nFirst, we create a vector containing as many points as we want to display, and distribute our colors among them as evenly as possible\n\n# create a vector to index colours\nrep_times &lt;- floor(n_records / length(image_pal))\n\ncolour_index &lt;- rep(seq_along(image_pal),\n  each = as.integer(rep_times))\n\nThen we can create a network using igraph, and use it to create a layout for our points\n\nlibrary(igraph)\n\ngraph_list &lt;- lapply(c(1:15), function(a){\n  lookup &lt;- which(colour_index == a)\n  return(\n    tibble(\n    from = lookup[c(1:(length(lookup)-1))],\n    to = lookup[c(2:length(lookup))])\n    )\n  })\ngraph_df &lt;- as_tibble(do.call(rbind, graph_list)) %&gt;%     # build matrix\n  tidyr::drop_na() %&gt;%\n  as.matrix(.)\ncolour_graph &lt;- graph_from_edgelist(graph_df)             # create network graph\n\n# convert to a set of point locations\ntest_layout &lt;- as.data.frame(layout_nicely(colour_graph)) # convert to df\ncolnames(test_layout) &lt;- c(\"x\", \"y\")                      # change colnames\ntest_layout$colour_index &lt;- factor(colour_index)          # add colour_index col\n\nFinally, we draw the plot with ggplot2, removing axes with theme_void()\n\nggplot(test_layout, aes(x = x, y = y, colour = colour_index)) +\n  geom_point(size = 3, alpha = 0.9) +\n  scale_color_manual(values = image_pal) +\n  coord_fixed() +\n  theme_void() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nThat’s it! While I like the effect here, I think the paletter package is best suited to cases where there are large areas of strongly contrasting colors; it’s less ideal for images with subtle color differences. It also doesn’t appear to have been updated lately, which may mean it’s not being supported any more. But I’m happy with this plot, and would definitely consider using it again.\n\n\nExpand for session info\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.2 (2022-10-31 ucrt)\n os       Windows 10 x64 (build 19044)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  English_Australia.utf8\n ctype    English_Australia.utf8\n tz       Australia/Sydney\n date     2023-03-29\n pandoc   2.19.2 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version    date (UTC) lib source\n dplyr       * 1.1.0      2023-01-29 [1] CRAN (R 4.2.2)\n feathers    * 0.0.0.9000 2022-10-11 [1] Github (shandiya/feathers@4be766d)\n galah       * 1.5.2      2023-03-20 [1] Github (AtlasOfLivingAustralia/galah@1b35520)\n ggplot2     * 3.4.1      2023-02-10 [1] CRAN (R 4.2.2)\n htmltools   * 0.5.4      2022-12-07 [1] CRAN (R 4.2.2)\n igraph      * 1.3.4      2022-07-19 [1] CRAN (R 4.2.1)\n paletter    * 0.0.0.9000 2023-01-10 [1] Github (AndreaCirilloAC/paletter@c09605b)\n sessioninfo * 1.2.2      2021-12-06 [1] CRAN (R 4.2.1)\n viridis     * 0.6.2      2021-10-13 [1] CRAN (R 4.2.1)\n viridisLite * 0.4.1      2022-08-22 [1] CRAN (R 4.2.1)\n\n [1] C:/Users/KEL329/R-packages\n [2] C:/Users/KEL329/AppData/Local/Programs/R/R-4.2.2/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2021-04-14_hex-maps-for-species-occurrence-data/post.html",
    "href": "posts/2021-04-14_hex-maps-for-species-occurrence-data/post.html",
    "title": "Hex maps for species occurrence data",
    "section": "",
    "text": "Author\nMatilda Stevenson\nDax Kellie\nMartin Westgate\n\n\nDate\nMarch 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nArticle updated 6 February, 2023. Updates streamline code, and provide more examples of output after each step. More in-text detail has also been added about what is happening at each step.\n\n\nThe Atlas of Living Australia (ALA) holds records of magpie sightings from a number data providers like iNaturalist, eBird and BirdLife Australia. Let’s make a visualisation of Australian Bird of the Year 2018 winner, Magpies, using records held in the ALA.\n\nGetting species occurrences\nAs with any R project, a good first step is to load the required packages\n\n# packages\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(ozmaps)\nlibrary(sf)\nlibrary(hexbin)\n\nWe will use the {galah} package to download records.\nTo download species occurrence records, the {galah} package requires you to add an email registered with the ALA to galah_config(). If running this code yourself, you will need to add an email using the code below, substituting your email with myemail@email.com. This email address should be registered with the ALA, which you can do here\n\nlibrary(galah)\ngalah_config(email = \"myemail@email.com\")\n\nNow we can download magpie occurrence records by using atlas_occurrences(). Note that we also set our data ‘profile’ to ‘ALA’; this means we only download records that meet some basic data quality standards enforced by the atlas. This is optional, but tends to improve the quality of the data returned. (If you wish to see the data quality filters applied in the ALA profile, use search_all(profiles, \"ALA\") |&gt; show_values())\n\nmagpie_occ &lt;- galah_call() %&gt;%\n  galah_identify(\"Cracticus tibicen\") %&gt;%\n  galah_apply_profile(ALA) %&gt;%\n  atlas_occurrences()\n\nLet’s have a look at the first few rows of the data we’ve just downloaded:\n\nmagpie_occ %&gt;% head()\n\n# A tibble: 6 × 8\n  decimalL…¹ decim…² eventDate           scien…³ taxon…⁴ recor…⁵ dataR…⁶ occur…⁷\n       &lt;dbl&gt;   &lt;dbl&gt; &lt;dttm&gt;              &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  \n1      -45.0    169. 2019-09-04 14:00:00 Gymnor… https:… fd07f7… ALA sp… PRESENT\n2      -44.5    170. 2018-10-28 08:44:00 Gymnor… https:… 2f5933… Earth … PRESENT\n3      -44.1    170. 2019-05-02 15:18:00 Gymnor… https:… f09f13… Earth … PRESENT\n4      -43.6    147. 2019-03-10 13:00:00 Gymnor… https:… bf2044… eBird … PRESENT\n5      -43.6    147. 2018-02-05 13:00:00 Gymnor… https:… 52269e… eBird … PRESENT\n6      -43.6    147. 2018-02-05 13:00:00 Gymnor… https:… fe1644… eBird … PRESENT\n# … with abbreviated variable names ¹​decimalLatitude, ²​decimalLongitude,\n#   ³​scientificName, ⁴​taxonConceptID, ⁵​recordID, ⁶​dataResourceName,\n#   ⁷​occurrenceStatus\n\n\nFor the purpose of this exercise, we’re going to filter records not on the mainland or Tasmania.\n\nfiltered_occ &lt;- magpie_occ %&gt;% filter(decimalLongitude &lt; 155,\n                                      decimalLongitude &gt; 110,\n                                      decimalLatitude &gt; -45,\n                                      decimalLatitude &lt; -10)\n\n\n\nPlotting binned data\nThe easiest way to create a hex map is using the hexbin package. However, because there are some areas that have many more observations than other areas, without standardising our data the result is not very useful.\n\nggplot() +\n  geom_hex(data = filtered_occ,\n           mapping = aes(x = decimalLongitude, \n                         y = decimalLatitude), \n           bins = 47, \n           colour = \"white\") +\n  coord_sf(ylim = c(-45, -10), \n           xlim = c(110, 155)) +\n  scale_fill_gradientn(colours = c(\"#EEECEA\", \"#E06E53\")) +\n  theme_void()\n\n\n\n\nTo make a more informative hex map, in this case it might be useful to try to create our hexagons manually. We can do this by manually creating a grid of hexagons, filtering the grid to the outline of Australia, and adding our data of magpie counts to set the fill color of those hexagons. To achieve this, we first convert the map of Australia provided by ozmaps to the same coordinate system as ALA data:\n\naus &lt;- st_transform(ozmaps::ozmap_country, 4326)\n\nNext we’ll create a grid of hexagons.\n\ngrid_all &lt;- st_make_grid(aus, \n                         cellsize = 1, \n                         what = \"polygons\", \n                         square = FALSE,\n                         flat_topped = TRUE)\n\nggplot() +\n  geom_sf(data = grid_all)\n\n\n\n\nNow we can extract all the hexagons in our full grid that intersect our map of Australia, and filter our grid to only include those hexagons by only keeping the hexagon rows that are returned after running st_intersects().\n\n# extract rows that are within AUS land\nkeep_hexes &lt;- st_intersects(grid_all, aus) %&gt;%\n  as.data.frame(.) %&gt;%\n  pull(row.id)\n\n# filter full grid to only hexagon IDs in AUS\noz_grid &lt;- grid_all[keep_hexes]\n\nggplot() + geom_sf(data = oz_grid)\n\n\n\n\nNow to figure out how many magpie observations are within each hexagon. To do this, first we’ll convert our magpie observation points to an sf spatial object and make sure the point projection is the same as our map of Australia. Then we can use st_intersects() again to return a list, where each data.frame within the list shows which hexagon ID each point is within.\n\nmagpie_points_sf &lt;- filtered_occ %&gt;% \n  st_as_sf(coords = c(\"decimalLongitude\", \"decimalLatitude\"), \n  crs = st_crs(4326))\n\n\nintersect &lt;- st_intersects(magpie_points_sf, oz_grid)\n\nintersect[5:10]\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 1\n\n[[3]]\n[1] 1\n\n[[4]]\n[1] 2\n\n[[5]]\n[1] 1\n\n[[6]]\n[1] 1\n\n\nWith all points in their own separate data.frame, we can use the wicked-fast table() function from base R to count how many points match each hexagon ID, giving us our point counts! A little renaming and wrangling helps to get our counts in the right format.\n\n# condense counts into tibble\ncounts &lt;- as_tibble(table(unlist(intersect)), \n          .name_repair = \"unique\") %&gt;%\n  rename(\"hex_id\" = 1,\n         \"count\" = 2) %&gt;%\n  mutate(hex_id = as.integer(hex_id)) %&gt;%\n  replace_na(list(count = 0))\n\nFinally, we’ll add our count column from complete_counts to our oz_grid. To this, we’ll add a column containing the row number in oz_grid to act as a reference column to join with complete_counts. We will also be sure that oz_grid is an sf object for plotting.\n\noz_grid &lt;- oz_grid %&gt;%\n  as_tibble() %&gt;%\n  mutate(id = row_number()) %&gt;%\n  full_join(counts,\n            by = join_by(id == hex_id)) %&gt;%\n  st_as_sf()\n\noz_grid |&gt; head()\n\nSimple feature collection with 6 features and 2 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 144.8105 ymin: -44.13201 xmax: 148.5633 ymax: -41.63201\nGeodetic CRS:  WGS 84\n# A tibble: 6 × 3\n                                                            geometry    id count\n                                                       &lt;POLYGON [°]&gt; &lt;int&gt; &lt;int&gt;\n1 ((146.5425 -43.63201, 146.8312 -44.13201, 147.4086 -44.13201, 147…     1   493\n2 ((145.6765 -43.13201, 145.9652 -43.63201, 146.5425 -43.63201, 146…     2     7\n3 ((147.4086 -43.13201, 147.6972 -43.63201, 148.2746 -43.63201, 148…     3  1325\n4 ((144.8105 -42.63201, 145.0992 -43.13201, 145.6765 -43.13201, 145…     4     4\n5 ((146.5425 -42.63201, 146.8312 -43.13201, 147.4086 -43.13201, 147…     5  7656\n6 ((145.6765 -42.13201, 145.9652 -42.63201, 146.5425 -42.63201, 146…     6    63\n\n\nFinally, build our map! We’ll use scale_fill_gradientn() to add a nice legend, and standardise our data using a log-transformation so that the colours on our map are scaled to be more informative.\n\nggplot() +\n  geom_sf(data = oz_grid, aes(fill = count), size = .01) +\n  scale_fill_gradientn(colours = c(\"#EEECEA\", \"#E06E53\"), \n                       na.value = \"white\", \n                       trans = \"log10\",\n                       labels = scales::comma_format(),\n                       n.breaks = 6,\n                       guide = guide_colourbar(title = \"Observations\")) +\n  coord_sf(ylim = c(-45, -10), \n           xlim = c(110, 155)) +\n  theme_void()\n\n\n\n\n\n\n\n\nThat’s it! All the extra work does make a difference in this case, providing a better representation of the spread of Mapgies across Australia. Manually constructing hex maps can be useful in other circumstances, too. For example, if we wanted to compare the number of magpies to contextual information within each polygon (such as rainfall or human population data), then manually constructing our own hexagons could help us to combine data from different sources.\nA final point is that we could have achieved the same result by creating polygons first, then querying the ALA for the number of magpie records in each polygon using galah_geolocate(). That’s a bit more challenging, and not worthwhile in this case; but it can be an efficient solution where you require information on more species than there are polygons, for example. You can learn how to do this in this ALA Labs article, if you are interested to learn how!\n\n\nExpand for session info\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.2 (2022-10-31 ucrt)\n os       Windows 10 x64 (build 19044)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  English_Australia.utf8\n ctype    English_Australia.utf8\n tz       Australia/Sydney\n date     2023-03-29\n pandoc   2.19.2 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n dplyr       * 1.1.0   2023-01-29 [1] CRAN (R 4.2.2)\n galah       * 1.5.2   2023-03-20 [1] Github (AtlasOfLivingAustralia/galah@1b35520)\n ggplot2     * 3.4.1   2023-02-10 [1] CRAN (R 4.2.2)\n hexbin      * 1.28.2  2021-01-08 [1] CRAN (R 4.2.1)\n htmltools   * 0.5.4   2022-12-07 [1] CRAN (R 4.2.2)\n ozmaps      * 0.4.5   2021-08-03 [1] CRAN (R 4.2.1)\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.2.1)\n sf          * 1.0-9   2022-11-08 [1] CRAN (R 4.2.2)\n tidyr       * 1.3.0   2023-01-24 [1] CRAN (R 4.2.2)\n\n [1] C:/Users/KEL329/R-packages\n [2] C:/Users/KEL329/AppData/Local/Programs/R/R-4.2.2/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2022-02-17_sunburst-plots-for-taxonomic-data/post.html",
    "href": "posts/2022-02-17_sunburst-plots-for-taxonomic-data/post.html",
    "title": "Sunburst plots for taxonomic data",
    "section": "",
    "text": "Author\nMartin Westgate\n\n\nDate\nFebruary 17 2022\n\n\n\n\n\n\n\n\n\n\n\nTaxonomy is pretty important at the ALA. Every occurrence record in the atlas is linked to a unique taxonomic identifier. These identifiers are themselves drawn from expertly curated taxonomic datasets. This system of classification is so important to our infrastructure that we have a special name for it; the ‘taxonomic backbone’. But what does it look like?\nVisualising trees is not particularly easy for me; I didn’t train in it, and the data structures involved can be a bit complex. More importantly, until recently it was difficult to download detailed taxonomic information from the ALA. Since version 1.3.1 of galah, however, it has been possible to download taxonomic trees using the atlas_taxonomy() function. Let’s have a go at visualising these trees now.\n\nDownloading taxonomic trees\nThe first step is to choose a taxonomic group to represent in tree form. I’ve chosen the chordates (Phylum Chordata) because they aren’t too large a group and the names are fairly well-known. We can specify this within galah using the function galah_identify. The second piece of information we need to supply is how far ‘down’ the tree to travel. I’ve chosen the Order level here using galah_down_to(order); while we could have gone to the Family or even Genus, trying to traverse too many levels (i.e. to Genus or Species) would take a very long time. A full list of accepted ranks can be found by calling show_all_ranks().\n\nlibrary(galah)\nchordate_orders &lt;- galah_call() |&gt;\n  galah_identify(\"chordata\") |&gt;\n  galah_down_to(order) |&gt;\n  atlas_taxonomy()\n\nThe object returned by atlas_taxonomy is slightly unusual; it uses the data.tree package, meaning that the dataset is literally structured like a tree. This is notably different from other representations of networks, such as you might find in igraph, for example. To get an idea of what the data look like, we can use the inbuilt print method for this data type:\n\nlibrary(data.tree)\nprint(chordate_orders, pruneMethod = \"dist\", limit = 10)\n\n                            levelName\n1  Chordata                          \n2   ¦--Cephalochordata               \n3   ¦   °--Amphioxi                  \n4   ¦       °--... 1 nodes w/ 0 sub  \n5   ¦--Tunicata                      \n6   ¦   ¦--Appendicularia            \n7   ¦   ¦   °--... 1 nodes w/ 0 sub  \n8   ¦   ¦--Ascidiacea                \n9   ¦   ¦   °--... 5 nodes w/ 0 sub  \n10  ¦   °--Thaliacea                 \n11  ¦       °--... 3 nodes w/ 0 sub  \n12  °--Vertebrata                    \n13      ¦--Agnatha                   \n14      ¦   °--... 2 nodes w/ 2 sub  \n15      °--Gnathostomata             \n16          °--... 5 nodes w/ 134 sub\n\n\nThis shows there are three nodes directly beneath Chordata in the taxonomic hierarchy, of which the largest (by number of sub-nodes) is the vertebrates (Vertebrata). There is a lot we could do with this tree; each node contains a unique taxonomic identifer, for example, meaning that we could use individual nodes to make new queries using galah. However, for now a useful task is simply to visualise the structure of the whole tree.\n\n\nGetting plot-ready data\nTaxonomic trees are complex. While all species have a Kingdom, Phylum, Order, Class and Family, there are many intermediate categories that are ‘optional’. In practice, this means that when we convert to a data.frame for plotting, there are a lot of missing values; nodes that apply to some rows but not others.\n\ndf_rank &lt;- ToDataFrameTypeCol(chordate_orders, type = \"rank\")\ndf_rank[10:20,] |&gt; tibble::as_tibble() |&gt; print(max_footer_lines = 2)\n\n# A tibble: 11 × 10\n   rank_phylum rank_su…¹ rank_…² rank_…³ rank_…⁴ rank_…⁵ rank_…⁶ rank_…⁷ rank_…⁸\n   &lt;chr&gt;       &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  \n 1 Chordata    Tunicata  Thalia… &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;   \n 2 Chordata    Vertebra… &lt;NA&gt;    Myxini… &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;   \n 3 Chordata    Vertebra… &lt;NA&gt;    Petrom… &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;   \n 4 Chordata    Vertebra… Amphib… Gnatho… Lissam… &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;   \n 5 Chordata    Vertebra… Amphib… Gnatho… &lt;NA&gt;    Labyri… &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;   \n 6 Chordata    Vertebra… Amphib… Gnatho… &lt;NA&gt;    Salien… &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;   \n 7 Chordata    Vertebra… Aves    Gnatho… Neogna… &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;   \n 8 Chordata    Vertebra… Aves    Gnatho… Neogna… &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;   \n 9 Chordata    Vertebra… Aves    Gnatho… Palaeo… &lt;NA&gt;    Ratitae &lt;NA&gt;    &lt;NA&gt;   \n10 Chordata    Vertebra… Aves    Gnatho… Palaeo… &lt;NA&gt;    Ratitae &lt;NA&gt;    &lt;NA&gt;   \n11 Chordata    Vertebra… Aves    Gnatho… &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;   \n# … with 1 more variable: rank_order &lt;chr&gt;, and abbreviated variable names\n#   ¹​rank_subphylum, ²​rank_class, ³​rank_informal, ⁴​rank_subclass, …\n\n\nThese missing values will show up as empty sections in the resulting diagram, which isn’t ideal. Instead, we can build this data.frame so as to place all nodes in order by row, with empty ‘levels’ being placed at the end. This also avoids the problem where ‘unnamed’ ranks are grouped in the same column. To achieve this, we simply choose a different node attribute (level in this case) to supply to the type argument.\n\ndf_level &lt;- ToDataFrameTypeCol(chordate_orders, type = \"level\")\ndf_level[10:20, ] |&gt; tibble::as_tibble()\n\n# A tibble: 11 × 8\n   level_1  level_2    level_3       level_4     level_5 level_6 level_7 level_8\n   &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt;         &lt;chr&gt;       &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  \n 1 Chordata Tunicata   Thaliacea     Salpida     &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;   \n 2 Chordata Vertebrata Agnatha       Myxini      Myxini… &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;   \n 3 Chordata Vertebrata Agnatha       Petromyzon… Petrom… &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;   \n 4 Chordata Vertebrata Gnathostomata Amphibia    Lissam… Anura   &lt;NA&gt;    &lt;NA&gt;   \n 5 Chordata Vertebrata Gnathostomata Amphibia    Labyri… Temnos… &lt;NA&gt;    &lt;NA&gt;   \n 6 Chordata Vertebrata Gnathostomata Amphibia    Salien… Spheno… &lt;NA&gt;    &lt;NA&gt;   \n 7 Chordata Vertebrata Gnathostomata Aves        Neogna… Accipi… &lt;NA&gt;    &lt;NA&gt;   \n 8 Chordata Vertebrata Gnathostomata Aves        Neogna… Phaeth… &lt;NA&gt;    &lt;NA&gt;   \n 9 Chordata Vertebrata Gnathostomata Aves        Palaeo… Ratitae Casuar… &lt;NA&gt;   \n10 Chordata Vertebrata Gnathostomata Aves        Palaeo… Ratitae Dinorn… &lt;NA&gt;   \n11 Chordata Vertebrata Gnathostomata Aves        Accipi… &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;   \n\n\nAnother problem in this dataset is the existence of duplicated taxonomic names. This happens because different authorities place the same taxon in different parts of the tree, and while the ALA tries to clean up these issues, some disagreements remain. The code below assumes that each name is only present once, so we have to remove duplicates to proceed. Fortunately there is a function in package base that flags duplcated values as TRUE and unique values as FALSE. We can use this function to identify rows where order is not unique.\n\nlibrary(dplyr)\nkeep_rows &lt;- !duplicated(df_rank$rank_order)\ndf_rank &lt;- filter(df_rank, keep_rows)\ndf_level &lt;- filter(df_level, keep_rows)\n\nThe next step is to determine how to represent this structure in a plot. At the moment we can’t do this, because the data are in ‘wide’ format. Instead, we need to reorder our data so that each node/taxon is represented once, and other plotting aesthetics can be added as additional columns. To achieve this, we first convert to ‘long’ format, preserving information like what row and column each taxonomic label was recorded in.\n\ndf_long &lt;- tibble(\n  row = rep(seq_len(nrow(df_level)), ncol(df_level)),\n  level = rep(seq_len(ncol(df_level)), each = nrow(df_level)),\n  taxon = do.call(c, df_level)) |&gt; \n  filter(!is.na(taxon)) # remove missing values\n\nThen, we can summarize this plot so that each row is a single taxon, recording some metadata about rows and columns from the original dataset\n\ndf_plot &lt;- df_long |&gt;\n  group_by(taxon) |&gt;\n  summarize(\n    xmin = min(row) - 1, \n    xmax = max(row), \n    ymin = level[1] - 1,\n    ymax = level[1])\n     \ndf_plot\n\n# A tibble: 161 × 5\n   taxon             xmin  xmax  ymin  ymax\n   &lt;chr&gt;            &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt;\n 1 Acanthopterygii     61    74     6     7\n 2 Accipititrifomes    15    16     5     6\n 3 Accipitriformes     19    20     4     5\n 4 Actinopterygii      56    96     4     5\n 5 Agnatha             10    12     2     3\n 6 Albuliformes        57    58     6     7\n 7 Amphibia            12    15     3     4\n 8 Amphioxi             0     1     2     3\n 9 Amphioxiformes       0     1     3     4\n10 Anguilliformes      58    59     6     7\n# … with 151 more rows\n\n\n\n\nDrawing\nOur dataset now contains all the information we need to plot the structure of our taxonomic tree. As usual, we’re going to plot this with ggplot2.\n\nlibrary(ggplot2)\nggplot(df_plot) +\n  geom_rect(\n    mapping = aes(\n      xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, \n      group = taxon,\n      fill = ymax),\n    color = \"white\")\n\n\n\n\n\n\n\n\nWhile this is (probably) accurate, it’s not very informative. The most obvious missing element is labels; to add these, we’ll need to determine which nodes are ‘leaves’, and which are ‘branches’. We’ll also want to restrict labelling to larger branches, to avoid the text looking crowded. Finally, there is no need to label leaves with both a rectangle and text; so we’ll remove the leaf rectangles from the plot.\n\ndf_plot &lt;- df_plot |&gt; mutate(\n  x_dist = xmax - xmin,\n  is_leaf = taxon %in% df_rank$rank_order)\n\np &lt;- ggplot() +\n  geom_rect(\n    data = filter(df_plot, !is_leaf),\n    mapping = aes(\n      xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, \n      group = taxon,\n      fill = ymax),\n    color = \"white\")\n\np +\n  # branch labels\n  geom_text(\n    data = filter(df_plot, x_dist &gt; 5),\n    mapping = aes(\n      x = xmin + (x_dist * 0.5), \n      y = ymin + 0.5,\n      label = taxon),\n    color  = \"white\",\n    size = 3) +\n  # leaf labels\n  geom_text(\n    data = filter(df_plot, is_leaf),\n    aes(x = xmin + 0.5, y = ymin, label = taxon),\n    angle = 90,\n    hjust = 0,\n    size = 2.5,\n    color = \"grey20\") \n\n\n\n\n\n\n\n\nThis is better, but not ideal. A much more pleasing look is to use coord_polar() to generate a circular plot; but this leads to linear text on a circular plot, which looks messy. Fortunately, the new package geomtextpath solves this problem. All we have to do is replace geom_text with geom_textpath, leaving all other code the same, and add coord_polar() at the end.\n\nlibrary(geomtextpath)\n\np &lt;- p + \n  geom_textpath(\n    data = filter(df_plot, x_dist &gt; 5),\n    mapping = aes(\n      x = xmin + (x_dist * 0.5), \n      y = ymin + 0.5,\n      label = taxon),\n    color  = \"white\",\n    size = 2.7) +\n  geom_textpath(\n    data = filter(df_plot, is_leaf),\n    aes(x = xmin + 0.5, y = ymin, label = taxon),\n    angle = 90,\n    hjust = 0,\n    size = 2.3,\n    color = \"grey20\") +\n  coord_polar()\np\n\n\n\n\n\n\n\n\nFinally, we can add some finishing touches by changing the color scheme, hiding the background colors and legend, and resizing the y axis so all the labels are visible.\n\nlibrary(viridis)\n\np +\n  scale_fill_viridis(begin = 0, end = 0.9, direction = -1) +\n  lims(y = c(0, 9)) +\n  theme_void() + \n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nDone! This is a fun plot, but there are ways it could be expanded or improved, the most obvious of which is to find ways to add supplementary information. Wouldn’t it be great, for example, to add leaf-level record counts as marginal barplots? Or scale the size of segments to the number of records, rather than the number of clades? While none of these are impossible, I’m going to leave this here for now. I hope you like the result!\n\n\nExpand for session info\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.2 (2022-10-31 ucrt)\n os       Windows 10 x64 (build 19044)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  English_Australia.utf8\n ctype    English_Australia.utf8\n tz       Australia/Sydney\n date     2023-03-29\n pandoc   2.19.2 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package      * version date (UTC) lib source\n data.tree    * 1.0.0   2020-08-03 [1] CRAN (R 4.2.1)\n dplyr        * 1.1.0   2023-01-29 [1] CRAN (R 4.2.2)\n galah        * 1.5.2   2023-03-20 [1] Github (AtlasOfLivingAustralia/galah@1b35520)\n geomtextpath * 0.1.1   2022-08-30 [1] CRAN (R 4.2.1)\n ggplot2      * 3.4.1   2023-02-10 [1] CRAN (R 4.2.2)\n htmltools    * 0.5.4   2022-12-07 [1] CRAN (R 4.2.2)\n sessioninfo  * 1.2.2   2021-12-06 [1] CRAN (R 4.2.1)\n viridis      * 0.6.2   2021-10-13 [1] CRAN (R 4.2.1)\n viridisLite  * 0.4.1   2022-08-22 [1] CRAN (R 4.2.1)\n\n [1] C:/Users/KEL329/R-packages\n [2] C:/Users/KEL329/AppData/Local/Programs/R/R-4.2.2/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2022-05-17_3d-map/post.html",
    "href": "posts/2022-05-17_3d-map/post.html",
    "title": "Download plant species data by hexagon to make a 3D hex map",
    "section": "",
    "text": "Grabbing people’s attention in a content-filled world can be difficult. 3D maps can be particularly eye-catching, and thanks to the rayshader package it has become relatively simple to make a beautiful 3D plot with the help of {ggplot2}.\nIn this post, we’ll make a 3D hex map of the number of plant species identified from ALA observations since 2020. This map builds on a previous hex map post, but this time we will use a more unique “grid-to-data” method to download our data, where instead of plotting hexagons over our map after extracting data, we’ll create a grid of hexagons that map to Australia before extracting any data and query the ALA for data for each hexagon. This method is cool because it saves a lot of work wrangling your data to fit your plot later on."
  },
  {
    "objectID": "posts/2022-05-17_3d-map/post.html#footnotes",
    "href": "posts/2022-05-17_3d-map/post.html#footnotes",
    "title": "Download plant species data by hexagon to make a 3D hex map",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIf you get a weird error related to the scales package, updating to the latest version should fix it: https://github.com/tylermorganwall/rayshader/issues/181#:~:text=Update%20to%20the,install.packages(%27rayshader%27) ↩︎"
  },
  {
    "objectID": "posts/2022-05-23-ggnewscale/post.html",
    "href": "posts/2022-05-23-ggnewscale/post.html",
    "title": "Multiple colour scales in choropleth maps with {ggnewscale}",
    "section": "",
    "text": "Author\nShandiya Balasubramanium\n\n\nDate\n23 May 2022\n\n\n\n\n\n\n\n\n\n\n\nChoropleth maps visually summarise how variables (like species richness or population density, for example) vary across geographic areas. These maps require two inputs:\n\na geospatial object with information on regional boundaries\na numerical variable that can be mapped to each geographic unit using colour\n\nHere, I walk through the process of mapping the density of plant records from the ALA to geographic bioregions across Australia, using two colour scales to differentiate between marine and terrestrial records.\n\nGet geospatial and count data\nLet’s start by loading the packages we’ll need.\n\nlibrary(galah)\nlibrary(here)\nlibrary(sf)\nlibrary(rmapshaper)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(ggnewscale)\n\nNext, we’ll need some regional boundaries. I think the IBRA7 and IMCRA4 bioregions will work nicely for what we’re planning. These boundaries classify Australia’s landscapes and waters into geographically distinct bioregions based on variables like climate, geomorphology, and species information.\nAfter downloading the data, we can read it in using the sf package and check that it looks correct. Here, I’ve also elected to use ms_simplify() from the rmapshaper package to simplify the geospatial features and speed up computation.\n\n# read in IMCRA shapefile\nimcra_shp &lt;- st_read(here(\"posts\", \n                          \"data\",\n                          \"imcra_mesoscale_bioregions\",\n                          \"imcra4_meso.shp\"), \n                     quiet = TRUE) |&gt; \n  ms_simplify(keep = 0.1)\n\n# read in IBRA shapefile\nibra_shp &lt;- st_read(here(\"posts\",\n                         \"data\",\n                         \"IBRA7_regions\",\n                         \"ibra7_regions.shp\"),\n                    quiet = TRUE) |&gt; \n  ms_simplify(keep = 0.1)\n\nAnd finally, let’s get the number of plant records in the ALA using the galah package, grouped by IBRA or IMCRA region. To do this, we need to know what the ALA calls the IBRA and IMCRA layers.\nUsing the search_fields() function, we can determine that the IBRA layer we’re after is called cl1048 and the IMCRA layer, cl966.\n\nsearch_fields(\"IBRA\")\n\n# A tibble: 4 × 4\n  id     description                                                 type  link \n  &lt;chr&gt;  &lt;chr&gt;                                                       &lt;chr&gt; &lt;chr&gt;\n1 cl3    \"Western Australian Biodiversity Science Research Priority… laye… \"htt…\n2 cl20   \"IBRA 6 Regions Interim Biogeographic Regionalisation of A… laye… \"htt…\n3 cl1049 \"IBRA 7 Subregions IBRA 7 Subregions\"                       laye… \"htt…\n4 cl1048 \"IBRA 7 Regions Interim Biogeographic Regionalisation for … laye… \"htt…\n\nsearch_fields(\"IMCRA\")\n\n# A tibble: 2 × 4\n  id    description                                                  type  link \n  &lt;chr&gt; &lt;chr&gt;                                                        &lt;chr&gt; &lt;chr&gt;\n1 cl966 IMCRA Meso-scale Bioregions IMCRA Meso-scale Bioregions      laye… http…\n2 cl21  IMCRA 4 Regions Integrated Marine and Coastal Regionalisati… laye… http…\n\n\nTo get counts of records from the ALA, we can pass a query with galah_call() and build our query using pipes.\nWe will specify that we only want plant records matching Plantae or Chlorophyta using galah_identify(), apply the default set of ALA data quality filters to remove poor quality records using galah_filter(), group records by region using galah_group_by(), and finally return the counts of records that match all our criteria with atlas_counts().\n\n# counts in IBRA regions\nibra_counts &lt;- galah_call() |&gt;\n  galah_identify(\"plantae\", \"chlorophyta\") |&gt;\n  galah_filter(profile = \"ALA\") |&gt; \n  galah_group_by(\"cl1048\") |&gt;      # IBRA regions\n  atlas_counts()\n\nhead(ibra_counts)\n\n# A tibble: 6 × 2\n  cl1048                      count\n  &lt;chr&gt;                       &lt;int&gt;\n1 Sydney Basin              2377040\n2 South Eastern Highlands   1578563\n3 South East Corner          836072\n4 South Eastern Queensland   815059\n5 NSW North Coast            810111\n6 Murray Darling Depression  757185\n\n# counts in IMCRA regions\nimcra_counts &lt;- galah_call() |&gt;\n  galah_identify(\"plantae\", \"chlorophyta\") |&gt;\n  galah_filter(profile = \"ALA\") |&gt; \n  galah_group_by(\"cl966\") |&gt;      # IMCRA bioregions\n  atlas_counts()\n\nhead(imcra_counts)\n\n# A tibble: 6 × 2\n  cl966                count\n  &lt;chr&gt;                &lt;int&gt;\n1 Victorian Embayments 26139\n2 Shoalwater Coast     19739\n3 Bruny                19597\n4 Central Victoria     19243\n5 Lucinda-Mackay Coast 19140\n6 Flinders             18338\n\n\n\n\nJoin geospatial and count data\nWe now have the two things we need to make a choropleth map:\n\nIBRA/IMCRA boundaries\ncounts of plant records in each region\n\nTo create a plot, we need to combine the geospatial and numeric data. But first, let’s check if the data needs to be tidied.\nAs we’re going to be joining the spatial and count data, we need to be sure that the names of the IBRA/IMCRA regions match in both datasets. To double check that all of our region names match, we’ll use setdiff(). There are no name mismatches when character(0) is returned, but if any region names are returned that means there is a problem somewhere that we need to fix before joining our dataframes.\nWhen we run setdiff(), the IBRA names match perfectly, but there’s a mismatch in two IMCRA names.\n\n# check region names match\nsetdiff(ibra_counts$cl1048, ibra_shp$REG_NAME_7)\n\ncharacter(0)\n\nsetdiff(imcra_counts$cl966, imcra_shp$MESO_NAME)\n\n[1] \"Pilbarra (nearshore)\" \"Pilbarra (offshore)\" \n\n\nReversing the order of IMCRA data frames in setdiff() reveals that that Pilbara is misspelled in the imcra_counts dataset. We can easily change this and confirm both sets of names match before continuing.\n\n# check the reverse for IMCRA names\nsetdiff(imcra_shp$MESO_NAME, imcra_counts$cl966)\n\n[1] \"Pilbara (offshore)\"  \"Pilbara (nearshore)\"\n\n# replace \"Pilbarra\" with \"Pilbara\" \nimcra_counts &lt;- imcra_counts |&gt; \n  mutate(cl966 = str_replace(string = cl966, \n                             pattern = \"Pilbarra\", \n                             replacement = \"Pilbara\"))\n\n# check names match\nsetdiff(imcra_counts$cl966, imcra_shp$MESO_NAME)\n\ncharacter(0)\n\n\nNow let’s check how our data are distributed so we can decide whether we should scale them with a transformation before plotting. Data skewed too far to the right will not show differences very clearly when they are mapped.\nChecking the distribution of counts in each dataset shows a substantial skew to the right.\n\nhist(imcra_counts$count)\nhist(ibra_counts$count)\n\n\n\n\n\n\n\n\n\n\n\nApplying a log-transformation to the count data makes the distribution more symmetrical.\n\nhist(log(imcra_counts$count))\nhist(log(ibra_counts$count))\n\n\n\n\n\n\n\n\n\n\n\nNext, we join the geospatial and numeric data. Along the way, we rename some columns, remove unnecessary columns, calculate counts as a proportion of the area of each region (so we’re plotting density of records, not counts of records), and convert the resulting dataframe into a simple features object.\n\nimcra_join &lt;- imcra_counts |&gt; \n  full_join(y = imcra_shp, by = c(\"cl966\" = \"MESO_NAME\")) |&gt; \n  rename(\"imcra\" = \"cl966\") |&gt; \n  select(imcra, count, AREA_KM2, geometry) |&gt; \n  mutate(density_log10 = log10(count / AREA_KM2)) |&gt; \n  select(imcra, density_log10, geometry) |&gt; \n  st_as_sf()\n\nibra_join &lt;- ibra_counts |&gt; \n  full_join(y = ibra_shp, by = c(\"cl1048\" = \"REG_NAME_7\")) |&gt; \n  rename(\"ibra\" = \"cl1048\") |&gt; \n  select(ibra, count, SQ_KM, geometry) |&gt; \n  mutate(density_log10 = log10(count / SQ_KM)) |&gt; \n  select(ibra, density_log10, geometry) |&gt; \n  st_as_sf()\n\n\n\nMake a map\nFinally, we’ll use the ggnewscale package to apply different colour palettes to the marine and terrestrial data in a choropleth map.\n\nggplot() + \n  geom_sf(data = imcra_join,\n          aes(fill = density_log10),\n          colour = NA) +\n  scale_fill_distiller(name = \"IMCRA\",\n                       type = \"seq\",\n                       palette = \"BuPu\",\n                       direction = 1,\n                       labels = c(\"0.001\", \"0.01\", \"0.1\", \"1\", \"10\"),\n                       guide = guide_colorsteps(direction = \"horizontal\",\n                                                label.position = \"bottom\",\n                                                title.position = \"left\")) +\n  # adds new colour scale\n  ggnewscale::new_scale_fill() +\n  geom_sf(data = ibra_join,\n          aes(fill = density_log10),\n          colour = NA) +\n  scale_fill_distiller(name = \"IBRA\",\n                       type = \"seq\",\n                       palette = \"YlOrBr\",\n                       direction = 1,\n                       labels = c(\"0.1\", \"1\", \"10\", \"100\"),\n                       guide = guide_colorsteps(direction = \"horizontal\",\n                                                label.position = \"bottom\",\n                                                title.position = \"left\")) +\n  # adds a title for both legends\n  annotate(\"text\", \n           x = 133, \n           y = -45.5, \n           label = \"No. of records per square km\",\n           size = 6) +\n  coord_sf(xlim = c(110, 155), ylim = c(-45, -10)) +\n  theme_void() +\n  theme(legend.position = \"bottom\",\n        legend.key.width = unit(12, 'mm'))\n\n\n\n\n\n\n\n\n\n\nSuccess!\nOne thing to note is that we didn’t necessarily have to use ggnewscale here; we could just as easily have combined all the data and plotted them on the same map without keeping the IBRA and IMCRA datasets separate. But, i) it’s nice to be able to differentiate marine and terrestrial regions at a glance, and ii) using two legends also makes it clear that there’s a stark difference in the number of plant records for marine and terrestrial regions.\n\n\nExpand for session info\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.2 (2022-10-31 ucrt)\n os       Windows 10 x64 (build 19044)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  English_Australia.utf8\n ctype    English_Australia.utf8\n tz       Australia/Sydney\n date     2023-02-10\n pandoc   2.19.2 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n dplyr       * 1.1.0   2023-01-29 [1] CRAN (R 4.2.2)\n galah       * 1.5.1   2023-01-13 [1] CRAN (R 4.2.2)\n ggnewscale  * 0.4.7   2022-03-25 [1] CRAN (R 4.2.1)\n ggplot2     * 3.3.6   2022-05-03 [1] CRAN (R 4.2.1)\n here        * 1.0.1   2020-12-13 [1] CRAN (R 4.2.1)\n htmltools   * 0.5.4   2022-12-07 [1] CRAN (R 4.2.2)\n rmapshaper  * 0.4.6   2022-05-10 [1] CRAN (R 4.2.1)\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.2.1)\n sf          * 1.0-8   2022-07-14 [1] CRAN (R 4.2.1)\n stringr     * 1.5.0   2022-12-02 [1] CRAN (R 4.2.2)\n\n [1] C:/Users/KEL329/R-packages\n [2] C:/Users/KEL329/AppData/Local/Programs/R/R-4.2.2/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2022-07-22_sample-bias/post.html",
    "href": "posts/2022-07-22_sample-bias/post.html",
    "title": "Quantify geographic sampling bias with {sampbias}",
    "section": "",
    "text": "Being human plays a big role in the species we observe, when we observe them and where we observe them. In particular, we tend to collect more data in areas that are closer to places we live (or have access to) because there are more opportunities to see species in areas we spend more time in than areas that are far away or inaccessible.\nLarge, public datasets like the Atlas of Living Australia are especially prone to this sampling bias because they largely reflect opportunistic observations rather than systematic monitoring programs. However, not all species observations are affected equally by these biases, and it’s useful to quantify how biased data are before interpreting them.\nThanks to the sampbias package, we can easily quantify and compare the effects of these biases on our data, specifically whether data are influenced by cities, roads, airports and rivers.\nThis post expands on a Twitter thread by Dr Ian Brennan to show how sampling bias affects museum records of reptiles. Dr Brennan is currently a Post Doctoral researcher at the Australian National University (ANU). Check out his website to learn more about him and his cool research."
  },
  {
    "objectID": "posts/2022-07-22_sample-bias/post.html#quolls",
    "href": "posts/2022-07-22_sample-bias/post.html#quolls",
    "title": "Quantify geographic sampling bias with {sampbias}",
    "section": "Quolls",
    "text": "Quolls\n\nQuolls & Mulgaras\n\n\n\n\n\n\n\n\n\n\n\nLeft: Dasyurus hallucatus (David White CC BY-NC 4.0), Right: Dasycercus blythi (Robert Browne-Cooper CC-BY-NC 3.0 (Au))"
  },
  {
    "objectID": "posts/2022-07-22_sample-bias/post.html#little-kingfisher",
    "href": "posts/2022-07-22_sample-bias/post.html#little-kingfisher",
    "title": "Quantify geographic sampling bias with {sampbias}",
    "section": "Little Kingfisher",
    "text": "Little Kingfisher\n\nLittle Kingfisher\n\n\n\n\n\n\n\n\n\n\n\nLeft: Ceyx pusillus (Greg Holland CC BY-NC 4.0), Right: Ceyx pusillus (Graham Winterflood CC-BY-SA 4.0 (Au))"
  },
  {
    "objectID": "posts/2022-07-22_sample-bias/post.html#mantids",
    "href": "posts/2022-07-22_sample-bias/post.html#mantids",
    "title": "Quantify geographic sampling bias with {sampbias}",
    "section": "Mantids",
    "text": "Mantids\n\nMantids\n\n\n\n\n\n\n\n\n\n\n\nLeft: Hierodula majuscula (Michael Mcmaster CC BY-NC 4.0), Right: Tenodera australasiae (Reiner Richter CC BY-NC-SA 4.0))"
  },
  {
    "objectID": "posts/2022-07-22_sample-bias/post.html#green-birdflower",
    "href": "posts/2022-07-22_sample-bias/post.html#green-birdflower",
    "title": "Quantify geographic sampling bias with {sampbias}",
    "section": "Green birdflower",
    "text": "Green birdflower\n\nGreen birdflower\n\n\n\n\n\n\n\n\n\n\n\nLeft: Crotalaria cunninghamii (Gerald Krygsman CC BY-NC 4.0), Right: Crotalaria cunninghamii (Steve Dew CC BY-NC 4.0))"
  },
  {
    "objectID": "posts/2022-07-22_sample-bias/post.html#footnotes",
    "href": "posts/2022-07-22_sample-bias/post.html#footnotes",
    "title": "Quantify geographic sampling bias with {sampbias}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nfor biases↩︎\nfrom over-interpreting your data↩︎"
  },
  {
    "objectID": "posts/2022-10-12_alpha-hulls/post.html",
    "href": "posts/2022-10-12_alpha-hulls/post.html",
    "title": "Convex and alpha hulls for conservation mapping",
    "section": "",
    "text": "The ability to predict where a species resides is important in conservation ecology, but when a species has very few existing observations (i.e. a data-deficient species), predicting its distribution can be difficult (or impossible) using standard methods for species distributions.\nConvex hulls and alpha hulls are two ways to plot the spatial distribution of data-deficient species, making it possible to calculate metrics that help us predict whether a species is threatened to become extinct (i.e. IUCN metrics).\nRecently, Dr. Marsh and colleagues used alpha hulls to estimate the impact of the 2020 mega bushfires on invertebrates in southern Australia. Since invertebrate data is inherently sparse, alpha hulls are really useful when you only have a handful of records to work with.\nIn this post, we’ll explain the difference between convex hulls and alpha hulls and show you how to make them yourself!"
  },
  {
    "objectID": "posts/2022-10-12_alpha-hulls/post.html#download-data",
    "href": "posts/2022-10-12_alpha-hulls/post.html#download-data",
    "title": "Convex and alpha hulls for conservation mapping",
    "section": "Download data",
    "text": "Download data\nTo illustrate the various spatial polygons you can make, let’s look at an invertebrate species from Dr. Marsh’s study: an endemic damselfly, Austroargiolestes calcaris, commonly known as the Powdered Flatwing\n\n\n\n \n\n\n\n\n\n \n\n\n\n\nA Powdered Flatwing perched on a plant by Reiner Richter CC-BY 4.0\n\nFirst we will load the R packages we’ll need:\n\n# install.packages(\"pacman\")\npacman::p_load(remotes, galah, tidyverse, alphahull, \n               sp, sf, ozmaps, patchwork)\n\nNow let’s use galah to download occurrence records from the Atlas of Living Australia (ALA). Note that you will need to first enter a registered email with the ALA using galah_config before fetching records.\n\n# Add registered email (register at ala.org.au)\ngalah_config(email = \"your-email@email.com\")\n\n\n# Download Powdered flatwing records \ngalah_call() |&gt; \n  galah_identify(\"Austroargiolestes calcaris\") |&gt; \n  galah_filter(profile=\"ALA\") |&gt; \n  galah_select(group = \"basic\") |&gt; \n  atlas_occurrences() -&gt; dfly\n\n# See first 10 rows\ndfly |&gt; head(10L)\n\n# A tibble: 10 × 8\n   decimal…¹ decim…² eventDate           scien…³ taxon…⁴ recor…⁵ dataR…⁶ occur…⁷\n       &lt;dbl&gt;   &lt;dbl&gt; &lt;dttm&gt;              &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  \n 1     -38.5    147. 2016-11-09 13:00:00 Austro… https:… 20b351… iNatur… PRESENT\n 2     -38      146. 2011-12-20 13:00:00 Austro… https:… d4e2c9… Reiner… PRESENT\n 3     -38.0    146. 2010-01-10 17:48:00 Austro… https:… 0c69fb… iNatur… PRESENT\n 4     -38.0    146. 2009-11-24 13:00:00 Austro… https:… b01df3… Reiner… PRESENT\n 5     -38.0    146. 2009-12-19 13:00:00 Austro… https:… 2ed539… Reiner… PRESENT\n 6     -38.0    146. 2018-02-04 03:40:00 Austro… https:… 586eb7… iNatur… PRESENT\n 7     -38.0    146. 2015-12-28 13:00:00 Austro… https:… 125786… Reiner… PRESENT\n 8     -37.9    145. 2004-10-30 14:00:00 Austro… https:… 9ff508… Reiner… PRESENT\n 9     -37.9    145. 2016-10-31 23:50:00 Austro… https:… fae8d5… ALA sp… PRESENT\n10     -37.9    145. 2019-11-23 01:38:00 Austro… https:… faae5f… iNatur… PRESENT\n# … with abbreviated variable names ¹​decimalLatitude, ²​decimalLongitude,\n#   ³​scientificName, ⁴​taxonConceptID, ⁵​recordID, ⁶​dataResourceName,\n#   ⁷​occurrenceStatus\n\n\nBefore we can plot anything, we will also need to remove all duplicated values and any NA values!\n\n# Remove duplicates & NAs\ndfly |&gt; \n  filter(!duplicated(decimalLongitude) & !duplicated(decimalLatitude)) |&gt; \n  filter(!is.na(decimalLongitude) & !is.na(decimalLatitude) ) -&gt; dfly_clean"
  },
  {
    "objectID": "posts/2022-10-12_alpha-hulls/post.html#map-a-convex-hull",
    "href": "posts/2022-10-12_alpha-hulls/post.html#map-a-convex-hull",
    "title": "Convex and alpha hulls for conservation mapping",
    "section": "Map a convex hull",
    "text": "Map a convex hull\nA convex hull is a way to draw around all the points of a species on a map with as few lines as possible. It’s defined as the smallest polygon that encloses all the points in the data set.\nTo plot a convex hull on a map, we can use chull() to compute a convex hull from our cleaned Powdered Flatwing data. chull() computes a series of points that make up our convex hull.\n\n# Compute convex hull\ndfly_clean |&gt; \n  dplyr::select(decimalLongitude, decimalLatitude) |&gt;  \n  chull() -&gt; dfly_chull\n\ndfly_chull\n\n[1] 149 148   1  25 137 223 401 355\n\n\nNext, we join the first point of the hull vector to the last point, creating a closed outline which can be plotted on a map.\n\n# Join first point of hull to the last point\ndfly_chull_pts &lt;- c(dfly_chull, dfly_chull[1])\n\nNow we can get a map of Australia from the {ozmaps} package and use st_transform() to make sure it has the correct projection of 4326.\n\n# Get map of Australia\naus &lt;- st_transform(ozmaps::ozmap_country, 4326)\n\nAnd finally, we plot our Powdered Flatwing occurrence records and its convex hull on a map!\n\n# Plot occurrences and convex hull\nggplot() + \n  geom_sf(data = aus, \n          colour = \"black\", \n          fill = \"white\")  + \n  geom_point(data = dfly_clean, \n             mapping = aes(decimalLongitude, decimalLatitude), \n             colour = \"black\", size = 0.8) + \n  geom_polygon(data = dfly_clean[dfly_chull_pts, ], \n               mapping = aes(decimalLongitude, decimalLatitude), \n               fill = \"orange\", \n               colour = \"black\", \n               alpha = 0.5) + \n  coord_sf(xlim=c(142, 152), \n           ylim=c(-32,-44)) +\n  labs(title = \"Convex hull\", \n       x = \"Longtitude (DD)\", \n       y = \"Latitude (DD)\") + ## DD here stands for decimal degrees\n  theme_bw()"
  },
  {
    "objectID": "posts/2022-10-12_alpha-hulls/post.html#what-is-an-alpha-hull",
    "href": "posts/2022-10-12_alpha-hulls/post.html#what-is-an-alpha-hull",
    "title": "Convex and alpha hulls for conservation mapping",
    "section": "What is an alpha hull?",
    "text": "What is an alpha hull?\nLike a convex hull, an alpha hull is also a way to draw the smallest polygon that encloses all the points in a data set. However, alpha hulls differ because they use an alpha parameter to control how tightly the boundary fits around a set of points. This method creates concave, arched edges that fit around occurrence records more tightly. A tighter boundary around our points helps us avoid over-predicting the range of a species.\nTo illustrate, here are three alpha hulls with increasing values for alpha. Notice as the alpha value increases, the tightness of our boundary decreases.\n\n\nCode\n# Compute alpha shapes and store in list column within a tibble\ntibble(\n  alpha_value = c(1, 2, 5),\n  ahull_ls = map(.x = c(1, 2, 5),\n                 .f = ~ dfly_clean |&gt; \n                   select(decimalLongitude, decimalLatitude) |&gt; \n                   ahull(alpha = .x)) \n) -&gt; dfly_ahulls\n\n\n# Transform alpha hull to an `sp` object and set map projection to 4326\nset_map_proj &lt;- function(sp_obj){\nsp_obj@proj4string &lt;- sp::CRS(\"EPSG:4326\") \n\nsp_obj\n}\n\ndfly_ahulls |&gt; \n  mutate(ahull_sp = map(.x = ahull_ls,\n                        .f = hull2spatial::ahull2poly),\n         ahull_sp = map(.x = ahull_sp,\n                        .f = set_map_proj)\n         ) -&gt; dfly_ahulls\n\n\n# Transform `sp` object into a `sf` object \ndfly_ahulls |&gt; \n  mutate(ahull_sf = map(.x = ahull_sp,\n                        .f = st_as_sf)\n         ) -&gt; dfly_ahulls\n\n# Transform occurrences into `sf` object for plotting\nst_as_sf(dfly_clean, \n         coords = c(\"decimalLongitude\", \"decimalLatitude\"), \n         crs = 4326) -&gt; dfly_sf\n\n## A function to compose map \nplot_ahull_fun &lt;- function(ahull_sf, title = NULL){\n  p &lt;- ggplot() + \n    geom_sf(data = aus, colour = \"black\", fill = \"white\")  +\n    geom_sf(data = dfly_sf, colour = \"black\", size = 0.5) +  \n    geom_sf(data = ahull_sf, fill = \"orange\", alpha = 0.5) +\n    coord_sf(xlim=c(142, 152),ylim=c(-32,-44)) +\n    ggtitle(paste(\"a = \", as.character(title))) +\n    labs(x = \"Longtitude (DD)\", y = \"Latitude (DD)\") + \n    theme_bw(base_size = 12)\n  \n  p\n}\n\ndfly_ahulls |&gt; \n  mutate(ahull_maps = map2(.x = ahull_sf,\n                           .y = alpha_value,\n                           .f = ~ plot_ahull_fun(.x , .y)) \n  ) -&gt; dfly_ahulls\n\n\n\n\n\n\n\n\n\n\n\nAlpha = 2 is the alpha value we’ve most commonly come across in research, and is the value recommended by the IUCN for various forms of species vulnerability analysis.\nSo, let’s learn how to make the a = 2 plot above!"
  },
  {
    "objectID": "posts/2022-10-12_alpha-hulls/post.html#map-an-alpha-hull",
    "href": "posts/2022-10-12_alpha-hulls/post.html#map-an-alpha-hull",
    "title": "Convex and alpha hulls for conservation mapping",
    "section": "Map an alpha hull",
    "text": "Map an alpha hull\nTo make an alpha hull, we will rely on the hull2spatial package (developed by Cecina Babich Morrow). This package allows us to convert “ahull” objects into ggplot-friendly objects (to learn more, check out their blog post about the package).\nInstall the package from GitHub using:\n\nremotes::install_github(\"babichmorrowc/hull2spatial\")\nlibrary(hull2spatial)\n\nTo compute our alpha hull, we’ll provide the longitude and latitude coordinates of our data points to the ahull() function, and set alpha = 2. ahull() creates a list object with far more complexity than our convex hull. A nice way to understand the difference is to look at the first 5 rows of the arcs component of our list dfly_ahull, which stores information like the center and radius of each arch in our alpha hull.\n\n# Compute an alpha hull\ndfly_clean |&gt; \n  dplyr::select(decimalLongitude, decimalLatitude) |&gt; \n  ahull(alpha = 2) -&gt; dfly_ahull\n\n# See first 5 values of `arcs` component of list\ndfly_ahull$arcs |&gt; head(5L)\n\n           c1        c2 r       v.x       v.y       theta end1 end2\n[1,] 144.8341 -39.83458 2 0.3890667 0.9212096 0.009959896    2    4\n[2,] 144.8227 -39.82989 2 0.3508991 0.9364133 0.037253656    4   10\n[3,] 144.7963 -39.82087 2 0.3060905 0.9520024 0.024179028   10   19\n[4,] 144.6001 -39.75170 2 0.3791546 0.9253334 0.002089519   19   25\n[5,] 143.4759 -38.58566 2 0.9341507 0.3568788 0.014707205   25  137\n\n\nNext we’ll transform our alpha hull and occurrence points into spatial objects for plotting.\nThe ahull2poly() function converts our alpha hull to one type of spatial object (an sp object), but we’ll use st_as_sf() to convert our result to an sf object (because it’s easier to plot) and set our map projection to 4326. We’ll do the same for our damselfly occurrence points.\n\n# Transform  `ahull` into spatial object, convert to sf, set coordinates\nhull2spatial::ahull2poly(dfly_ahull) |&gt; \n  st_as_sf() |&gt; \n  st_set_crs(st_crs(aus)) -&gt; dfly_sf_ahull\n\n# Convert occurrence points to `sf` for plotting\ndfly_clean |&gt; \n  st_as_sf(coords = c(\"decimalLongitude\", \"decimalLatitude\"), \n           crs = 4326) -&gt; dfly_sf\n\nFinally, we can create our plot!\n\n# Plot the occurrences and alpha hull\nggplot() + \n  geom_sf(data = aus, colour = \"black\", fill = \"white\")  +\n  geom_sf(data = dfly_sf, colour = \"black\", size = 0.5) +  \n  geom_sf(data = dfly_sf_ahull, fill = \"orange\", alpha = 0.5) +\n  coord_sf(xlim=c(142, 152),ylim=c(-32,-44)) +\n  ggtitle(\"Alpha hull\") +\n  labs(x = \"Longtitude (DD)\", y = \"Latitude (DD)\") + \n  theme_bw()\n\n\n\n\n\n\n\n\n\nAlpha hull with filtered observations\nCitizen science data are often excluded from scientific analyses due to poor data quality e.g. rare species can be misidentified by someone who’s not an expert. Although a strict data criteria will reduce the number of data points, we can still compute and plot alpha hulls for the Powdered Flatwing - this is the beauty of them!\nLet’s repeat exactly the same steps as above for generating an alpha hull, but only use a subset of our damselfly observations that comes from specimen data. We can do this by specifying the basisOfRecord with galah_filter().\n\n# Create a vector excluding human observations\ninstitution_only &lt;- c(\"PRESERVED_SPECIMEN\", \"LIVING_SPECIMEN\", \n                   \"MACHINE_OBSERVATION\", \"MATERIAL_SAMPLE\")\n\ngalah_call() |&gt; \n  galah_identify(\"Austroargiolestes calcaris\") |&gt; \n  galah_filter(basisOfRecord == institution_only,\n               profile = \"ALA\") |&gt; \n  galah_select(group = \"basic\") |&gt; \n   atlas_occurrences() -&gt; dfly_specionly\n\nBelow is our alpha hull of our specimen-only damselfly data. You’ll notice that there are two separate hulls in this map! This is another benefit of using an alpha hull over a convex hull. The mathematical constraints of a convex hull mean all points must be contained within a single polygon - this can lead to an over-estimation of a species’ range."
  },
  {
    "objectID": "posts/2022-10-12_alpha-hulls/post.html#a-real-life-example",
    "href": "posts/2022-10-12_alpha-hulls/post.html#a-real-life-example",
    "title": "Convex and alpha hulls for conservation mapping",
    "section": "A real-life example",
    "text": "A real-life example\nAlpha hulls, and their ability to generate multiple hulls when data is sparse, can help us understand how sensitive certain species are to environmental change over time, even when species have few existing observations.\nFor example, Dr. Takach and their team wanted to investigate how the distribution of mammals in the tropical savanna like Mesembriomys gouldii (the Black-Footed Tree Rat) shrink or expand in response to pressures like habitat loss and changing climate. Using alpha hulls, they found that the ecological niche of this species has shrunk due to a loss of suitable habitat over time.\n\n\n\n \n\n\n\n\n\n \n\n\n\n\nA Black-Footed Tree Rat perched on a branch by Colin Trainor CC-BY-NC 4.0\n\nThe published paper didn’t provide a visual of this species’ distribution, so we’ve made a map below with ALA data to show the change in distribution over time:\n\n\nCode\n# Download records\ngalah_call() |&gt; \n  galah_identify(\"Mesembriomys gouldii\") |&gt; \n  galah_filter(profile = \"ALA\") |&gt; \n  galah_select(group = \"basic\") |&gt; \n  atlas_occurrences() -&gt; tree_rat\n\n# Remove duplicates and NAs\ntree_rat |&gt; \n  filter(! duplicated(decimalLongitude) & ! duplicated(decimalLatitude)) |&gt; \n  filter(! is.na(decimalLongitude) & ! is.na(decimalLatitude) ) -&gt; tree_ratclean\n\n# Convert occurrence points to sf for plotting\ntree_ratclean |&gt; \n  st_as_sf(coords = c(\"decimalLongitude\", \"decimalLatitude\"), \n           crs = 4326) -&gt; tree_rat_sf\n\n# Compute alpha hull\ntree_ratclean |&gt; \n  select(decimalLongitude, decimalLatitude) |&gt; \n  ahull(alpha = 2) -&gt; tree_rat_ahull\n\n# Transform `ahull` to `sf`, set projection\nhull2spatial::ahull2poly(tree_rat_ahull) |&gt; \n  st_as_sf() |&gt;\n  st_set_crs(st_crs(aus)) -&gt; tree_rat_sf_ahull\n\n# Convert occurrence points to sf for plotting\ntree_ratclean |&gt; \n  st_as_sf(coords = c(\"decimalLongitude\", \"decimalLatitude\"), \n           crs = 4326) -&gt; tree_rat_sf\n\n# Get map of Australia & set projection\naus &lt;- st_transform(ozmaps::ozmap_country, 4326)\n\n#---\n\n# Download tree rat records after 2000\ngalah_call() |&gt;\n  galah_identify(\"Mesembriomys gouldii\") |&gt;\n  galah_filter(profile = \"ALA\",\n               year &gt;= 2000,) |&gt;\n  galah_select(group = \"basic\") |&gt;\n  atlas_occurrences() -&gt; Rtree_rat\n\n# Remove duplicates & exclude NAs\nRtree_rat |&gt; \n  filter(!duplicated(decimalLongitude) & !duplicated(decimalLatitude)) |&gt; \n  filter(!is.na(decimalLongitude) & !is.na(decimalLatitude) ) -&gt; Rtree_ratclean\n\n# Compute an alpha hull for our specimen only occurrences\nRtree_ratclean |&gt; \n  select(decimalLongitude, decimalLatitude) |&gt; \n  ahull(alpha = 2) -&gt; Rtree_rat_ahull\n\n# Transform `ahull` to sf, set coordinates\nhull2spatial::ahull2poly(Rtree_rat_ahull) |&gt; \n  st_as_sf() |&gt; \n  st_set_crs(st_crs(aus)) -&gt; Rtree_rat_sf_ahull\n\n# Transform occurrence points to sf for plotting \nRtree_ratclean |&gt; \n  st_as_sf(coords = c(\"decimalLongitude\", \"decimalLatitude\"), \n           crs = 4326) -&gt; Rtree_rat_sf\n\n#---\n\n# Nice title\nrat_title &lt;- expression(italic(\"Mesembriomys gouldii \"), \"alpha hulls\")\n\n# Plot!\nggplot() + \n  geom_sf(data = aus, colour = \"black\", fill = \"white\")  +\n  geom_sf(data = tree_rat_sf_ahull, aes(fill = \"chartreuse3\") ,alpha = 0.5, colour = \"black\", position = \"identity\") +\n    geom_sf(data = Rtree_rat_sf_ahull, aes(fill = \"blueviolet\"), alpha = 0.5, colour = \"black\", position = \"identity\") +\n  scale_fill_identity(guide = \"legend\",\n                      name = \"Record date ranges\",\n                      labels = c('2000 Onwards', 'All Records')) +\n  guides(colour = guide_legend(override.aes = list(alpha = 0.1))) +\n  coord_sf(xlim=c(125, 145),ylim=c(-20,-10)) +\n  ggtitle(rat_title) +\n  labs(x = \"Longtitude (DD)\", y = \"Latitude (DD)\") + \n  theme_bw() +\n  theme(legend.position = \"bottom\") -&gt; combinedtree_rat_ahull_p"
  },
  {
    "objectID": "posts/2022-10-12_alpha-hulls/post.html#final-thoughts",
    "href": "posts/2022-10-12_alpha-hulls/post.html#final-thoughts",
    "title": "Convex and alpha hulls for conservation mapping",
    "section": "Final thoughts",
    "text": "Final thoughts\nWhile sophisticated tools for modelling species distribution exist, they require a lot of data to make reliable estimates. Convex polygons and alpha hulls are flexible alternatives that can help us understand dynamic changes to distributions of understudied or vulnerable data-deficient species.\n\n\n\n\n\n\nAcknowledgement:\n\n\n\nThe work in this post is part of project titled: Curated biodiversity data for rapid assessment of bushfire impact. This project is funded by the Australian Research Data Commons (ARDC) bushfire data challenges program.\n\n\n\n\nExpand for session info\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.2 (2022-10-31 ucrt)\n os       Windows 10 x64 (build 19044)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  English_Australia.utf8\n ctype    English_Australia.utf8\n tz       Australia/Sydney\n date     2023-03-16\n pandoc   2.19.2 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package       * version date (UTC) lib source\n alphahull     * 2.5     2022-06-16 [1] CRAN (R 4.2.1)\n dplyr         * 1.1.0   2023-01-29 [1] CRAN (R 4.2.2)\n forcats       * 1.0.0   2023-01-29 [1] CRAN (R 4.2.2)\n galah         * 1.5.1   2023-02-21 [1] Github (AtlasOfLivingAustralia/galah@bd43dd2)\n ggplot2       * 3.4.1   2023-02-10 [1] CRAN (R 4.2.2)\n htmltools     * 0.5.4   2022-12-07 [1] CRAN (R 4.2.2)\n hull2spatial  * 0.1.0   2022-10-12 [1] Github (babichmorrowc/hull2spatial@921594f)\n lubridate     * 1.9.2   2023-02-10 [1] CRAN (R 4.2.2)\n ozmaps        * 0.4.5   2021-08-03 [1] CRAN (R 4.2.1)\n pacman        * 0.5.1   2019-03-11 [1] CRAN (R 4.2.1)\n patchwork     * 1.1.2   2022-08-19 [1] CRAN (R 4.2.1)\n purrr         * 1.0.1   2023-01-10 [1] CRAN (R 4.2.2)\n readr         * 2.1.4   2023-02-10 [1] CRAN (R 4.2.2)\n remotes       * 2.4.2   2021-11-30 [1] CRAN (R 4.2.1)\n sessioninfo   * 1.2.2   2021-12-06 [1] CRAN (R 4.2.1)\n sf            * 1.0-9   2022-11-08 [1] CRAN (R 4.2.2)\n sp            * 1.5-0   2022-06-05 [1] CRAN (R 4.2.1)\n stringr       * 1.5.0   2022-12-02 [1] CRAN (R 4.2.2)\n tibble        * 3.1.8   2022-07-22 [1] CRAN (R 4.2.1)\n tidyr         * 1.3.0   2023-01-24 [1] CRAN (R 4.2.2)\n tidyverse     * 2.0.0   2023-02-22 [1] CRAN (R 4.2.2)\n xaringanExtra * 0.7.0   2022-07-16 [1] CRAN (R 4.2.1)\n\n [1] C:/Users/KEL329/R-packages\n [2] C:/Users/KEL329/AppData/Local/Programs/R/R-4.2.2/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2023-01-12_counting-points-in-shapefiles/post.html",
    "href": "posts/2023-01-12_counting-points-in-shapefiles/post.html",
    "title": "Counting points in multipolygon shapefiles for choropleth mapping",
    "section": "",
    "text": "Choropleth maps are an excellent way to visualise differences in variables (eg. number of species observed) across several geographic regions (eg. countries, states, study areas). Often, creating a choropleth map from species observations requires two things:\nHowever, to create a choropleth map of species observations requires us to summarise our points to a single statistic for each polygon of our shapefile. This conversion from points to polygons can sometimes be tricky!\nHere, we show you how to extract and count the number of points inside each polygon of a shapefile to create a choropleth map of the number of species observations per km2 in each suburb of the Australian Capital Territory (ACT)."
  },
  {
    "objectID": "posts/2023-01-12_counting-points-in-shapefiles/post.html#download-data",
    "href": "posts/2023-01-12_counting-points-in-shapefiles/post.html#download-data",
    "title": "Counting points in multipolygon shapefiles for choropleth mapping",
    "section": "Download data",
    "text": "Download data\nFirst we will load the R packages that we need:\n\nlibrary(galah)\nlibrary(here) \nlibrary(rmapshaper) \nlibrary(tidyverse) \nlibrary(sf)\nlibrary(ggtext)\n\n\nDownload shapefile\nNext we will need a shapefile. You can find many shapefiles online from reputable sources. For this example, I’ve downloaded a shapefile of suburb boundaries in the city of Canberra, ACT from the ACT’s open-access map database.\nUsually when you download a shapefile, it is compressed within a zip folder. Save this downloaded zip folder in a local folder inside your current R project. If you need to unzip your folder, you can do so with the following code:\n\nzip_folder &lt;- here(\"folder-name\", \"shapefile-folder-name.zip\")\noutput_dir &lt;- \"folder-name-to-save-unzipped-files\" \nunzip(zip_folder, exdir = output_dir) \n\nNow we load this unzipped shapefile into R. To save space, we’ll remove some complexity from our shapefile polygons with ms_simplify() from the {rmapshaper} package.\nThe actsuburbs shapefile contains both suburb boundaries and “district” boundaries, which can encompass several suburbs. To avoid confusion, we will remove districts using filter(LOC_CLASS != \"District\"). We’ll also use st_make_valid() to make sure any weird invalid geometries in our shapefile are made valid, and therefore plot correctly.\n\nactsuburbs &lt;- st_read(here(\"folder-name\",\n                           \"folder-name-2\",\n                           \"shapefilename.shp\")) |&gt;\n                     ms_simplify(keep = 0.1) |&gt; \n  st_transform(crs = st_crs(\"WGS84\")) |&gt; \n  st_make_valid() |&gt; \n  filter(LOC_CLASS != \"District\")\n\nNow to see if our shapefile plots correctly, we can use geom_sf() (and it looks like it does!)\n\nggplot() +\n  geom_sf(data = actsuburbs) +\n  theme(axis.text.x = element_text(angle = -90, hjust = 0))\n\n\n\n\n\n\nDownload species observations\nNext let’s use the {galah} package to download bird occurrence records from the Atlas of Living Australia (ALA).\nWe can download all Aves (bird) data provided by BirdLife Australia within the ACT by using galah_filter() to narrow our download. We’ll also add ALA’s data profile, or what the ALA calls a set of data quality filters to remove suspicious records, using galah_apply_profile(ALA).\nYou will need to provide a registered email with the ALA using galah_config() before retrieving records.\n\ngalah_config(email = \"your-email@email.com\") \n\n\nbirdocc &lt;- galah_call() |&gt; \n  galah_identify(\"Aves\") |&gt; \n  galah_apply_profile(ALA) |&gt;\n  galah_filter(stateProvince == \"Australian Capital Territory\",\n               dataProviderName == \"BirdLife Australia\") |&gt;  \natlas_occurrences()\n\nbirdocc |&gt; head(8L)\n\n# A tibble: 8 × 8\n  decimalL…¹ decim…² eventDate           scien…³ taxon…⁴ recor…⁵ dataR…⁶ occur…⁷\n       &lt;dbl&gt;   &lt;dbl&gt; &lt;dttm&gt;              &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  \n1      -35.9    149. 2013-10-11 13:00:00 Dacelo… https:… 0d70c8… BirdLi… PRESENT\n2      -35.9    149. 2013-10-11 13:00:00 Hirund… https:… 9fef9b… BirdLi… PRESENT\n3      -35.9    149. 2013-10-11 13:00:00 Corvus… https:… a947cb… BirdLi… PRESENT\n4      -35.9    149. NA                  Acanth… https:… 15e4e5… BirdLi… PRESENT\n5      -35.9    149. NA                  Anthus… https:… ec68b3… BirdLi… PRESENT\n6      -35.9    149. NA                  Platyc… https:… 6290fe… BirdLi… PRESENT\n7      -35.9    149. NA                  Petroc… https:… 795689… BirdLi… PRESENT\n8      -35.9    149. NA                  Rhipid… https:… ac46a9… BirdLi… PRESENT\n# … with abbreviated variable names ¹​decimalLatitude, ²​decimalLongitude,\n#   ³​scientificName, ⁴​taxonConceptID, ⁵​recordID, ⁶​dataResourceName,\n#   ⁷​occurrenceStatus\n\n\n\nFor those unfamiliar with Australian geography, the ACT is located here:"
  },
  {
    "objectID": "posts/2023-01-12_counting-points-in-shapefiles/post.html#count-points-in-each-polygon",
    "href": "posts/2023-01-12_counting-points-in-shapefiles/post.html#count-points-in-each-polygon",
    "title": "Counting points in multipolygon shapefiles for choropleth mapping",
    "section": "Count points in each polygon",
    "text": "Count points in each polygon\nTo prepare our data, we’ll convert each observation into a format suitable for spatial mapping. st_as_sf() transforms each point into an sf spatial object (which plots nicely with {ggplot2}). We’ll also make sure the points are projected to crs = set_crs(\"WGS84\"), the same as our shapefile, so that the points line up correctly.\n\nbird_points_sf &lt;- birdocc |&gt; \n  st_as_sf(coords = c(\"decimalLongitude\", \"decimalLatitude\"), \n  crs = st_crs(\"WGS84\"))\n\nNow we’ll find and count how many points are in each of our suburbs.\nThe st_intersects() function checks whether each point is within, or “intersects”, a specified POLYGON and then marks it as TRUE or FALSE in a matrix. Using st_intersects() in a loop with pmap() allows us to run st_intersects() on each row of a supplied list.\nIn our case, because each row of actsuburbs$geometry corresponds to each suburb, pmap_dbl() recursively checks which points are within each of our ACT suburbs! Adding lengths() around st_intersects() will count the number of rows returned for each suburb list, returning the total number of points that intersect each suburb. 1. We’ve saved this count in a new column bird_count.\n\n\n\n\n\n\nWarning\n\n\n\nThis function takes ~3.5 minutes to run\n\n\n\nact_counts &lt;- actsuburbs |&gt; \n  mutate(bird_count = pmap_dbl(.l = list(x = actsuburbs$geometry),\n                           .f = function(x) {\n                             lengths(st_intersects(x, bird_points_sf))\n                             }))\n\nact_counts |&gt; \n  select(LOC_NAME, bird_count) |&gt; \n  head(8L) # see sample of counts\n\nSimple feature collection with 8 features and 2 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 149.0563 ymin: -35.48032 xmax: 149.2188 ymax: -35.15856\nGeodetic CRS:  WGS 84\n   LOC_NAME bird_count                       geometry\n1     Acton        670 POLYGON ((149.128 -35.28592...\n2   Ainslie        120 POLYGON ((149.1374 -35.2583...\n3    Amaroo         50 POLYGON ((149.1157 -35.1682...\n4    Aranda         38 POLYGON ((149.0876 -35.2551...\n5     Banks          0 POLYGON ((149.1019 -35.4803...\n6    Barton        755 POLYGON ((149.1295 -35.3070...\n7     Beard          0 POLYGON ((149.2156 -35.3407...\n8 Belconnen       1521 POLYGON ((149.0789 -35.2304...\n\n\nShowing the total number of bird observations on a choropleth map can be misleading because areas that are larger might have more records simply because they are large areas! It’s a good idea to standardise your data to avoid this bias. In this case, we will show the number of observations per square kilometer.\nTo do this, we will use sf::st_area() to help us get the area per m2 of our suburbs & convert it to km2 by dividing by 1000, saving this in a new column area_km2. Then we’ll divide our bird_count by area_km2.\n\nact_counts &lt;- act_counts |&gt;\n  rowwise() |&gt; \n  mutate(area_km2 = as.integer(st_area(geometry))/1000,\n         counts_km2 = bird_count/area_km2) |&gt;\n  replace_na(list(counts_km2 = 0))\n\nact_counts |&gt; rmarkdown::paged_table() # final data frame\n\n\n\n  \n\n\n\nIt’s a good idea to check the distribution of our data before we plot so we know what we should expect it to look like. If we check our bird counts, we can notice that our count data is skewed because many regions have lower numbers of observations, and only a few regions have very high numbers of observations.\n\nhist(act_counts$bird_count, main = \"bird_count distribution\")\n\n\n\n\nLog transformation will reduce the skew in our data, ultimately making our final choropleth map easier to interpret. We will handle this when we make our ggplot in the final step!"
  },
  {
    "objectID": "posts/2023-01-12_counting-points-in-shapefiles/post.html#footnotes",
    "href": "posts/2023-01-12_counting-points-in-shapefiles/post.html#footnotes",
    "title": "Counting points in multipolygon shapefiles for choropleth mapping",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nMany thanks to Shandiya Balasubramaniam for suggesting this method, and for many other very helpful edits!↩︎"
  },
  {
    "objectID": "posts/2023-03-14_animated-map/post.html",
    "href": "posts/2023-03-14_animated-map/post.html",
    "title": "Animated species distribution maps with {gifski}",
    "section": "",
    "text": "Each species has a habitat range where it normally lives and can expect to be found over its lifetime. However, individuals of a species rarely stay in the same spot for long periods of time. Just like us, they react to changes in their environment, interactions with other species, and interactions with other individuals.\nAs a result, it can be useful to see how a distribution of a species changes in space and over time. In marine environments, for example, seemingly small changes in temperature, chemicals and light can result in large changes to a species’ distribution.\nHere we will map the distribution of Nudibranchia around Australia each month as an animated map to see how nudibranch distributions change over the year.\nThis post is inspired by Liam Bailey’s cool (and hilarious) Bigfoot distribution map. You can find his code here."
  },
  {
    "objectID": "posts/2023-03-14_animated-map/post.html#occurrence-data",
    "href": "posts/2023-03-14_animated-map/post.html#occurrence-data",
    "title": "Animated species distribution maps with {gifski}",
    "section": "Occurrence data",
    "text": "Occurrence data\nLet’s first download observations of Nudibranchia across Australia.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeft: Doriprismatica atromarginata (diana88jingfung CC-BY-NC 4.0 (Int)) Middle: Ceratosoma amoenum (Erik Schlogl CC-BY-NC 4.0 (Int)) Right: Pteraeolidia ianthina (Jallitt CC-BY-NC 4.0 (Int))\n\nWe’ll load the necessary packages.\n\nlibrary(galah)\nlibrary(tidyverse)\nlibrary(glue)\nlibrary(lubridate)\nlibrary(stars)         # Raster management \nlibrary(ozmaps)        # Australian map\nlibrary(SSDM)          # Linear modelling\nlibrary(sdmpredictors) # Environmental variables \nlibrary(grDevices)     # Colours and fonts\nlibrary(maps)          # Cities for map\nlibrary(tmaptools)     # Create plot ratio\nlibrary(gifski)        # Create GIF\nlibrary(knitr)         # View GIF\n\nNow we will use the {galah} package to download observations of Nudibranchia.\nYou will need to provide a registered email with the ALA to galah_config() before retrieving records.\n\n# Add registered email (register at ala.org.au)\ngalah_config(email = \"your-email@email.com\")\n\n\n# Download observations\nnudibranch_occurrences &lt;- \n  galah_call() |&gt;                               \n  galah_identify(\"Nudibranchia\") |&gt;   \n  galah_filter(country == \"Australia\") |&gt;\n  galah_apply_profile(ALA) |&gt; # ALA's set of data cleaning filters\n  atlas_occurrences()"
  },
  {
    "objectID": "posts/2023-03-14_animated-map/post.html#environmental-variables",
    "href": "posts/2023-03-14_animated-map/post.html#environmental-variables",
    "title": "Animated species distribution maps with {gifski}",
    "section": "Environmental variables",
    "text": "Environmental variables\nNow we will download our environmental variables for our model.\nFor our Nudibranchia model, we will use 4 common marine environmental variables:\n\nSea surface temperature\nSea surface salinity\nDistance to shore\nBathymetry\n\nTo get them, we’ll use load_layers() from the {sdmpredictors} package to download our variables as raster layers (geographic layers that have a value per pixel of our variable). We’ll use the rasterstack argument to combine our layers into one object.\n\n\n\n\n\n\nNote\n\n\n\nThe {sdmpredictors} package has lots of data sets and layers available. Check out their website to learn more.\n\n\n\n# Download variables\nenv &lt;- load_layers(layercodes = c(\"MS_biogeo08_sss_mean_5m\", \n                                  \"MS_biogeo13_sst_mean_5m\", \n                                  \"MS_biogeo05_dist_shore_5m\", \n                                  \"MS_bathy_5m\"), \n                   equalarea = FALSE, \n                   rasterstack = TRUE)\n\nTo prepare variable data for our model, we need to crop the geographical boundaries of our data to include only the coast (and surrounding ocean) of Australia. With the help of the {raster} package, we’ll use extent() to set the outer boundaries and crop() to remove the land.\n\n# Create extent\naus_ext &lt;- raster::extent(100, 165, -45, -10)\n\n# Limit environmental variables\naus_env &lt;- raster::crop(env, aus_ext) \n\n# Check variables \nplot(aus_env)"
  },
  {
    "objectID": "posts/2023-04-03_highlighted-time-series/post.html",
    "href": "posts/2023-04-03_highlighted-time-series/post.html",
    "title": "Make a highlighted time-series plot",
    "section": "",
    "text": "Author\nThai Rushbrook\nOlivia Torresan\nDax Kellie\n\n\nDate\n3 April 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntern Post\n\n\n\n\n\n\nA majority of species observations in the Atlas of Living Australia are collected opportunistically, where people record observations incidentally rather than through an ongoing monitoring program.\nHowever, whether an observation is recorded or not doesn’t just depend on the species. It might be rainy, it might be too hot, an area might be inaccessible; all of these factors can affect whether people make an observation.\nThe COVID-19 pandemic had a major impact on people’s health, behaviour and travel. In Australia, several lockdowns over 2020-2021 imposed restrictions on people’s movements, limiting them to certain activities near their homes. Melbourne experienced the longest continuous lockdown in the world.\nTo what extent did COVID-19 and lockdowns affect the number of species observations people made over that time? Here, we’ll use a highlighted time-series plot to investigate how lockdowns in Melbourne affected the observations of Anatidae (ducks, geese and swans), a taxonomic group frequently seen on walks and outdoor gatherings, compared to previous years.\n\nGet data\nWe’ll start by downloading Anatidae records.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeft: Tadorna (Casarca) tadornoides (Tracey Hinton CC-BY-NC 4.0 (Int)) Middle: Cygnus (Chenopis) atratus (jpshahady CC-BY-NC 4.0 (Int)) Right: Spatula rhynchotis (Annette Green CC-BY-NC 4.0 (Int))\n\nFirst, let’s load some packages:\n\n# Load packages\nlibrary(galah)\nlibrary(tidyverse)\nlibrary(grid)\nlibrary(pilot) # remotes::install_github(\"olihawkins/pilot\")\nlibrary(ggtext)\nlibrary(showtext)\n\nLet’s use the {galah} package to download Anatidae records in Melbourne from years before and during COVID-19.\nSearching with search_all(fields) shows us that {galah} contains Greater Capital City Statistical Areas, which we can use to filter our query.\n\nsearch_all(fields, \"city\")\n\n# A tibble: 1 × 4\n  id      description                                                type  link \n  &lt;chr&gt;   &lt;chr&gt;                                                      &lt;chr&gt; &lt;chr&gt;\n1 cl10929 PSMA ABS Greater Capital City Statistical Areas (2016) AB… laye… http…\n\nsearch_all(fields, \"city\") |&gt; search_values(\"melbourne\")\n\n• Showing values for 'cl10929'.\n\n\n# A tibble: 1 × 2\n  field   category         \n  &lt;chr&gt;   &lt;chr&gt;            \n1 cl10929 GREATER MELBOURNE\n\n\nLet’s build our query to return Anatidae records from GREATER MELBOURNE and use galah_select() to return only the eventDate column.\nYou will need to first provide a registered email with the ALA using galah_config() before retrieving records.\n\n# Add registered email (register at ala.org.au)\ngalah_config(email = \"your-email@email.com\")\n\n\nbirds &lt;-\n  galah_call() |&gt;\n  galah_identify(\"Anatidae\") |&gt;\n  galah_filter(\n    cl10929 == \"GREATER MELBOURNE\",\n    year &gt;= 2017,\n    year &lt;= 2021,\n    basisOfRecord == \"HUMAN_OBSERVATION\"\n  ) |&gt;\n  galah_select(eventDate) |&gt;\n  atlas_occurrences()\n\nbirds |&gt; slice_sample(n = 10)\n\n# A tibble: 10 × 1\n   eventDate          \n   &lt;dttm&gt;             \n 1 2018-09-01 14:00:00\n 2 2019-03-28 13:00:00\n 3 2017-10-23 13:00:00\n 4 2021-04-17 14:00:00\n 5 2018-03-26 13:00:00\n 6 2021-10-16 13:00:00\n 7 2021-08-20 14:00:00\n 8 2019-03-29 13:00:00\n 9 2021-10-30 13:00:00\n10 2020-08-25 14:00:00\n\n\nWe’ll then extract the week and year of each date and count the total observations for each week.\n\nbirds_weekly &lt;- birds |&gt; \n  mutate(date = as_date(eventDate),\n         year = year(eventDate),\n         week = week(eventDate)) |&gt;\n  filter(year &gt; 2016) |&gt; # remove stray 2016 records\n  group_by(year, week) |&gt;\n  summarise(week_obs = n())\n\nbirds_weekly \n\n# A tibble: 265 × 3\n# Groups:   year [5]\n    year  week week_obs\n   &lt;dbl&gt; &lt;dbl&gt;    &lt;int&gt;\n 1  2017     1      647\n 2  2017     2      670\n 3  2017     3      665\n 4  2017     4      790\n 5  2017     5      745\n 6  2017     6      580\n 7  2017     7      659\n 8  2017     8      680\n 9  2017     9      575\n10  2017    10      541\n# … with 255 more rows\n\n\nWe want to compare observations recorded in 2020-2021 to previous years, but because we know that contributions to the ALA have increased each year, comparing raw numbers will be an unequal comparison and bias our results.\nTo avoid this, let’s scale our weekly record counts by the total number of Anatidae observations each year. Doing this let’s us compare proportions rather than raw numbers.\nFirst let’s download the total Anatidae records for each year.\n\nbirds_yearly &lt;- \n  galah_call() |&gt;    \n  galah_identify(\"Anatidae\") |&gt; \n  galah_filter(cl10929 == \"GREATER MELBOURNE\", \n               year &gt;= 2017, year &lt;= 2021) |&gt; \n  galah_group_by(year) |&gt;\n  atlas_counts() |&gt;\n  rename(year_obs = count) |&gt;\n  mutate(year = as.numeric(year)) |&gt;\n  arrange(-desc(year))\n  \nbirds_yearly\n\n# A tibble: 5 × 2\n   year year_obs\n  &lt;dbl&gt;    &lt;int&gt;\n1  2017    37195\n2  2018    48697\n3  2019    47874\n4  2020    48851\n5  2021    57520\n\n\nNow we’ll join birds_yearly with birds_weekly so we can calculate the proportion of records observed each week. We’ll do this by dividing each row’s weekly total by the yearly total.\n\nbirds_prop &lt;- birds_weekly |&gt; \n  left_join(birds_yearly) |&gt; \n  rowwise() |&gt; \n  mutate(prop = week_obs / year_obs,\n         .keep = \"unused\") |&gt; \n  ungroup()\n\nbirds_prop\n\n# A tibble: 265 × 3\n    year  week   prop\n   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1  2017     1 0.0174\n 2  2017     2 0.0180\n 3  2017     3 0.0179\n 4  2017     4 0.0212\n 5  2017     5 0.0200\n 6  2017     6 0.0156\n 7  2017     7 0.0177\n 8  2017     8 0.0183\n 9  2017     9 0.0155\n10  2017    10 0.0145\n# … with 255 more rows\n\n\nTo compare observations in years prior to and during COVID-19, we’ll want to plot two lines:\n\nA baseline of average weekly observation counts in 2017-2019\nA line with weekly observation counts over 2020 and 2021\n\nTo create the average 2017-2019 baseline, let’s calculate the mean proportion of records each week from 2017-2019.\nTo do this, we’ll place our weekly proportions in separate columns using pivot_wider().\n\nbirds_wide &lt;- birds_prop |&gt;\n  pivot_wider(names_from = year, \n              values_from = prop, \n              names_sort = TRUE,\n              names_glue = \"year_{year}\")\n\nbirds_wide\n\n# A tibble: 53 × 6\n    week year_2017 year_2018 year_2019 year_2020 year_2021\n   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1     1    0.0174    0.0174    0.0322    0.0283    0.0218\n 2     2    0.0180    0.0189    0.0295    0.0191    0.0186\n 3     3    0.0179    0.0156    0.0265    0.0251    0.0202\n 4     4    0.0212    0.0153    0.0230    0.0243    0.0175\n 5     5    0.0200    0.0162    0.0185    0.0159    0.0203\n 6     6    0.0156    0.0134    0.0178    0.0175    0.0205\n 7     7    0.0177    0.0177    0.0187    0.0147    0.0157\n 8     8    0.0183    0.0137    0.0198    0.0154    0.0190\n 9     9    0.0155    0.0145    0.0133    0.0128    0.0184\n10    10    0.0145    0.0125    0.0212    0.0117    0.0167\n# … with 43 more rows\n\n\nThen we’ll calculate the mean proportion of observations each week across year_2017, year_2018 and year_2019 columns.\n\nbirds_mean_prop &lt;- birds_wide |&gt;\n  rowwise() |&gt;\n  mutate(\n    mean_2017_19 = mean(c_across(year_2017:year_2019)),\n    .keep = \"unused\"\n    ) |&gt;\n  ungroup()\n\nbirds_mean_prop\n\n# A tibble: 53 × 4\n    week year_2020 year_2021 mean_2017_19\n   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n 1     1    0.0283    0.0218       0.0223\n 2     2    0.0191    0.0186       0.0221\n 3     3    0.0251    0.0202       0.0200\n 4     4    0.0243    0.0175       0.0199\n 5     5    0.0159    0.0203       0.0183\n 6     6    0.0175    0.0205       0.0156\n 7     7    0.0147    0.0157       0.0180\n 8     8    0.0154    0.0190       0.0173\n 9     9    0.0128    0.0184       0.0144\n10    10    0.0117    0.0167       0.0161\n# … with 43 more rows\n\n\nNow we have all the numbers we need for plotting! We just need to reorganise them so that they plot correctly.\nTwo columns in birds_mean_prop contain proportional counts for 2020 and 2021. Although there are 52 weeks in a year, both years extend from weeks 1-53 because neither year started or ended exactly at the end of the week — 2020 ended on a Thursday and 2021 ended on a Friday.\n\nwday(ymd(\"2020-12-31\"), label = TRUE)\n\n[1] Thu\nLevels: Sun &lt; Mon &lt; Tue &lt; Wed &lt; Thu &lt; Fri &lt; Sat\n\nwday(ymd(\"2021-12-31\"), label = TRUE)\n\n[1] Fri\nLevels: Sun &lt; Mon &lt; Tue &lt; Wed &lt; Thu &lt; Fri &lt; Sat\n\n\nThis means that the proportional counts in week 53 of 2020 and week 1 of 2021 are in the same week! We can combine them to better represent the full week’s observations and save the combined count in week 1 of 2021.\n\nbirds_mean_prop &lt;- birds_mean_prop |&gt;\n  rows_update(tibble(week = 1, year_2021 = sum(birds_mean_prop$year_2020[53] + birds_mean_prop$year_2021[1]))) |&gt;\n  rows_update(tibble(week = 53, year_2020 = NA)) # remove 2020's week 53 count\n\nbirds_mean_prop |&gt; slice_head(n = 3)\n\n# A tibble: 3 × 4\n   week year_2020 year_2021 mean_2017_19\n  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1     1    0.0283    0.0305       0.0223\n2     2    0.0191    0.0186       0.0221\n3     3    0.0251    0.0202       0.0200\n\nbirds_mean_prop |&gt; slice_tail(n = 3)\n\n# A tibble: 3 × 4\n   week year_2020 year_2021 mean_2017_19\n  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1    51    0.0190 0.0154         0.0171 \n2    52    0.0212 0.0152         0.0190 \n3    53   NA      0.0000348      0.00717\n\n\nTo allow us to plot proportional counts from Jan 2020 to Dec 2021 as one line (105 weeks total), we’ll separate our 2021 proportional counts, revise 2021 week numbers to start from 53, and place them under our 2020 proportions. That’ll let us plot from week 1 to week 105!\n\n# 2021 record count proportions\nbirds_2021 &lt;- birds_mean_prop |&gt;\n  select(-year_2020) |&gt;\n  rename(prop = year_2021) |&gt;\n  mutate(week = week + 52)\n\nglimpse(birds_2021)\n\nRows: 53\nColumns: 3\n$ week         &lt;dbl&gt; 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 6…\n$ prop         &lt;dbl&gt; 0.03048674, 0.01858484, 0.02016690, 0.01747218, 0.0202538…\n$ mean_2017_19 &lt;dbl&gt; 0.02233243, 0.02214004, 0.01999055, 0.01987294, 0.0182600…\n\n# 2020 + 2021 record count proportions\nbirds_final &lt;- birds_mean_prop |&gt;\n  select(-year_2021) |&gt;\n  drop_na() |&gt;\n  rename(prop = year_2020) |&gt;\n  bind_rows(birds_2021) # attach 2021 to the bottom\n\nglimpse(birds_final)\n\nRows: 105\nColumns: 3\n$ week         &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17…\n$ prop         &lt;dbl&gt; 0.028269636, 0.019078422, 0.025096723, 0.024318847, 0.015…\n$ mean_2017_19 &lt;dbl&gt; 0.02233243, 0.02214004, 0.01999055, 0.01987294, 0.0182600…\n\n\n\n\nLockdowns\nDuring the height of the pandemic, Melbourne had 6 distinct lockdowns. Let’s add their start and end dates to a tibble.\nBecause we want to plot 2020 and 2021 on the same plot, we’ll use ifelse() to make sure our week numbers in 2021 match our week numbers in birds_final.\n\nn_lockdown &lt;- c(1:6)\nstart_date &lt;- c(\"2020-03-31\", \"2020-07-09\",\n                \"2021-02-13\", \"2021-05-28\",\n                \"2021-07-16\", \"2021-08-05\")\nend_date &lt;- c(\"2020-05-12\", \"2020-10-27\",\n              \"2021-02-17\", \"2021-06-10\",\n              \"2021-07-27\", \"2021-10-21\")\n\nlockdowns &lt;- tibble(n_lockdown, start_date, end_date) |&gt;\n  mutate(\n    n_days = as_date(ymd(end_date)) - as_date(ymd(start_date)),\n    week_start = ifelse(year(start_date) == 2020, \n                        week(start_date), week(start_date) + 52),\n    week_end = ifelse(year(end_date) == 2020, \n                      week(end_date), week(end_date) + 52),\n    )\nlockdowns \n\n# A tibble: 6 × 6\n  n_lockdown start_date end_date   n_days   week_start week_end\n       &lt;int&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;drtn&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1          1 2020-03-31 2020-05-12  42 days         13       19\n2          2 2020-07-09 2020-10-27 110 days         28       43\n3          3 2021-02-13 2021-02-17   4 days         59       59\n4          4 2021-05-28 2021-06-10  13 days         74       75\n5          5 2021-07-16 2021-07-27  11 days         81       82\n6          6 2021-08-05 2021-10-21  77 days         83       94\n\n\n\n\nMake plot\nTo help us see the components of our final plot more clearly, let’s construct our visualisation step-by-step.\nFirst, we’ll add our lockdown dates as highlighted rectangular blocks. To do this we can use geom_rect(), setting the xmin and xmax values to our week_start and week_end columns in lockdowns. We’ll make the rectangle spread across the entire plot by setting ymax = Inf and ymin = 0.\nWe’ll also set our fill inside of aes() and define its value within scale_fill_manual() which will allow us to add the lockdown colour and label to its own legend.\n\np1 &lt;- ggplot() +\n  geom_rect(data = lockdowns,\n            aes(xmin = week_start,\n                xmax = week_end,\n                fill = \"Lockdown\"),\n            ymin = 0,\n            ymax = Inf,\n            alpha=0.2) +\n  scale_fill_manual(\n    values = c(\"Lockdown\" = pilot_color(\"yellow\")))\np1\n\n\n\n\n\n\n\n\nNext we’ll add our proportional species observation counts as lines. We can define their colours and edit the legend and axis labels, too.\n\np2 &lt;- p1 +\n  # add lines\n  geom_line(data = birds_final, \n            aes(x = week, y = prop, \n            color = \"2020-21 Records\"), \n            linewidth = 1) + \n  geom_line(data = birds_final, \n            aes(x = week, y = mean_2017_19, \n            color = \"2017-19 Average\"),\n            linetype = \"twodash\", \n            linewidth = 0.8) + \n  # add fill\n  geom_area(data = birds_final, \n            aes(x = week, y = prop),\n            fill=pilot_color(\"blue\"), \n            alpha=0.3) + \n  scale_color_manual(values = c(pilot_color(\"orange\"),\n                                pilot_color(\"blue\")), \n                     labels = c(\"2017-19 (average)\", \n                                \"2020-21\")) +\n  guides(fill = guide_legend(title = \"\"), \n         color = guide_legend(title = \"Year\")) +\n  labs(y = \"Proportion of year's total observations\",\n       x = \"Month\",\n       title = \"Anatidae observations in Melbourne prior to & during COVID-19\")\np2\n\n\n\n\n\n\n\n\nThe plot above is enough to see everything we need to see from our data. You could stop here if you wished, but we’ve gone ahead and made a more refined visualisation with nice fonts, axis scales, axis labels and titles!\n\n\nCode\n# add fonts\nfont_add_google(\"Montserrat\", family = \"mont\")\nfont_add_google(\"Hind\", family = \"hind\")  \nshowtext_auto(enable = TRUE)\n\np2 + \n  # make axis scales understandable\n  scale_y_continuous(expand = c(0, 0),\n                     limits = c(0, 0.035),\n                     labels = scales::percent_format()) +\n  scale_x_continuous(expand = c(0, 0),\n                     limits = c(1, 105),\n                     breaks = c(1, 14, 27, 40, 52, 65, 78, 91),\n                     labels = c(\"Jan\", \"Apr\", \"Jul\", \"Oct\", \"Jan\", \"Apr\", \"Jul\", \"Oct\")) +\n  # add year x axis labels\n  coord_cartesian(clip = \"off\") +\n  annotate_pilot(label = \"2020\", x = 27, y = 0, \n                 alpha = 0.7, vjust = 3.8,size = 10) +\n  annotate_pilot(label = \"2021\", x = 78, y = 0, \n                 alpha = 0.7, vjust = 3.8, size = 10) +\n  labs(title = \"*Anatidae* observations in Melbourne prior to & during COVID-19\") +\n  theme_pilot(grid = \"\",\n              axes = \"bl\") +\n  theme(axis.title.x = element_text(size = 23, vjust = -1.3),\n        axis.title.y = element_text(size = 23),\n        axis.text.x = element_text(size = 20),\n        axis.text.y = element_text(size = 20),\n        axis.line = element_line(linewidth = 0.5),\n        legend.text = element_text(size = 23),\n        legend.title = element_text(size = 20),\n        plot.caption = element_text(size = 18),\n        text = element_text(family = \"hind\"),\n        plot.title = element_markdown(family = \"mont\", size = 31),\n        plot.subtitle = element_markdown(family = \"mont\", size = 28))\n\n\n\n\n\n\n\n\n\nNow that we have our final plot, we can see a few interesting trends:\n\nIn the first lockdown (soon after COVID-19 arrived in Australia), species observations were lower than the 2017-2019 average.\nIn the 2 longest lockdowns, species observations were higher than the 2017-2019 average.\nIn the last half of all lockdowns except the first lockdown, observations increased.\n\nAre these trends that you expected to see?\nIt’s impossible to make any claims of why these trends emerged from our data visualisation alone, but we can speculate (for fun!)\nWere people making fewer observations in the first lockdown because they were preoccupied with all the other priorities of settling into new working-from-home routines? Did people make more observations at the tail end of lockdowns because they were seeking relief from being inside by spending more time by natural ponds and lakes?\nSome evidence from the US found more people were using natural spaces during COVID-19, and time in these spaces lowered depression and anxiety. A New Zealand study found similar results.\n\n\nFinal thoughts\nThis post has detailed how you can use ALA data to explore relationships between record counts and events. Although we can’t make any causal claims from what we see in our plot, making a time-series is a nice way to do some exploratory analysis on a lot of data!\n\n\nExpand for session info\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.2 (2022-10-31 ucrt)\n os       Windows 10 x64 (build 19044)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  English_Australia.utf8\n ctype    English_Australia.utf8\n tz       Australia/Sydney\n date     2023-04-04\n pandoc   2.19.2 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n dplyr       * 1.1.0   2023-01-29 [1] CRAN (R 4.2.2)\n forcats     * 1.0.0   2023-01-29 [1] CRAN (R 4.2.2)\n galah       * 1.5.2   2023-03-20 [1] Github (AtlasOfLivingAustralia/galah@1b35520)\n ggplot2     * 3.4.1   2023-02-10 [1] CRAN (R 4.2.2)\n ggtext      * 0.1.2   2022-09-16 [1] CRAN (R 4.2.2)\n htmltools   * 0.5.4   2022-12-07 [1] CRAN (R 4.2.2)\n lubridate   * 1.9.2   2023-02-10 [1] CRAN (R 4.2.2)\n pilot       * 4.0.0   2022-07-13 [1] Github (olihawkins/pilot@f08cc16)\n purrr       * 1.0.1   2023-01-10 [1] CRAN (R 4.2.2)\n readr       * 2.1.4   2023-02-10 [1] CRAN (R 4.2.2)\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.2.1)\n showtext    * 0.9-5   2022-02-09 [1] CRAN (R 4.2.1)\n showtextdb  * 3.0     2020-06-04 [1] CRAN (R 4.2.1)\n stringr     * 1.5.0   2022-12-02 [1] CRAN (R 4.2.2)\n sysfonts    * 0.8.8   2022-03-13 [1] CRAN (R 4.2.1)\n tibble      * 3.1.8   2022-07-22 [1] CRAN (R 4.2.1)\n tidyr       * 1.3.0   2023-01-24 [1] CRAN (R 4.2.2)\n tidyverse   * 2.0.0   2023-02-22 [1] CRAN (R 4.2.2)\n\n [1] C:/Users/KEL329/R-packages\n [2] C:/Users/KEL329/AppData/Local/Programs/R/R-4.2.2/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2023-04-11_quantifying-species-range/post.html",
    "href": "posts/2023-04-11_quantifying-species-range/post.html",
    "title": "Quantifying species range and overlap with fire-burned areas using concave hulls",
    "section": "",
    "text": "Author\nFonti Kar\nMargot Schneider\n\n\nDate\n11 April 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe 2019/2020 Australian bushfires had a devastating impact on the natural landscape, threatening our native biodiversity. More than ever, decision makers need curated, open access biodiversity data to help respond effectively to future bushfires.\nOur team at the Atlas of Living Australia (ALA) has been working with Invertebrates Australia and CSIRO National Research Collections team to collate biodiversity datasets that can be used for off-the-shelf bushfire assessments. The two datasets contain data on Australian taxonomic groups that are often overlooked and severely affected during bushfires: invertebrates (insects, molluscs, spiders) and vascular plants.\n\nWe are thrilled to announce that these datasets are available from CSIRO’s data access portal!\n\nThis post expands on our last post about using convex and alpha hulls to visualise distributions of data-deficient species.\nHere, we show you how to compute a new form of spatial polygon — a concave hull — and use it to represent a species’ range and to calculate the overlap with fire-burned areas (range overlap). Unlike convex hulls, concave hulls have the added flexibility to adjust their tightness to the data (or concavity). This flexibility allows more accurate estimation of species ranges, making it a useful approach to rapidly assess how natural disasters like bush fires affected biodiversity.\n\nDownload data\nFirst we will load the R packages we need:\n\n# install.packages(\"pacman\")\npacman::p_load(tidyverse, here, rmapshaper, sf, ggpointdensity, viridis, ozmaps, concaveman, cowplot, patchwork)\n\nNext, we will go to the Data Access Portal to download the invertebrate and vascular plant datasets.\nClick on the Files tab (under the main title), then the Download button (in the top right corner), and select Download all files as Zip archive. Save this zip file in a local folder inside your current R project and be sure to unzip it.\nNow we can read the curated datasets into R:\n\n# Invertebrates data\ninverts &lt;- read_csv(here(\"your_directory_name\", \"invertebrate.data.03.2023.csv\"))\n\n# Vascular plants data\nvplants &lt;- read_csv(here(\"your_directory_name\", \"vascularplant.data.03.2023.csv\"))  |&gt; \n  rename(latitude = latitude_used, # Rename coordinate variables for consistency\n         longitude = longitude_used)\n\n\n\nOverview of data\nBoth datasets are based on studies that investigated the impact of the Black Summer bushfires and are designed to support future modelling and impact assessments. The invertebrate dataset spans across Australia, whereas the vascular plant dataset is restricted to South-Eastern Australia and contains only species where more than 50% of their range was affected by the 2019/2020 fires.\n Summary of Invertebrate and Vascular Plant Data\n\n\n\n\n\n\n  \n    \n    \n      Taxonomic Group\n      Classes\n      Families\n      Species\n      Records\n    \n  \n  \n    Invertebrates\n46\n2,044\n44,146\n300,987\n    Vascular Plants\n7\n76\n896\n41,572\n  \n  \n  \n\n\n\n\nA total of 44,146 invertebrate species and 896 species of vascular plants are represented in these datasets. Below, we’ve attempted to show the geographic range of these data. So much data makes it challenging to visualise all data points and concave hulls at once. As such, we created the concave hull maps (left) below by randomly selecting one invertebrate species from each class and one plant species from each family.\n\n\nCode\n# Identify species that have more than 4 observations \nmore_than_4_obs &lt;- inverts |&gt; \n  group_by(scientific_name) |&gt; \n  summarise(n_obs = n()) |&gt; \n  filter(n_obs &gt; 4) |&gt; \n  pull(scientific_name)\n\n# Subset species with more than 4 observations and appear on mainland Australia + Tasmania\ninverts_subset &lt;- inverts |&gt;\n  filter(scientific_name %in% more_than_4_obs) |&gt; \n  filter(latitude &lt; -10, latitude &gt;= -45,\n         longitude &gt;= 113, longitude &lt;= 155) |&gt; \n  select(scientific_name:family, longitude, latitude)\n\n# Nest occurrence data\ninverts_nest &lt;- inverts_subset |&gt; \n  nest(coords = c(longitude, latitude))\n\n# Subset a random species from each class \nset.seed(123)  # Set seed so we all get the same results\nsubset &lt;- inverts_nest |&gt; \n  group_by(class) |&gt; \n  slice_sample(n = 1) \n\n# Convert coordinates into sf object and compute concave hulls as list columns.\nsubset_concave &lt;- subset |&gt;\n    mutate(points_sf = map(.x = coords,\n                           ~ st_as_sf(.x, coords = c(\"longitude\", \"latitude\"),\n                                      crs = 4326)), \n           concave_sf = map(points_sf,\n                            ~ concaveman(.x)))\n\n# Unnest the concave hull list column\nsubset_concave &lt;- subset_concave |&gt; \n  select(scientific_name:family, concave_sf) |&gt; \n  unnest(cols = c(concave_sf)) |&gt; \n  ungroup() |&gt; \n  st_sf(crs = 4326) \n\n# Retrieve Australia polygon\naus &lt;- st_transform(ozmap_country, 4326)\n\n# Plotting spatial distributions\ninverts_concave &lt;- ggplot() + \n  geom_sf(data = aus, colour = \"black\", fill = NA) +\n  geom_sf(data = subset_concave, fill = \"#609966\", alpha = 0.2, lwd = 0) +\n  coord_sf(xlim = c(110, 155)) +\n  theme_void() \n\n# Create plot showing overlapping points\ninverts_points_map &lt;- ggplot() +\n  geom_pointdensity(data = inverts_subset,\n                    mapping = aes(x = longitude,\n                                  y = latitude)) +\n  geom_sf(data = aus, colour = \"white\", fill = NA) +  \n  scale_color_viridis(option = \"E\", begin = 0.1) +\n  coord_sf(xlim = c(110, 155)) +\n  guides(alpha = \"none\",\n         colour = guide_colorbar(title = \"Number of \\noverlapping points\")) +\n  theme_void() +\n  theme(legend.position = \"bottom\",\n        legend.margin = margin(0, 0, 0, 0),\n        legend.box.margin = margin(0, 0, 0, 0),\n        legend.justification = \"left\"\n        )\n\ninverts_concave + inverts_points_map + plot_annotation(title = \"Invertebrate Dataset\") \n\n\n\n\n\n\n\n\n\n\n\nCode\n# Identify species that have more than 4 observations \nmore_than_4_obs_plants &lt;- vplants |&gt; \n  group_by(scientific_name) |&gt; \n  summarise(n_obs = n()) |&gt; \n  filter(n_obs &gt; 4) |&gt; \n  pull(scientific_name)\n\n# Subset species with more than 4 observations and appear on mainland Australia + Tasmaina\nvplant_subset &lt;- vplants |&gt;\n  filter(scientific_name %in% more_than_4_obs_plants) |&gt; \n  filter(latitude &lt; -10, latitude &gt;= -45,\n         longitude &gt;= 113, longitude &lt;= 155) |&gt; \n  select(species, class:genus, longitude, latitude) \n\n# Nest occurrence data\nvplant_nest &lt;- vplant_subset |&gt; \n   nest(coords = c(longitude, latitude))\n\n# Subset a random species from each family \nset.seed(123)  # Set seed so we all get the same results\nplant_subset &lt;- vplant_nest |&gt; \n  group_by(family) |&gt; \n  slice_sample(n = 1) \n\n# Compute concave hulls\npl_subset_concave &lt;- plant_subset |&gt;\n    mutate(points_sf = map(.x = coords,\n                           ~ st_as_sf(.x, coords = c(\"longitude\", \"latitude\"),\n                                      crs = 4326)), \n           concave_sf = map(points_sf,\n                            ~ concaveman(.x)))\n\n# Unnest the data\npl_subset_concave &lt;- pl_subset_concave |&gt; \n  select(species:family, concave_sf) |&gt; \n  unnest(cols = c(concave_sf)) |&gt; \n  st_as_sf(crs = 4326) \n\n# Plotting spatial distributions\nplant_concave &lt;- ggplot() + \n  geom_sf(data = aus, colour = \"black\", fill = NA) +\n  geom_sf(data = pl_subset_concave, fill = \"#609966\", colour = NA, alpha = 0.15, lwd = 0) + \n  coord_sf(xlim = c(140, 158),\n           ylim = c(-23, -43)) +\n  theme_void()\n\n# Create plot showing overlapping points\nplants_points_map &lt;- ggplot() +\n  geom_pointdensity(data = vplant_subset,\n                    mapping = aes(x = longitude,\n                                  y = latitude)) +\n  geom_sf(data = aus, colour = \"black\", fill = NA) +  \n  scale_color_viridis(option = \"E\", begin = 0.1) +\n  coord_sf(xlim = c(140, 158),\n           ylim = c(-23, -43)) +\n  guides(alpha = \"none\",\n         colour = guide_colorbar(title = \"Number of \\noverlapping points\")) +\n  theme_void() +\n  theme(legend.position = \"bottom\",\n        legend.margin = margin(0, 0, 0, 0),\n        legend.box.margin = margin(0, 0, 0, 0),\n        legend.justification = \"left\"\n        )\n  \nplant_concave + plants_points_map + plot_annotation(title = \"Vascular Plant Dataset\")\n\n\n\n\n\n\n\nPre-cleaning\nLet’s use these datasets to calculate concave hulls and range overlaps with burned regions. One benefit of using these curated datasets is that they do not contain any duplicates or missing values. This makes data cleaning an easier job!\nHowever, there are still a few steps we need to do before computing concave hulls:\n\nRemove data-deficient species\nFirst, we need to filter out any data-deficient species with fewer than 4 data points because concave hulls are best estimated with at least 4 data points. To do this, we’ll calculate the number of observations for each species, then identify which ones have more than 4 records. Using this list of species, we can extract their data.\n\nmore_than_4_obs &lt;- inverts |&gt; \n  group_by(scientific_name) |&gt; \n  summarise(n_obs = n()) |&gt; \n  filter(n_obs &gt; 4) |&gt; \n  pull(scientific_name)\n\nmore_than_4_obs |&gt; head()\n\n[1] \"Aaaaba fossicollis\"    \"Aaaaba nodosus\"        \"Aades cultratus\"      \n[4] \"Aades griseatus\"       \"Aaroniella rawlingsi\"  \"Abantiades latipennis\"\n\ninverts_subset &lt;- inverts |&gt;\n  filter(scientific_name %in% more_than_4_obs)\n\n\n\nRestrict data to mainland Australia and Tasmania\nThe invertebrate dataset includes records on offshore islands which can drastically skew the shape of a species’ concave hull. For the purpose of this post, we will filter these out and only use records that occur on mainland Australia and Tasmania.\n\nsubset_mainland &lt;- inverts_subset |&gt; \n  filter(latitude &lt; -10, latitude &gt;= -45,\n         longitude &gt;= 113, longitude &lt;= 155) |&gt; \n  select(scientific_name:family, longitude, latitude)\n\n\n\nList columns and nesting occurrence data\nFor the majority of calculations in this post, we will be making use of list columns, a very useful data structure for iterative analyses. You can think of a list column as mini data frames nested within a column by a grouping variable.\nIn this case we are nesting the coordinate data by species, which will make operations at the species level more efficient.\n\ninverts_nest &lt;- subset_mainland |&gt; \n  nest(coords = c(longitude, latitude))\n\ninverts_nest |&gt; \n  print(n = 6)\n\n# A tibble: 16,347 × 4\n  scientific_name       class   family        coords           \n  &lt;chr&gt;                 &lt;chr&gt;   &lt;chr&gt;         &lt;list&gt;           \n1 Aaaaba fossicollis    Insecta Buprestidae   &lt;tibble [12 × 2]&gt;\n2 Aaaaba nodosus        Insecta Buprestidae   &lt;tibble [16 × 2]&gt;\n3 Aades cultratus       Insecta Curculionidae &lt;tibble [20 × 2]&gt;\n4 Aades griseatus       Insecta Curculionidae &lt;tibble [5 × 2]&gt; \n5 Aaroniella rawlingsi  Insecta Philotarsidae &lt;tibble [35 × 2]&gt;\n6 Abantiades latipennis Insecta Hepialidae    &lt;tibble [10 × 2]&gt;\n# … with 16,341 more rows\n\n\nYou can inspect elements in the list column like this:\n\ninverts_nest |&gt; \n  pluck(\"coords\", 1) |&gt;  # 1 refers to the first element of the list column\n  print(n = 6)\n\n# A tibble: 12 × 2\n  longitude latitude\n      &lt;dbl&gt;    &lt;dbl&gt;\n1      153.    -28.4\n2      151.    -33.8\n3      153.    -31.0\n4      146.    -37.8\n5      153.    -30.3\n6      151.    -33.8\n# … with 6 more rows\n\n\nThe biggest change with working with list columns is that you have to iterate across each element. To do this, we will use various functions from the {purrr} package for the next calculation steps.\n\n\n\nSpecies range overlap with fire-burned areas\n\nGet fire layer\nShapefiles for the 2019-2020 fire season are available through the National Indicative Aggregated Fire Extent Dataset from the Department of Climate Change, Energy, the Environment and Water.\nClick on Download Data (near the top of the page), then click on NIAFED_v20200623.zip to download the zip file. Save the zip file in your project folder and unzip to retrieve the shapefiles.\nNow we can read the shapefile into R and set the projection to EPSG:4326. To speed up the computation of concave hulls and overlaps, we will remove elevation values and simplify the edges of the fire POLYGON.\n\nfire &lt;- st_read(here(\"your_directory_name\", \"NIAFED_20190701_20200622_v20200623.shp\")) |&gt; \n  st_transform(crs = 4326) |&gt; \n  st_zm() |&gt;  # Remove Z or M values\n  ms_simplify() # Simplify edges of the fire layer\n\n\n\nChoose taxonomic group\nWhile it is possible to calculate range overlap with burned areas for all species in the dataset, it can take a lot of memory and processing time. Instead, we will demonstrate our workflow with — the bee family (Apidae) — as a working example.\n\n# Filter invertebrate data to Apidae\nbees &lt;- inverts_nest |&gt; \n  filter(family == \"Apidae\") \n\n\n\nCompute concave hull\nIn the next steps, we will work through the coordinate data for each species iteratively using map.\nWe will transform each species’ coordinates into an sf object using st_as_sf(), then compute the concave hulls with the concaveman() function. You can adjust the tightness of the hull boundary around a set of points using the concavity argument - the smaller the value, the tighter the hull. We’ve wrapped mutate() around these steps so the output will become variables in our tibble.\n\nbees_concave &lt;- bees |&gt;\n    mutate(points_sf = map(.x = coords,\n                           ~ st_as_sf(.x, coords = c(\"longitude\", \"latitude\"), # Set as sf object\n                                      crs = 4326) |&gt; \n                             rename(points = geometry)), # Rename geometry variable to something intuitive\n           concave_sf = map(points_sf,\n                            ~ concaveman(.x, concavity = 2) |&gt; # Compute concave hulls\n                              rename(concave = polygons)) # Rename geometry variable to something intuitive\n           ) \n\nbees_concave |&gt; print(n = 6)\n\n# A tibble: 54 × 6\n  scientific_name                   class   family coords   points_sf    conca…¹\n  &lt;chr&gt;                             &lt;chr&gt;   &lt;chr&gt;  &lt;list&gt;   &lt;list&gt;       &lt;list&gt; \n1 Amegilla (Asaropoda) bombiformis  Insecta Apidae &lt;tibble&gt; &lt;sf&gt;         &lt;sf&gt;   \n2 Amegilla (Asaropoda) calva        Insecta Apidae &lt;tibble&gt; &lt;sf [5 × 1]&gt; &lt;sf&gt;   \n3 Amegilla (Asaropoda) dawsoni      Insecta Apidae &lt;tibble&gt; &lt;sf&gt;         &lt;sf&gt;   \n4 Amegilla (Asaropoda) paracalva    Insecta Apidae &lt;tibble&gt; &lt;sf [5 × 1]&gt; &lt;sf&gt;   \n5 Amegilla (Asaropoda) rhodoscymna  Insecta Apidae &lt;tibble&gt; &lt;sf&gt;         &lt;sf&gt;   \n6 Amegilla (Notomegilla) aeruginosa Insecta Apidae &lt;tibble&gt; &lt;sf&gt;         &lt;sf&gt;   \n# … with 48 more rows, and abbreviated variable name ¹​concave_sf\n\n\n\n\nCompute range overlap and descriptive statistics\nTo compute range overlaps, we need to set our geometry calculations to assume the Earth is flat and not spherical by setting sf_use_s2(FALSE). This may be a limitation of the method but it still gives us a good approximation.\n\n# Disable spherical geometry\nsf_use_s2(FALSE) \n\nUsing st_intersection(), we can identify the overlap between each species’ concave hull with fire-burned areas. We can then use st_area() to calculate the area (m2) of overlap and convert it into a percentage of each species’ original range so that all species are comparable.\nUsing possibly() with our map() functions allows the calculations to return NA for species that did not overlap with burned areas. Once calculations are complete, we will un-nest the variables: overlap_area and percent_overlap, so they appear as regular columns in our tibble.\n\n# Calculate range overlap\nbees_overlap &lt;- bees_concave |&gt;\n  mutate(\n    overlap_sf = map(concave_sf,\n                     possibly(~ st_intersection(fire, .x) |&gt; select(-Id) |&gt; rename(overlap = geometry))), # Identify overlap\n    overlap_area = map(overlap_sf,\n                       possibly( ~ st_area(.x))), # Calculate area\n    percent_overlap = map2(.x = overlap_area,\n                           .y = concave_sf,\n                           possibly( ~ (.x / st_area(.y)) * 100))) |&gt; # Calculate percentage\n  unnest(cols = c(overlap_area, percent_overlap)) # Unnest the area and percentage columns\n    \nbees_overlap |&gt; print(n = 6)\n\n# A tibble: 28 × 9\n  scientific_name  class family coords   point…¹ conca…² overl…³ overl…⁴ perce…⁵\n  &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;  &lt;list&gt;   &lt;list&gt;  &lt;list&gt;  &lt;list&gt;    [m^2]     [1]\n1 Amegilla (Asaro… Inse… Apidae &lt;tibble&gt; &lt;sf&gt;    &lt;sf&gt;    &lt;sf&gt;    2.92e10   5.50 \n2 Amegilla (Asaro… Inse… Apidae &lt;tibble&gt; &lt;sf&gt;    &lt;sf&gt;    &lt;sf&gt;    3.18e 8   0.138\n3 Amegilla (Asaro… Inse… Apidae &lt;tibble&gt; &lt;sf&gt;    &lt;sf&gt;    &lt;sf&gt;    2.83e 8   0.277\n4 Amegilla (Zonam… Inse… Apidae &lt;tibble&gt; &lt;sf&gt;    &lt;sf&gt;    &lt;sf&gt;    1.63e10   6.63 \n5 Amegilla (Zonam… Inse… Apidae &lt;tibble&gt; &lt;sf&gt;    &lt;sf&gt;    &lt;sf&gt;    1.06e 7  15.4  \n6 Amegilla (Zonam… Inse… Apidae &lt;tibble&gt; &lt;sf&gt;    &lt;sf&gt;    &lt;sf&gt;    1.10e11   3.08 \n# … with 22 more rows, and abbreviated variable names ¹​points_sf, ²​concave_sf,\n#   ³​overlap_sf, ⁴​overlap_area, ⁵​percent_overlap\n\n\n\n\nRank species by fire impact\nNext, we will take the top 3 species with the highest percentage range overlap with fire-burned areas (percent_overlap) for our data visualisation. The top 3 species include a stingless bee, a reed bee, and a carpenter bee.\n\ntop3 &lt;- bees_overlap |&gt; \n  slice_max(order_by = percent_overlap,\n            n = 3) \n\ntop3\n\n# A tibble: 3 × 9\n  scientific_name  class family coords   point…¹ conca…² overl…³ overl…⁴ perce…⁵\n  &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;  &lt;list&gt;   &lt;list&gt;  &lt;list&gt;  &lt;list&gt;    [m^2]     [1]\n1 Austroplebeia c… Inse… Apidae &lt;tibble&gt; &lt;sf&gt;    &lt;sf&gt;    &lt;sf&gt;    5.48e 8    37.1\n2 Exoneura (Exone… Inse… Apidae &lt;tibble&gt; &lt;sf&gt;    &lt;sf&gt;    &lt;sf&gt;    2.08e10    28.2\n3 Xylocopa (Kopto… Inse… Apidae &lt;tibble&gt; &lt;sf&gt;    &lt;sf&gt;    &lt;sf&gt;    9.92e 9    27.1\n# … with abbreviated variable names ¹​points_sf, ²​concave_sf, ³​overlap_sf,\n#   ⁴​overlap_area, ⁵​percent_overlap\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeft: Austroplebeia (Geoffbyrne CC-BY-NC 4.0), Middle: Exoneura (Campbell Matt CC BY-NC 4.0), Right: Xylocopa (koptortosoma) aruana (zig madycki CC BY 3.0)\n\n\n\n\nMake map\nWe will now select the variables we need and un-nest the relevant ones (points_sf, concave_sf, overlap_sf) for plotting - this gives us everything we need to create our maps!\n\nbee_map_data &lt;- top3 |&gt; \n  select(scientific_name, points_sf, concave_sf, overlap_sf) |&gt; \n  unnest(cols = c(points_sf, concave_sf, overlap_sf)) \n\nbee_map_data |&gt; print(n = 6)\n\n# A tibble: 31 × 4\n  scientific_name                points                                  concave\n  &lt;chr&gt;                     &lt;POINT [°]&gt;                            &lt;POLYGON [°]&gt;\n1 Austroplebeia cassiae (143.45 -14.08) ((143.27 -14.08, 143.28 -14.05, 142.92 …\n2 Austroplebeia cassiae (143.27 -14.08) ((143.27 -14.08, 143.28 -14.05, 142.92 …\n3 Austroplebeia cassiae  (143.32 -14.1) ((143.27 -14.08, 143.28 -14.05, 142.92 …\n4 Austroplebeia cassiae (145.13 -15.67) ((143.27 -14.08, 143.28 -14.05, 142.92 …\n5 Austroplebeia cassiae (143.28 -14.05) ((143.27 -14.08, 143.28 -14.05, 142.92 …\n6 Austroplebeia cassiae (142.92 -13.42) ((143.27 -14.08, 143.28 -14.05, 142.92 …\n# … with 25 more rows, and 1 more variable: overlap &lt;MULTIPOLYGON [°]&gt;\n\n\n\nCreate the base map\nLet’s create our base map with the outline of Australia and the fire-burned area. You can see a majority of burnt areas are located in Northern Australia and the South-East coast.\n\n# Retrieve Australia polygon\naus &lt;- st_transform(ozmap_country, 4326)\n\nbase_map &lt;- ggplot() + \n  geom_sf(data = aus, colour = \"black\", fill = \"white\") +\n  geom_sf(data = fire, fill = \"#FEC3A6\", colour = \"#FEC3A6\") + \n  theme_void()\n\n\n\n\n\n\n\n\n\n\nAdd species range overlap\nNow we can add the range overlap of our three bee species. We use geometry within aes to specify which variable from bee_map_data we want to plot.\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate inset map\nThe navy blue hull in the top right corner of Australia is very small (Austroplebeia cassiae), so we will make an enlarged inset map so we can see it clearer.\n\ninset &lt;- main_map + \n   coord_sf(\n    xlim = c(142.8 , 145.3),\n    ylim = c(-15.9, -13.25),\n    expand = FALSE\n            ) + \n   theme_void() +\n   theme(legend.position = \"none\",\n         panel.border = element_rect(colour = \"black\", fill = NA, linewidth = 0.2))\n\n\n\n\n\n\n\n\n\n\n\n\nWe’ll also draw a box around the area of interest in the enlarged map.\n\nmain_bbox &lt;- main_map + \n   geom_rect(aes(xmin = 142.8, xmax = 145.3,\n             ymin = -15.9, ymax = -13.25),\n             colour = \"black\",\n             fill = NA, \n             lwd = 0.2) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArrange map components\nFinally, we can arrange our base map and inset together for our final map!\nThis map shows the three bee species with the highest percentage overlap with fire-burned areas. Two of these bee species are located in Northern Australia and one is located in South-Eastern Australia.\n\ncombined_map &lt;- ggdraw(main_bbox) +\n  draw_plot(inset, \n            x = 0.52, y = 0.63, \n            width =0.45, height = 0.3)\n\ncombined_map\n\n\n\n\n\n\n\nBonus: Vascular plants\nWe repeated the same workflow with the vascular plant dataset and created a map of range overlap with burned areas for the genus Daviesia.\nCommonly known as bitterpeas, Daviesia comprises plants pollinated by reed bees (Exoneura), which are featured in the bee map above.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeft: Daviesa buxifolia (Betty and Don Wood CC BY 3.0), Middle: Daviesa nova-anglica (Janeteveh CC BY-NC 4.0)), Right: Daviesa suaveolens (Crisp, M.D. CC BY 3.0))\n\n\n\nCode\n# Extract candidate genus\ndaviesia &lt;- vplant_nest |&gt; \n  filter(genus == \"Daviesia\")\n\n# Compute concave hulls\ndaviesia_concave &lt;- daviesia |&gt;\n    mutate(points_sf = map(.x = coords,\n                           ~ st_as_sf(.x, coords = c(\"longitude\", \"latitude\"),\n                                      crs = 4326)), \n           concave_sf = map(points_sf,\n                            ~ concaveman(.x)))\n\n# Compute range overlap and descriptive statistics and select \ndaviesia_overlap &lt;- daviesia_concave |&gt; \n  mutate(overlap_sf = map(concave_sf, \n                          possibly(~ st_intersection(fire, .x) |&gt; select(-Id))),\n  overlap_area = map(overlap_sf,\n                     possibly(~ st_area(.x))),\n  percent_overlap = map2(.x = overlap_area,\n                         .y = concave_sf,\n                         possibly(~ (.x / st_area(.y))*100))) |&gt; \n  unnest(cols = c(overlap_area, percent_overlap)) \n\n## Prepare for plotting and rename variables\ndaviesia_map_data &lt;- daviesia_overlap |&gt; \n  select(species, overlap_area, percent_overlap, points_sf, concave_sf, overlap_sf) |&gt; \n  unnest() |&gt; \n  rename(points = geometry, \n         concave = polygons, \n         overlap = geometry1) \n\n## Create main map reusing base_map from above\ndaviesia_main_map &lt;- base_map + \n    geom_sf(data = daviesia_map_data, \n          aes(geometry = concave, \n              colour = species, \n              fill = species), \n          size = 1.5, alpha = 0.005) + \n  geom_sf(data = daviesia_map_data, \n          aes(geometry = overlap), \n          colour = \"#FF925C\", fill = \"#FF925C\") + \n  geom_sf(data = daviesia_map_data, \n          aes(geometry = points, \n              colour = species), \n          size = 0.9) + \n  scale_colour_manual(values = c(\"#023E50\", \"#7B8A6A\", \"#3C908E\" )) + \n  scale_fill_manual(values = c(\"#023E50\", \"#7B8A6A\", \"#3C908E\")) + \n  guides(colour = guide_legend(override.aes = list(alpha = 1))) + \n  coord_sf(xlim = c(140, 158),\n           ylim = c(-23, -43)) +\n  theme(legend.title= element_blank(),\n        legend.position = \"bottom\") \n\n# Inset 1\ndaviesia_inset_1 &lt;- daviesia_main_map +\ncoord_sf(\n    xlim = c(145.5 , 150.3),\n    ylim = c(-35, -37.95),\n    expand = FALSE\n  ) + \n  theme_void() +\n  theme(legend.position = \"none\",\n        panel.border = element_rect(colour = \"black\", fill = NA, linewidth = 0.3))\n\n# Inset 2\ndaviesia_inset_2 &lt;- daviesia_main_map +\n  coord_sf(\n    xlim = c(151.55 , 152.75),\n    ylim = c(-28.6, -31.25),\n    expand = FALSE\n  ) + \n  theme_void() +\n  theme(legend.position = \"none\",\n        panel.border = element_rect(colour = \"black\", fill = NA, linewidth = 0.3))\n\n# Drawing the inset boxes on main map\ndaviesia_bbox &lt;- daviesia_main_map + \n   geom_rect(aes(xmin = 145.5, xmax = 150.3, # Inset 1\n             ymin = -35, ymax = -37.95),\n             colour = \"black\",\n             fill = NA, linewidth = 0.2) + \n  geom_rect(aes(xmin = 151.55, xmax = 152.75, # Inset 2\n             ymin = -28.6, ymax = -31.25),\n             colour = \"black\",\n             fill = NA, linewidth = 0.2) \n\n# Daviesia plot with insets \ndaviesia_combined &lt;- ggdraw(daviesia_bbox) +\n  draw_plot(daviesia_inset_1, x = 0.59, y = 0.15, \n            width = 0.42, height = 0.30) +\n  draw_plot(daviesia_inset_2, x = 0.52, y = 0.52, \n            width = 0.5, height = 0.4)\n\ndaviesia_combined\n\n\n\n\n\n\n\nFinal thoughts\nIn natural catastrophes, decision makers have limited time to act. They need ready-to-go data and workflows to assess and manage possible consequences of the catastrophe and any proposed ways to mitigate it. Here, we used curated datasets of Australian invertebrates and vascular plants to illustrate how concave hulls can represent estimate species range and estimate range overlap with natural disasters. We hope our work can aid future assessments of vulnerable species and help prioritise conservation efforts.\n\n\n\n\n\n\nAcknowledgement:\n\n\n\nThe work in this post is part of a project titled: Curated biodiversity data for rapid assessment of bushfire impact. This project is funded by the Australian Research Data Commons (ARDC) bushfire data challenges program.\n\n\n\n\nExpand for session info\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.2 (2022-10-31 ucrt)\n os       Windows 10 x64 (build 19044)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  English_Australia.utf8\n ctype    English_Australia.utf8\n tz       Australia/Sydney\n date     2023-04-13\n pandoc   2.19.2 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package        * version date (UTC) lib source\n concaveman     * 1.1.0   2020-05-11 [1] CRAN (R 4.2.2)\n cowplot        * 1.1.1   2020-12-30 [1] CRAN (R 4.2.1)\n dplyr          * 1.1.0   2023-01-29 [1] CRAN (R 4.2.2)\n forcats        * 1.0.0   2023-01-29 [1] CRAN (R 4.2.2)\n ggplot2        * 3.4.1   2023-02-10 [1] CRAN (R 4.2.2)\n ggpointdensity * 0.1.0   2019-08-28 [1] CRAN (R 4.2.1)\n gt             * 0.9.0   2023-03-31 [1] CRAN (R 4.2.3)\n here           * 1.0.1   2020-12-13 [1] CRAN (R 4.2.1)\n htmltools      * 0.5.4   2022-12-07 [1] CRAN (R 4.2.2)\n lubridate      * 1.9.2   2023-02-10 [1] CRAN (R 4.2.2)\n ozmaps         * 0.4.5   2021-08-03 [1] CRAN (R 4.2.1)\n patchwork      * 1.1.2   2022-08-19 [1] CRAN (R 4.2.1)\n purrr          * 1.0.1   2023-01-10 [1] CRAN (R 4.2.2)\n readr          * 2.1.4   2023-02-10 [1] CRAN (R 4.2.2)\n rmapshaper     * 0.4.6   2022-05-10 [1] CRAN (R 4.2.1)\n sessioninfo    * 1.2.2   2021-12-06 [1] CRAN (R 4.2.1)\n sf             * 1.0-9   2022-11-08 [1] CRAN (R 4.2.2)\n stringr        * 1.5.0   2022-12-02 [1] CRAN (R 4.2.2)\n tibble         * 3.1.8   2022-07-22 [1] CRAN (R 4.2.1)\n tidyr          * 1.3.0   2023-01-24 [1] CRAN (R 4.2.2)\n tidyverse      * 2.0.0   2023-02-22 [1] CRAN (R 4.2.2)\n viridis        * 0.6.2   2021-10-13 [1] CRAN (R 4.2.1)\n viridisLite    * 0.4.1   2022-08-22 [1] CRAN (R 4.2.1)\n\n [1] C:/Users/KEL329/R-packages\n [2] C:/Users/KEL329/AppData/Local/Programs/R/R-4.2.2/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2023-04-28_plotting-invasive-species/post.html",
    "href": "posts/2023-04-28_plotting-invasive-species/post.html",
    "title": "Plotting invasive species distributions with alpha shapes and choropleth maps in Python",
    "section": "",
    "text": "Author\nCaitlin Ramsay\nAmanda Buyan\nDax Kellie\n\n\nDate\n28 April 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntern Post\n\n\n\n\n\n\nHumans’ movement across the globe has led to the accidental, and sometimes deliberate, transportation of species beyond their native habitats. In Australia since European colonisation, around 3,000 species have been introduced.\nWithin the last 200 years over 100 native species have gone extinct, with invasive species labelled as affecting 82% (1,257 of 1,533) of Australia’s threatened taxa in 2018. Since 1960, invasive species have cost the Australian economy at least $390 billion in damages, and are now considered a main driver of extinctions in native plants and animals.\nHowever, species from outside of Australia aren’t the only ones that can encroach on other species’ habitats. Native Australian species can do it, too. Thanks in part to human activity, changing temperatures and more frequent extreme weather events, some Australian species have established themselves in new areas outside of their native range. Although not as popularly discussed, Australian species that have become pests in new habitats can disrupt ecosystems much like internationally invasive species.\nIn this post, we will use Python and the {galah} package to visualise how distributions of both international invasive species and native introduced pest species have shifted over time. To do this, we will use alpha shapes to visualise the distribution of Rhinella marina (Cane toads) since the 1930s and create a choropleth map to visualise the expanded habitat range of Pittosporum undulatum.\n\nInvasive Species\n\nDownload data\nTo start, we will use the infamous example of the cane toad to illustrate how far an invasive species’ distribution can spread each decade.\n\n\n\n \n\n\n\n\n\n \n\n\n\n\nRhinella marina (Isaac Clarey CC-BY-NC 4.0 (Int))\n\nFirst load the required Python packages.\n\nimport galah\nimport pandas as pd\nimport geopandas\nimport numpy as np\nfrom dateutil.parser import parse\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport alphashape\nfrom flexitext import flexitext\n\nNext, we will use the {galah} package to download occurrence records of cane toads in Australia from the Atlas of Living Australia (ALA). You will need to first provide a registered email with the ALA using galah.galah_config() before retrieving records.\n\n# Add registered email (register at ala.org.au)\ngalah.galah_config(email = \"your-email@email.com\")\ngalah.galah_config(data_profile=\"ALA\")\n\n\ncane_toads = galah.atlas_occurrences(taxa = \"Rhinella marina\", use_data_profile = True)\ncane_toads.head(5)\n\n\n\n\n\n\n\n\ndecimalLatitude\ndecimalLongitude\neventDate\nscientificName\ntaxonConceptID\nrecordID\ndataResourceName\noccurrenceStatus\n\n\n\n\n0\n-38.300000\n145.000000\n1990-04-23T00:00:00Z\nRhinella marina\nhttps://biodiversity.org.au/afd/taxa/e79179f8-...\n58772bea-1c61-4716-a453-f201e89fcc8d\nMuseums Victoria provider for OZCAM\nPRESENT\n\n\n1\n-38.300000\n145.000000\n1990-07-21T00:00:00Z\nRhinella marina\nhttps://biodiversity.org.au/afd/taxa/e79179f8-...\n141f0b10-bdf2-4239-80e4-1b5167e1f76c\nMuseums Victoria provider for OZCAM\nPRESENT\n\n\n2\n-37.820000\n145.230000\n1990-04-14T00:00:00Z\nRhinella marina\nhttps://biodiversity.org.au/afd/taxa/e79179f8-...\nf6d07eb2-4f8f-476e-a212-726b10a4a745\nMuseums Victoria provider for OZCAM\nPRESENT\n\n\n3\n-37.800000\n144.700000\n2022-04-15T21:52:00Z\nRhinella marina\nhttps://biodiversity.org.au/afd/taxa/e79179f8-...\n1e683cd7-88fd-44b4-98cf-7cffff12ebee\nEarth Guardians Weekly Feed\nPRESENT\n\n\n4\n-36.431411\n148.329322\n2017-03-07T00:00:00Z\nRhinella marina\nhttps://biodiversity.org.au/afd/taxa/e79179f8-...\n549908bf-0b34-4227-9288-42a7fa52dabf\nNSW BioNet Atlas\nPRESENT\n\n\n\n\n\n\n\n\n\nClean data\nWe’ll clean our data to ensure that there are no null or missing values in our coordinates and date fields. Because galah.atlas_occurrences() returns a Pandas dataframe, we have plenty of functions we can use to clean our data.\n\ncane_toads = cane_toads.dropna(subset=[\"eventDate\", \"decimalLatitude\", \"decimalLongitude\"])\n\nWe want to map cane toad’s distribution each decade in our final visualisation. However, the eventDate value for each record is formaatted as a string value yyyy-mm-dd Thh:mm:ssZ. Let’s write our own function convert_date_to_decade() that extract the year from a date string and return its corresponding decade by rounding down to the nearest decade.\n\ndef convert_date_to_decade(value):\n    date = parse(value)\n    return date.year - (date.year%10)\n\nWe’ll create our new decade column by mapping each record’s date value in eventDate to its corresponding decade value.\n\ncane_toads[\"decade\"] = cane_toads[\"eventDate\"].map(convert_date_to_decade)\n\n\n\nMake Australia map\nNext, let’s download a shapefile of Australia with state boundaries. The Australian Bureau of Statistics provides digital boundary files from which you can explore many other Australian shapefiles. Download the States and Territories - 2021 - Shapefile a zip folder. Save the zip folder inside your working folder and then unzip it to access the .shp file inside.\n{GeoPandas} is a package that handles geospatial data in Python and can be used to load in shapefiles as GeoPandas dataframes. Let’s test this out by plotting our Australian state boundary shapefile.\n\nmpl.rcParams['figure.dpi'] = 1200 # generate a high resolution image\nstates = geopandas.read_file(\"Australia_state_boundaries/STE_2021_AUST_GDA2020.shp\")\nstates.plot(edgecolor = \"#5A5A5A\", linewidth = 0.5, facecolor = \"white\")\n\n\n\n&lt;Axes: &gt;\n\n\n\n\n\n\n\nGenerate alpha shapes\nAlpha shapes can be used to define and visualise the shape of a set of species occurrence points in space. They are useful because they can be generated on data-deficient species with few available observations, and without using environmental data or complex algorithms. Let’s use alpha shapes to see how cane toads’ distribution has changed each decade since they were introduced.\nFirst, we need to obtain a list of all decades with cane toad observations. We’ll use the decade column from our cane_toads dataframe to group our observations.\n\ndecades = list(set(cane_toads[\"decade\"]))\n\nWe will be using the {alphashape} package to create alpha shapes representing the cane toad distribution for each decade they have been observed. The alphashape.alphashape() function requires two things:\n\nA set of observation coordinates\nAn alpha parameter, which sets how tightly the shape’s lines conform to our observations\n\nLet’s make an alpha shape for each decade’s observations. We’ll also add a slight buffer to each alpha shape to smooth out some of its edges. Then we’ll group all the shapes into one large GeoPandas dataframe.\n\n\n\n\n\n\nNote\n\n\n\nWe used alpha = 1, but it’s good practice to change this parameter depending on how widely distributed the coordinates of your data are. Also note that alphashape.alphashape() requires at least 3 data points to calculate an alpha shape.\n\n\n\nalpha_shape_gdf = geopandas.GeoDataFrame() # GeoPandas data frame to contain all alpha shapes\nfor i, d in enumerate(decades):\n    decade_points = cane_toads[[\"decimalLongitude\", \"decimalLatitude\"]] [cane_toads[\"decade\"] == d]\n    if len(decade_points) &lt;= 3: \n        continue\n    alpha_shape = alphashape.alphashape(decade_points, 1)\n    d = {\"decade\": d, \"geometry\": [alpha_shape.buffer(0.2)]}\n    tmp_gdf = geopandas.GeoDataFrame(d, crs=\"EPSG:7844\")\n    alpha_shape_gdf = pd.concat([alpha_shape_gdf, tmp_gdf])\n\nNext, let’s clean up our GeoPandas dataframe so that it is ready for plotting! Sometimes the alphashape.alphashape() algorithm will produce an empty shape that needs to be removed from the dataframe (this generally happens when the chosen alpha parameter is not appropriate for the supplied set of points). Let’s remove these shapes from our data.\n\nalpha_shape_gdf = alpha_shape_gdf[~alpha_shape_gdf[\"geometry\"].is_empty]\n\nNow let’s format our decade string to display correctly on the figure legend by making sure it’s in YYYYs format.\n\nalpha_shape_gdf[\"decade_string\"] = alpha_shape_gdf[\"decade\"].map(lambda d: str(d) + \"s\")\n\nFinally, because we expect cane toad distributions in earlier decades to be smaller than in recent decades, we’ll need to plot earlier distributions on top of later distributions to avoid covering the earlier ones up. To achieve this, let’s order the alpha shapes in descending order by decade.\n\nalpha_shape_gdf.sort_values(by='decade', ascending=False, inplace=True)\n\n\n\nMap alpha shape distributions\nFinally, we can plot our alpha shape distributions for each decade onto our map of Australia!\nThis figure showcases the incredible pace of the cane toad’s spread across northern Australia. Our map shows that cane toads have spread across most of Queensland, the top end of the Northern Territory (from the 1980s to 2010s) and more recently, into the Kimberley region of Western Australia.\n\nax = states.boundary.plot(edgecolor=\"#5A5A5A\", linewidth=0.5, facecolor=\"white\", zorder=-1)\n\nalpha_shape_gdf.plot(ax = ax, cmap=\"plasma\", column = \"decade_string\", legend=True, categorical=True)\nlgd = ax.get_legend()\nlgd.draw_frame(False)\nlgd.set_bbox_to_anchor((1.2, 0.8))\n\ntitle_text = \"&lt;style: italic&gt;Rhinella marina&lt;/&gt; (cane toad) distributions per decade\"\nflexitext(0.5, 1, title_text, va=\"bottom\", ha=\"center\");\n\ncaption_text = \"&lt;color:#5A5A5A, style:italic, size:7&gt;Distributions calculated with alpha hulls of each decade's cane toad observations&lt;/&gt;\"\nflexitext(0.05, 0, caption_text, va=\"top\");\n\nplt.xlim([110, 161])\nplt.ylim([-45, -8])\nplt.axis(\"off\")\nplt.subplots_adjust(left=-0.15, right=1)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nOther invasive species\nLet’s use the same code as above to visualise other invasive species Camelus dromedarius (Feral dromedary camels) and Echium plantagineum (Paterson’s curse).\n\n\nCode\n# Camel\ncamels = galah.atlas_occurrences(\"Camelus dromedarius\", use_data_profile=\"ALA\")\ncamels = camels.dropna(subset=[\"eventDate\", \"decimalLatitude\", \"decimalLongitude\"])\ncamels[\"decade\"] = camels[\"eventDate\"].map(convert_date_to_decade)\ndecades = list(set(camels[\"decade\"]))\n\nalpha_shape_gdf = geopandas.GeoDataFrame() # GeoPandas data frame to contain all alpha shapes\n\nfor i, d in enumerate(decades):\n    decade_points = camels[[\"decimalLongitude\", \"decimalLatitude\"]] [camels[\"decade\"] == d]\n    if len(decade_points) &lt;= 3: \n        continue\n    alpha_shape = alphashape.alphashape(decade_points, 1)\n    d = {\"decade\": d, \"geometry\": [alpha_shape.buffer(0.2)]}\n    tmp_gdf = geopandas.GeoDataFrame(d, crs=\"EPSG:4326\")\n    alpha_shape_gdf = pd.concat([alpha_shape_gdf, tmp_gdf])\n\nalpha_shape_gdf = alpha_shape_gdf[ ~alpha_shape_gdf[\"geometry\"].is_empty]\nalpha_shape_gdf[\"decade_string\"] = alpha_shape_gdf[\"decade\"].map(lambda d: str(d) + \"s\")\nalpha_shape_gdf.sort_values(by='decade', ascending=False, inplace=True)\n\nax = states.boundary.plot(edgecolor=\"#5A5A5A\", linewidth=0.5, facecolor=\"white\", zorder=-1)\n\nalpha_shape_gdf.plot(ax = ax, cmap=\"plasma\", column = \"decade\", legend=True, categorical=True)\nlgd = ax.get_legend()\nlgd.draw_frame(False)\nlgd.set_bbox_to_anchor((1.2, 0.61))\n\ntitle_text = \"&lt;style: italic&gt;Camelus dromedarius&lt;/&gt; (dromedary camel) distributions per decade\"\nflexitext(0.5, 1, title_text, va=\"bottom\", ha=\"center\");\n\ncaption_text = \"&lt;color:#5A5A5A, style:italic, size:7&gt;Distributions calculated with alpha hulls of each decade's dromedary camel observations&lt;/&gt;\"\nflexitext(0.05, 0, caption_text, va=\"top\");\n\nplt.xlim([110, 161])\nplt.ylim([-45, -8])\nplt.axis(\"off\")\nplt.subplots_adjust(left=-0.1, right=1)\n\nplt.show()\n\n\n# Paterson's Curse\nopuntia = galah.atlas_occurrences(\"Echium plantagineum\", use_data_profile=\"ALA\")\nopuntia = opuntia.dropna(subset=[\"eventDate\", \"decimalLatitude\", \"decimalLongitude\"])\nopuntia[\"decade\"] = opuntia[\"eventDate\"].map(convert_date_to_decade)\ndecades = list(set(opuntia[\"decade\"]))\n\nalpha_shape_gdf = geopandas.GeoDataFrame() # GeoPandas data frame to contain all alpha shapes\n\nfor i, d in enumerate(decades):\n    decade_points = opuntia[[\"decimalLongitude\", \"decimalLatitude\"]] [opuntia[\"decade\"] == d]\n    if len(decade_points) &lt;= 3: \n        continue\n    alpha_shape = alphashape.alphashape(decade_points, 1)\n    d = {\"decade\": d, \"geometry\": [alpha_shape.buffer(0.2)]}\n    tmp_gdf = geopandas.GeoDataFrame(d, crs=\"EPSG:4326\")\n    alpha_shape_gdf = pd.concat([alpha_shape_gdf, tmp_gdf])\n\nalpha_shape_gdf = alpha_shape_gdf[ ~alpha_shape_gdf[\"geometry\"].is_empty]\nalpha_shape_gdf[\"decade_string\"] = alpha_shape_gdf[\"decade\"].map(lambda d: str(d) + \"s\")\nalpha_shape_gdf.sort_values(by='decade', ascending=False, inplace=True)\n\nax = states.boundary.plot(edgecolor=\"#5A5A5A\", linewidth=0.5, facecolor=\"white\", zorder=-1)\n\nalpha_shape_gdf.plot(ax = ax, cmap=\"plasma\", column = \"decade\", legend=True, categorical=True)\nlgd = ax.get_legend()\nlgd.draw_frame(False)\nlgd.set_bbox_to_anchor((1.2, 0.85))\n\ntitle_text = \"&lt;style: italic&gt;Echium plantagineum&lt;/&gt; (Paterson's curse) distributions per decade\"\nflexitext(0.5, 1, title_text, va=\"bottom\", ha=\"center\");\n\ncaption_text = \"&lt;color:#5A5A5A, style:italic, size:7&gt;Distributions calculated with alpha hulls of each decade's Paterson's curse observations&lt;/&gt;\"\nflexitext(0.05, 0, caption_text, va=\"top\");\n\nplt.xlim([110, 161])\nplt.ylim([-45, -8])\nplt.axis(\"off\")\nplt.subplots_adjust(left=-0.1, right=1)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNative introduced pest species\nWhen people think of invasive species, they generally think of species that have been introduced to Australia from other countries. However, even Australia’s native species can become pests when introduced to a new ecosystem.\nOne good example of native pests are the trees Pittosporum undulatum (sometimes called Sweet Pittosporum). These trees have been introduced as ornamental plants in gardens across Australia because of their sweet-scented flowers and bright berries. Although Pittosporum undulatum’s native range extends from southern Queensland to eastern Victoria, it is now considered an environmental weed in many regions where it has been introduced.\n\n\n\n \n\n\n\n\n\n \n\n\n\n\nPittosporum undulatum (Chris Clarke CC-BY)\n\nLet’s create a choropleth map to visualise the to visualise the bioregions where Pittosporum undulatum is native and introduced.\n\nDownload IBRA regions\nFirst, let’s download a shapefile of Australia’s bioregions. The IBRA7 bioregions classify areas within Australia that are geographically and ecologically distinct. Download the zip folder, save it in your project directory and unzip it. We can again use the {GeoPandas} package to read in and handle these data.\n\nbioregions = geopandas.read_file(\"IBRA7_regions/ibra7_regions.shp\")\nbioregions.plot(edgecolor = \"#5A5A5A\", linewidth = 0.25, facecolor = \"white\")\n\n\n\n&lt;Axes: &gt;\n\n\n\n\n\nWithin our bioregions dataframe, the column REG_NAME_7 contains IBRA bioregion names.\n\nbioregions.head(5)\n\n\n\n\n\n\n\n\nREG_CODE_7\nREG_NAME_7\nHECTARES\nSQ_KM\nREC_ID\nREG_CODE_6\nREG_NAME_6\nREG_NO_61\nFEAT_ID\nShape_Leng\nShape_Area\ngeometry\n\n\n\n\n0\nARC\nArnhem Coast\n3.335669e+06\n33356.686\n1\nARC\nArnhem Coast\n81.0\nGA_100K_Islands\n52.135362\n2.774143\nMULTIPOLYGON (((136.93863 -14.36548, 136.93790...\n\n\n1\nARP\nArnhem Plateau\n2.306023e+06\n23060.226\n2\nARP\nArnhem Plateau\n82.0\nGA_100K_Mainland\n8.206764\n1.921833\nPOLYGON ((134.08186 -12.32124, 134.09525 -12.3...\n\n\n2\nAUA\nAustralian Alps\n1.232981e+06\n12329.805\n3\nAA\nAustralian Alps\n6.0\nGA_100K_Mainland\n63.337626\n1.242821\nMULTIPOLYGON (((145.75905 -37.67486, 145.76034...\n\n\n3\nAVW\nAvon Wheatbelt\n9.517104e+06\n95171.043\n4\nAW\nAvon Wheatbelt\n70.0\nGA_100K_Mainland\n35.275357\n9.012298\nPOLYGON ((115.48396 -28.30698, 115.48428 -28.3...\n\n\n4\nBBN\nBrigalow Belt North\n1.367453e+07\n136745.325\n5\nBBN\nBrigalow Belt North\n22.0\nGA_100K_Islands\n91.288203\n11.986228\nMULTIPOLYGON (((151.14295 -23.71304, 151.14210...\n\n\n\n\n\n\n\n\n\nFind bioregions with observations\nWe’ll once again use {galah} to find numbers of Pittosporum undulatum in each bioregion. First, let’s find which field ID corresponds to bioregions in {galah}\n\ngalah.search_all(fields = \"IBRA\") \n\n\n\n\n\n\n\n\nid\ndescription\ntype\nlink\n\n\n\n\n486\ncl3\nWestern Australian Biodiversity Science Resear...\nlayers\n\n\n\n495\ncl20\nIBRA 6 Regions Interim Biogeographic Regionali...\nlayers\n\n\n\n536\ncl1049\nIBRA 7 Subregions IBRA 7 Subregions\nlayers\n\n\n\n537\ncl1048\nIBRA 7 Regions Interim Biogeographic Regionali...\nlayers\n\n\n\n\n\n\n\n\nIt looks like field cl1048 contains IBRA 7 regions. Let’s check what values this field contains by using galah.show_values().\n\ngalah.show_values(field = \"cl1048\")\n\n\n\n\n\n\n\n\nfield\ncategory\n\n\n\n\n0\ncl1048\nSouth Eastern Queensland\n\n\n1\ncl1048\nSydney Basin\n\n\n2\ncl1048\nSouth Eastern Highlands\n\n\n3\ncl1048\nSouth East Coastal Plain\n\n\n4\ncl1048\nMurray Darling Depression\n\n\n...\n...\n...\n\n\n84\ncl1048\nCentral Arnhem\n\n\n85\ncl1048\nIndian Tropical Islands\n\n\n86\ncl1048\nLittle Sandy Desert\n\n\n87\ncl1048\nGibson Desert\n\n\n88\ncl1048\nCoral Sea\n\n\n\n\n89 rows × 2 columns\n\n\n\nNow we can use the group_by argument in galah.atlas_counts() to group observations of Pittosporum undulatum by bioregion, returning all bioregions where Pittosporum undulatum has been observed at least once. We’ll extract extract and save the bioregion names in a dataframe.\n\nfound_bioregion_counts = galah.atlas_counts(\"Pittosporum undulatum\",\n                                           group_by=\"cl1048\",\n                                           expand = False)\n\n# extract bioregion names from Pandas dataframe into list\nfound_bioregions = list(found_bioregion_counts[\"cl1048\"])\n\nprint(found_bioregion_counts[0:10])\n\n                     cl1048  count\n0              Sydney Basin   9649\n1  South East Coastal Plain   3163\n2         South East Corner   2916\n3   South Eastern Highlands   2766\n4           NSW North Coast   2299\n5  South Eastern Queensland   1083\n6      Flinders Lofty Block    412\n7   Southern Volcanic Plain    345\n8        Victorian Midlands    192\n9       Brigalow Belt South    167\n\n\n\n\nSeparate native & introduced regions\nNext, let’s separate bioregions where Pittosporum undulatum is native from bioregions where it has been introduced. The Australia Native Plants Society estimates Pittosporum undulatum’s native range overlapping with South Eastern Queensland, NSW North Coast, Sydney Basin, South East Corner and South East Coastal Plain (see here). Let’s save these bioregion names in a separate dataframe and compare them to the overall list found_bioregions.\n\nnative_bioregions = [\"South Eastern Queensland\", \"NSW North Coast\", \"Sydney Basin\", \"South East Corner\", \"South East Coastal Plain\"]\nintroduced_bioregions = [region for region in found_bioregions if region not in native_bioregions]\n\nprint(introduced_bioregions[1:5]) # first 5 introduced regions\n\n['Flinders Lofty Block', 'Southern Volcanic Plain', 'Victorian Midlands', 'Brigalow Belt South']\n\n\nNext we can add a new column native to our GeoPandas bioregion dataframe to identify native and introduced regions. We’ll use the .loc method to assign a “Native”, “Introduced” or “No observations” label to each row depending on whether the region is in native_bioregions or introduced_bioregions.\n\nbioregions.loc[bioregions[\"REG_NAME_7\"].isin(native_bioregions), \"native\"] = \"Native\"\nbioregions.loc[bioregions[\"REG_NAME_7\"].isin(introduced_bioregions), \"native\"] = \"Introduced\"\nbioregions[\"native\"] = bioregions[\"native\"].fillna(\"No observations\")\n\n\n\nMake choropleth map\nWhen plotting this GeoPandas dataframe, we can specify that we want the map coloured according to its native label so that native, introduced and not found bioregions are distinguishable colours. This is done by supplying the column argument of the .plot() function with the column of the dataframe that the colouring is based upon. However, matplotlib would choose a default colourmap to colour the bioregions so we will need to specify the exact colours we wanted associated with each type of bioregion.\nTo identify our three categories of regions on our map, we’ll create a new column colour containing colour hex codes for plotting our regions.\n\nbioregions.loc[bioregions[\"native\"] == \"Native\", \"colour\"] = \"#8FBD4C\" # Native\nbioregions.loc[bioregions[\"native\"] == \"Introduced\", \"colour\"] = \"#F7872E\" # Introduced\nbioregions.loc[bioregions[\"native\"] == \"No observations\", \"colour\"] = \"#E4DFCF\" # No observations\n\nWe can use this colour column as the input to our .plot() function.\nOur map shows that Pittosporum undulatum has been observed in Western Australia, Northern Territory, South Australia, and even Tasmania despite having a fairly narrow native range along the east coast of Australia.\n\nbioregions.plot(edgecolor=\"white\", linewidth = 0.25, color = bioregions[\"colour\"])\n\ntitle_text = \"&lt;style:italic&gt;Pittosporum undulatum&lt;/&gt; &lt;color:#8FBD4C, weight:bold&gt;native&lt;/&gt; and &lt;color:#F7872E, weight:bold&gt;introduced&lt;/&gt; Australian bioregions\"\nflexitext(0.5, 1, title_text, va=\"bottom\", ha=\"center\");\n\nplt.xlim([110, 161])\nplt.ylim([-45, -8])\nplt.axis(\"off\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nFinal thoughts\nHuman activity—from constructing buildings to travelling overseas to gardening—plays a part in shaping modern ecosystems. Our maps showed how quickly well-known invasive species have established themselves across Australia, and how widely even native Australian plants can spread when introduced to non-native regions.\nHumans are just one of many drivers of introducing species to new areas. Changes to the environment, for example, can shrink available resources and living space in a habitat, giving introduced species a chance to outcompete native species for what resources and space are left. As species inevitably enter and alter ecosystems, large weather events, extreme temperatures and habitat degradation can give invasives a big leg-up on the native competition, too.\nNonetheless, there is still hope. Research finds native species can still adapt to changing environments and simple tasks like pulling weeds can help native species survive after events like fires.\n\n\nExpand for session info\n\n\nimport math\nimport natsort\nimport pandas\nimport session_info\n\nsession_info.show()\n\n\nClick to view session information\n-----\nalphashape          1.3.1\ndateutil            2.8.2\nflexitext           0.2.0\ngalah               0.1.0\ngeopandas           0.12.2\nmatplotlib          3.7.1\nnatsort             8.3.1\nnumpy               1.24.3\npandas              1.5.3\nsession_info        1.0.0\nshapely             2.0.1\n-----\n\n\nClick to view modules imported as dependencies\nPIL                 9.5.0\narrow               1.2.3\nasttokens           NA\nattr                23.1.0\nbackcall            0.2.0\ncertifi             2022.12.07\ncffi                1.15.1\ncharset_normalizer  3.1.0\ncolorama            0.4.6\ncomm                0.1.3\ncycler              0.10.0\ncython_runtime      NA\ndebugpy             1.6.7\ndecorator           5.1.1\ndefusedxml          0.7.1\nexecuting           1.2.0\nfastjsonschema      NA\nfiona               1.9.3\nfqdn                NA\ngoogle              NA\nidna                3.4\nipykernel           6.22.0\nipython_genutils    0.2.0\nisoduration         NA\njedi                0.18.2\njsonpointer         2.3\njsonschema          4.17.3\nkiwisolver          1.4.4\nmatplotlib_inline   0.1.6\nmpl_toolkits        NA\nnbformat            5.8.0\nnetworkx            3.1\nnt                  NA\nntsecuritycon       NA\npackaging           23.1\nparso               0.8.3\npickleshare         0.7.5\npkg_resources       NA\nplatformdirs        3.2.0\nplotly              5.14.1\nprompt_toolkit      3.0.38\npsutil              5.9.5\npure_eval           0.2.2\npvectorc            NA\npydev_ipython       NA\npydevconsole        NA\npydevd              2.9.5\npydevd_file_utils   NA\npydevd_plugins      NA\npydevd_tracing      NA\npygments            2.15.1\npyparsing           3.0.9\npyproj              3.5.0\npyrsistent          NA\npythoncom           NA\npytz                2023.3\npywin32_bootstrap   NA\npywin32_system32    NA\npywintypes          NA\nrequests            2.28.2\nrfc3339_validator   0.1.4\nrfc3986_validator   0.1.1\nrtree               1.0.1\nscipy               1.10.1\nsix                 1.16.0\nstack_data          0.6.2\ntenacity            NA\ntornado             6.3.1\ntraitlets           5.9.0\ntrimesh             3.21.5\nuri_template        NA\nurllib3             1.26.15\nwcwidth             0.2.6\nwebcolors           1.13\nwin32api            NA\nwin32com            NA\nwin32security       NA\nzmq                 25.0.2\nzoneinfo            NA\n\n \n-----\nIPython             8.12.0\njupyter_client      8.2.0\njupyter_core        5.3.0\nnotebook            6.5.4\n-----\nPython 3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]\nWindows-10-10.0.19044-SP0\n-----\nSession information updated at 2023-05-01 13:20"
  },
  {
    "objectID": "posts/2023-05-16_dingoes/post.html",
    "href": "posts/2023-05-16_dingoes/post.html",
    "title": "An exploration of dingo observations in the ALA",
    "section": "",
    "text": "Amos Smith Olivia Torresan\nDax Kellie\n\n\n\n5 May 2023\nThe dingo (Canis familiaris) is among Australia’s most recognisable species internationally. However, debate continues about whether dingoes are considered invasive or native species.\nDingoes arrived in Australia around 3,000–5,000 years ago, and their rapid dispersal was likely facilitated by humans. Dingoes hold great significance to many Aboriginal and Torres Strait Islander communities. In some communities, women and children often took dingoes with them to hunt small game or collect food, regarded as protection from danger.\nIn the present day, dingoes negatively impact livestock producers, especially sheep farmers. To reduce these impacts, landowners and government agencies spend an estimated ~$30 million annually across Australia to control dingo populations. Control methods include using traps, baits and shooting, along with constructing a physical barrier to limit their movement: the Dog Fence (also known as the Dingo Fence).\nThe Dog Fence is a wire fence made to protect from the loss of sheep and livestock; currently, it is the longest fence in the world (5,614 km). Since its construction 80 years ago, the Dog Fence has shaped the landscape of Australia. However, perhaps unintentionally, the Dog Fence has acted as a natural experiment. On the side where dingoes remain present there is more vegetation and fewer invasive species like foxes than on the side where dingoes are absent. The difference between sides of the fence is so distinct that you can even see it from space! Nearly a century later, the Dog Fence has shown the importance of apex predators like dingoes in ecosystems and their benefit to native biodiversity1.\nTo understand the debate about the dingo’s role in Australia’s ecosystems, it’s useful to know the species’ current distribution. Here, we’ll explore where and how often dingo observations are recorded in the Atlas of Living Australia (ALA) to understand how historical and ongoing differences in attitudes toward dingo conservation affect data collection."
  },
  {
    "objectID": "posts/2023-05-16_dingoes/post.html#records-by-state",
    "href": "posts/2023-05-16_dingoes/post.html#records-by-state",
    "title": "An exploration of dingo observations in the ALA",
    "section": "Records by state",
    "text": "Records by state\n\nFind fields to filter data\nWe’ll use the {galah} package to download our data.\nThe taxonomic name for dingoes—Canis familiaris—is broadly the name for all wild dogs, though recent genomic research has found pure dingoes are genomically distinct from wild dogs2. This means that if we search using the scientific name Canis familiaris, we’ll likely return more than just dingo records. To fix this, let’s filter our records to those specified by the data provider with the name common name “Dingo”.\nLet’s use search_fields() to help us find which fields we can use to filter the taxonomic name. There are a few options, but the raw_vernacularName field seems to hold original common names specified by data providers.\n\nsearch_fields(\"common name\")\n\n# A tibble: 4 × 4\n  id                   description                                   type  link \n  &lt;chr&gt;                &lt;chr&gt;                                         &lt;chr&gt; &lt;chr&gt;\n1 common_name_and_lsid Concatenation of common name and LSID, usefu… fiel… &lt;NA&gt; \n2 vernacularName       The common name the ALA has matched this rec… fiel… &lt;NA&gt; \n3 names_and_lsid       Concatenation of common name and LSID, usefu… fiel… &lt;NA&gt; \n4 raw_vernacularName   The original common name value supplied by t… fiel… &lt;NA&gt; \n\nsearch_fields(\"raw_vernacularName\") |&gt; search_values(\"dingo\")\n\n# A tibble: 4 × 2\n  field              category           \n  &lt;chr&gt;              &lt;chr&gt;              \n1 raw_vernacularName Dingo, domestic dog\n2 raw_vernacularName Dingo              \n3 raw_vernacularName Dingo & Dog (feral)\n4 raw_vernacularName dingo              \n\n\nWe can use the same method to find a field that contains states & territories.\n\nsearch_fields(\"australian states\")\n\n# A tibble: 2 × 4\n  id     description                                                 type  link \n  &lt;chr&gt;  &lt;chr&gt;                                                       &lt;chr&gt; &lt;chr&gt;\n1 cl2013 ASGS Australian States and Territories Australian Statisti… laye… http…\n2 cl22   Australian States and Territories Australian States and Te… laye… http…\n\nsearch_fields(\"cl22\") |&gt; show_values()\n\n# A tibble: 11 × 2\n   field category                    \n   &lt;chr&gt; &lt;chr&gt;                       \n 1 cl22  New South Wales             \n 2 cl22  Victoria                    \n 3 cl22  Queensland                  \n 4 cl22  South Australia             \n 5 cl22  Western Australia           \n 6 cl22  Northern Territory          \n 7 cl22  Australian Capital Territory\n 8 cl22  Tasmania                    \n 9 cl22  Unknown1                    \n10 cl22  Ashmore and Cartier Islands \n11 cl22  Coral Sea Islands           \n\n\n\n\nDownload counts\nWe’ll download the number of dingo observations in each state/territory with atlas_counts() and arrange the resulting counts in descending order.\nAround 75% of dingo observations are recorded in the Northern Territory and South Australia.\n\ndingo_counts &lt;- galah_call() |&gt;\n  galah_identify(\"canis familiaris\") |&gt;\n  galah_filter(raw_vernacularName == c(\"Dingo\", \"dingo\")) |&gt;\n  galah_group_by(cl22) |&gt;\n  atlas_counts() |&gt;\n  arrange(desc(count))\n\ndingo_counts |&gt; gt::gt()\n\n\n\n\n\n  \n    \n    \n      cl22\n      count\n    \n  \n  \n    Northern Territory\n6155\n    South Australia\n2933\n    Queensland\n1283\n    New South Wales\n1110\n    Victoria\n412\n    Western Australia\n130\n    Australian Capital Territory\n4"
  },
  {
    "objectID": "posts/2023-05-16_dingoes/post.html#data-providers",
    "href": "posts/2023-05-16_dingoes/post.html#data-providers",
    "title": "An exploration of dingo observations in the ALA",
    "section": "Data providers",
    "text": "Data providers\nNext let’s find out who the main data providers are of dingo observations to see whether observations come from citizen science programs or state monitoring programs. We’ll filter to only display providers that have provided more than 5 observations of dingoes.\n\ndata_providers &lt;- galah_call() |&gt;\n  galah_identify(\"canis familiaris\") |&gt;\n  galah_filter(raw_vernacularName == c(\"Dingo\", \"dingo\")) |&gt;\n  galah_group_by(dataResourceName)|&gt;\n  galah_apply_profile(ALA) |&gt;\n  atlas_counts()\n\ncounts_filtered &lt;- data_providers |&gt;\n  filter(count &gt; 5)\n\n\n\n# A tibble: 9 × 2\n  dataResourceName                                           count\n  &lt;chr&gt;                                                      &lt;int&gt;\n1 Fauna Atlas N.T.                                            4867\n2 SA Fauna (BDBSA)                                            2833\n3 Australian National Wildlife Collection provider for OZCAM  2035\n4 WildNet - Queensland Wildlife Data                          1120\n5 NSW BioNet Atlas                                            1053\n6 Victorian Biodiversity Atlas                                 101\n7 Australian Museum provider for OZCAM                          76\n8 Museums Victoria provider for OZCAM                           36\n9 Northern Gulf Fauna Survey                                    18\n\n\n\nDownload observations\nWe can check to see where each data provider’s observations are recorded. We’ll download dingo observations using atlas_occurrences(). Then we’ll filter our observations to only those supplied by providers in counts_filtered.\nYou will need to first provide a registered email with the ALA using galah_config() before retrieving records.\n\ndingo_obs &lt;- galah_call()|&gt;\n  galah_identify(\"canis familiaris\") |&gt;\n  galah_filter(raw_vernacularName == c(\"Dingo\", \"dingo\")) |&gt;\n  galah_apply_profile(ALA) |&gt;\n  atlas_occurrences()\n\n\npoints_filtered &lt;- dingo_obs |&gt;\n  filter(dataResourceName %in% counts_filtered$dataResourceName)\n\n\n\n# A tibble: 12,139 × 8\n   decimal…¹ decim…² eventDate           scien…³ taxon…⁴ recor…⁵ dataR…⁶ occur…⁷\n       &lt;dbl&gt;   &lt;dbl&gt; &lt;dttm&gt;              &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  \n 1     -39      146. NA                  Canis … https:… 902931… Museum… PRESENT\n 2     -39      146. NA                  Canis … https:… e8fc34… Museum… PRESENT\n 3     -39      146. NA                  Canis … https:… 091e59… Museum… PRESENT\n 4     -38.6    143. 1866-03-27 00:00:00 Canis … https:… 13bd89… Victor… PRESENT\n 5     -38.4    146. NA                  Canis … https:… 5b05ba… Museum… PRESENT\n 6     -38.4    144. 1865-01-01 00:00:00 Canis … https:… c9f581… Victor… PRESENT\n 7     -38.4    143. 1886-09-01 00:00:00 Canis … https:… 4cf713… Victor… PRESENT\n 8     -38.4    146. NA                  Canis … https:… 8ef4ea… Museum… PRESENT\n 9     -38.1    142. 1886-01-23 00:00:00 Canis … https:… 7deaea… Victor… PRESENT\n10     -38.1    146. 1973-04-13 00:00:00 Canis … https:… 00a9e4… Austra… PRESENT\n# … with 12,129 more rows, and abbreviated variable names ¹​decimalLatitude,\n#   ²​decimalLongitude, ³​scientificName, ⁴​taxonConceptID, ⁵​recordID,\n#   ⁶​dataResourceName, ⁷​occurrenceStatus\n\n\n\n\nVisualise\nWe can create a bar plot and a map of observations to visualise our results.\nJust five data providers account for ~98% of dingo records, with Fauna Atlas N. T. contributing ~40% of records. All major data providers are government monitoring programs, rather than citizen science providers like iNaturalist.\n\n\nCode\ncustom_colours &lt;- c(\n  \"Museums Victoria provider for OZCAM\" = \"#604830\",\n  \"Victorian Biodiversity Atlas\" = \"#486030\",\n  \"Australian National Wildlife Collection provider for OZCAM\" = \"#6090d8\",\n  \"NSW BioNet Atlas\" = \"#604830\",\n  \"WildNet - Queensland Wildlife Data\" = \"#6fab3f\",\n  \"SA Fauna (BDBSA)\" = \"#d89060\",\n  \"Australian Museum provider for OZCAM\" = \"#FFC300\",\n  \"Fauna Atlas N.T.\" = \"#a84830\"\n)\n\n# Bar plot\ncounts_filtered |&gt;\n  ggplot(aes(\n    x = reorder(str_wrap(dataResourceName, 28), count),\n    y = count, fill = dataResourceName)) +\n  geom_bar(stat = \"identity\", width = .8) +\n  scale_fill_manual(values = custom_colours) +\n  scale_x_discrete(expand = c(0, 0)) +\n  scale_y_continuous(labels = scales::label_comma()) +\n  coord_flip() +\n  xlab(\"\") +\n  pilot::theme_pilot(grid = \"v\",\n                     axes = \"b\") +\n  theme(legend.position = \"none\",\n        axis.text = element_text(size = 12))\n# Map\naus &lt;- ozmap_data(data = \"states\")\n\nggplot() +\n  geom_sf(data = aus, fill = \"#FBFBEF\") +\n  geom_point(\n    data = points_filtered,\n    mapping = aes(\n      x = decimalLongitude,\n      y = decimalLatitude,\n      colour = dataResourceName),\n    alpha = 0.5) +\n  scale_color_manual(values = custom_colours) +\n  theme_void() +\n  coord_sf(\n    ylim = c(-45, -10),\n    xlim = c(110, 155)) +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "posts/2023-05-16_dingoes/post.html#time-of-year",
    "href": "posts/2023-05-16_dingoes/post.html#time-of-year",
    "title": "An exploration of dingo observations in the ALA",
    "section": "Time of year",
    "text": "Time of year\nNext, let’s investigate what months of the year have more dingo records. Viewing observations over time can show us patterns of when a species is most active. It can also reveal human biases in data collection. We’ll look specifically at observations in Northern Territory and South Australia because these states have the most data. Given the huge temperature gradient between the north and south of Australia, we might expect the timing of dingo observations to differ between NT and SA.\n\nDownload data\nFirst we’ll download observations by month in the Northern Territory by using the month field inside galah_group_by().\n\n# download data\ndingo_NT &lt;- galah_call() |&gt;\n  galah_identify(\"canis familiaris\") |&gt;\n  galah_filter(raw_vernacularName == c(\"Dingo\", \"dingo\"),\n               cl22 == \"Northern Territory\") |&gt;\n  galah_group_by(month) |&gt;\n  atlas_counts()\n\n\n\n# A tibble: 12 × 2\n   month count\n   &lt;chr&gt; &lt;int&gt;\n 1 6       909\n 2 7       818\n 3 8       771\n 4 9       596\n 5 5       543\n 6 10      526\n 7 4       485\n 8 3       416\n 9 11      368\n10 1       276\n11 2       220\n12 12      205\n\n\nWe’ll use the lubridate::month() function to convert the class of our month column from character to ordered factor.\n\n# format months for plotting\nmonth_NT &lt;- dingo_NT |&gt;\n  mutate(\n    month = month(as.numeric(month), label = TRUE) # format month\n    )\n\n\n\n# A tibble: 12 × 2\n   month count\n   &lt;ord&gt; &lt;int&gt;\n 1 Jun     909\n 2 Jul     818\n 3 Aug     771\n 4 Sep     596\n 5 May     543\n 6 Oct     526\n 7 Apr     485\n 8 Mar     416\n 9 Nov     368\n10 Jan     276\n11 Feb     220\n12 Dec     205\n\n\n\n\nMake bar plot\nNow we can make a bar chart to see observations over the year. We’ll do the same for South Australia, too.\nNorthern Territory’s dingo observations are recorded mainly over winter months (June–August). Alternatively, South Australia’s dingo observations are mainly recorded during autumn months (April–June).\n\n# plot\nbarplot_nt &lt;- ggplot(data = month_NT, \n                     aes(x = month, y = count)) +\n  geom_bar(stat = \"identity\", fill = \"#a84830\") +\n  labs(title = \"Northern Territory\", \n       x = \"Month\", \n       y = \"No. of observations\") +\n  scale_x_discrete(expand = c(0,0)) +\n  scale_y_continuous(limits = c(0, 1000),\n                     expand = c(0,0)) +\n  pilot::theme_pilot(grid = \"h\")\n\n\n\nCode\n# Northern Territory\nbarplot_nt\n## South Australia\n\n# download data\ndingo_SA &lt;- galah_call() |&gt;\n  galah_identify(\"canis familiaris\") |&gt;\n  galah_filter(raw_vernacularName == c(\"Dingo\", \"dingo\"),\n               cl22 == \"South Australia\") |&gt;\n  galah_group_by(month) |&gt;\n  atlas_counts() |&gt;\n  mutate(\n    month = month(as.numeric(month), label = TRUE) # format month\n    )\n\n# plot\nggplot(data = dingo_SA, \n       aes(x = month, y = count)) +\n  geom_bar(stat = \"identity\", fill = \"#d89060\") +\n  labs(title = \"South Australia\", \n       x = \"Month\", \n       y = \"No. of observations\") +\n  scale_x_discrete(expand = c(0,0)) +\n  scale_y_continuous(limits = c(0, 1000),\n                     expand = c(0,0)) +\n  pilot::theme_pilot(grid = \"h\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDoes this suggest dingoes are more active during winter, or are data collectors surveying during cooler times of the year? The answer might be “both”. One dingo tracking research study found that dingoes are far more active in winter, spending 46% of their day stationary in winter compared to 91% of their day in summer. Similarly, it’s easier for data collectors to survey during winter months when the heat is less extreme. Cooler winter temperatures might allow dingoes and surveyors to be more active, increasing the likelihood of incidental observations."
  },
  {
    "objectID": "posts/2023-05-16_dingoes/post.html#northern-territory",
    "href": "posts/2023-05-16_dingoes/post.html#northern-territory",
    "title": "An exploration of dingo observations in the ALA",
    "section": "Northern Territory",
    "text": "Northern Territory\n\nDownload CAPAD shapefile\nWe’ll first need the CAPAD shapefile. We can get it by downloading the CAPAD2020_terrestrial.zip folder from their website. Download and save this folder in your R Project or working directory and unzip it.\n\n# read in capad shapefile\ncapad &lt;- st_read(here(\"posts\",\n                      \"data\",\n                      \"CAPAD\",\n                      \"CAPAD2020_terrestrial.shp\"),\n                 quiet = TRUE) |&gt;\n  ms_simplify(keep = 0.1) |&gt;\n  st_transform(crs = st_crs(\"WGS84\")) |&gt;\n  st_make_valid()\n\nWe will filter our CAPAD layer to only the Northern Territory for our plot.\n\n# filter to NT\ncapad_nt &lt;- capad |&gt;\n  filter(STATE == \"NT\")\n\n\n\nDownload records\nNow we can download dingo observations in the Northern Territory (and remove any NAs with drop_na()).\n\n# download dingo observations in NT\ndingo_obs_nt &lt;- galah_call() |&gt;\n  galah_identify(\"canis familiaris\") |&gt;\n  galah_filter(raw_vernacularName == c(\"Dingo\", \"dingo\"),\n               cl22 == \"Northern Territory\") |&gt;\n  atlas_occurrences() |&gt;\n  drop_na() # filter any NA values out\n\n\n\n# A tibble: 6,133 × 8\n   decimal…¹ decim…² eventDate           scien…³ taxon…⁴ recor…⁵ dataR…⁶ occur…⁷\n       &lt;dbl&gt;   &lt;dbl&gt; &lt;dttm&gt;              &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  \n 1     -26.0    134. 1983-07-13 00:00:00 Canis … https:… 28343a… Fauna … PRESENT\n 2     -26.0    129. 1995-09-02 00:00:00 Canis … https:… d08326… SA Fau… PRESENT\n 3     -26.0    133. 2001-08-13 00:00:00 Canis … https:… de0ef0… Fauna … PRESENT\n 4     -26.0    129. 1995-09-02 00:00:00 Canis … https:… 54ab35… SA Fau… PRESENT\n 5     -26.0    133. 2001-08-07 00:00:00 Canis … https:… 3ffd21… Fauna … PRESENT\n 6     -26.0    133. 2001-08-13 00:00:00 Canis … https:… 4e02d3… Fauna … PRESENT\n 7     -26.0    133. 2001-08-07 00:00:00 Canis … https:… 85d44d… Fauna … PRESENT\n 8     -26.0    135. 1997-05-02 00:00:00 Canis … https:… 1736af… Fauna … PRESENT\n 9     -26.0    130. 1993-08-07 00:00:00 Canis … https:… 546762… Fauna … PRESENT\n10     -26.0    130. 1993-07-30 00:00:00 Canis … https:… 4a111e… Fauna … PRESENT\n# … with 6,123 more rows, and abbreviated variable names ¹​decimalLatitude,\n#   ²​decimalLongitude, ³​scientificName, ⁴​taxonConceptID, ⁵​recordID,\n#   ⁶​dataResourceName, ⁷​occurrenceStatus\n\n\n\n\nMake map\nWe’ll make our map of the Northern Territory by plotting each of our components and adding a colour scale to indicate places where there is more than one observation in a single point.\n\n# make map\nnt_plot &lt;- ggplot() +\n  geom_sf(data = ozmap_states |&gt; filter(NAME == \"Northern Territory\"), \n          fill = \"#F8FBEF\", \n          colour = \"grey60\", \n          linewidth = 0.3) +\n  geom_pointdensity(data = dingo_obs_nt,\n                    mapping = aes(x = decimalLongitude,\n                                  y = decimalLatitude),\n                    size = 2.4, \n                    alpha = 0.6) +\n  geom_sf(data = capad_nt, \n          fill = \"#1F901F\", \n          colour = \"#1F901F\", \n          linewidth = 0.5, \n          alpha = 0.2, \n          linetype = \"dashed\") +\n  scale_color_viridis(option = \"D\", \n                      direction = -1,\n                      begin = 0.0,\n                      end = 0.4,\n                      guide = guide_colorbar(title = (\"Number of overlapping observations\"),\n                                     title.position = \"top\",\n                                     title.hjust = 0.5)) +\n  theme_void() +\n  theme(legend.position = \"bottom\",\n        legend.title = element_text(face = \"bold\"),\n        legend.key.width = unit(15, 'mm'),\n        plot.margin = unit(c(1,0,1,0),\"cm\"))\n\n\n\nAdd coloured title\nFinally, we can avoid adding more than one legend by using colour in our title to specify the colour of protected areas and dingo observations on our map (using a clever method by Cara Thompson). We’ll need to use ggnewscale::new_scale_color() to add our custom colour palette for our text because we are already using another colour palette for our observation points (you can check out our previous post on using {ggnewscale} to learn more).\n\n# create palette for title\ndingo_palette &lt;- list(\"protected\" = \"#1F901F\",\n                      \"obs\" = \"#404788\")\n\nnt_plot +\n  ggnewscale::new_scale_color() +\n  scale_colour_manual(values = dingo_palette) +\n  labs(\n    title = glue(\n      \"&lt;span style='color:{dingo_palette$obs}'&gt;Dingo observations&lt;/span&gt; in \n      &lt;span style='color:{dingo_palette$protected}'&gt;**protected areas**&lt;/span&gt;\"),\n    subtitle = \"Northern Territory\") +\n  theme(plot.title = element_markdown(face = \"bold\", size = 16, hjust = 0.5),\n        plot.subtitle = element_markdown(hjust = 0.5, size = 15))\n\n\n\n\n\n\n\n\n\n\nCalculate proportion inside protected areas\nBy comparing the number of records in CAPAD areas to the total observations in Northern Territory, we find that more than half of all dingo observations are recorded inside of protected areas.\n\n\n\n\n\n\nTip\n\n\n\nSearching for CAPAD fields in {galah} shows us that {galah} has the CAPAD 2020 layer available for us to use in a query.\n\nsearch_all(fields, \"capad\") |&gt; print(n = 2)\n\n# A tibble: 5 × 4\n  id      description                                                type  link \n  &lt;chr&gt;   &lt;chr&gt;                                                      &lt;chr&gt; &lt;chr&gt;\n1 cl2109  \"Bush Heritage Reserves April 2015 Bush Heritage Reserves… laye… http…\n2 cl11033 \"CAPAD 2020 Terrestrial The Collaborative Australian Prot… laye… http…\n# … with 3 more rows\n\n\nWe can return the number of dingo observations in each CAPAD area by using galah_group_by(cl11033) in our query. Adding the observation counts together will give us the total observations in CAPAD areas.\n\n\n\n# Download dingo record counts inside CAPAD areas\ndingo_capad_nt &lt;- galah_call() |&gt;\n  galah_identify(\"canis familiaris\") |&gt;\n  galah_filter(raw_vernacularName == c(\"Dingo\", \"dingo\"),\n               cl22 == \"Northern Territory\") |&gt;\n  galah_group_by(cl11033) |&gt; # capad\n  atlas_counts() |&gt;\n  drop_na() # filter any NA values out\n\n# Proportion inside vs outside of protected areas\nin_protected &lt;- dingo_capad_nt|&gt; summarise(total = sum(count))\nout_of_protected &lt;- nrow(dingo_obs_nt)\n\npaste(round(in_protected / out_of_protected * 100, 2), \"%\", sep = \"\")\n\n[1] \"57.39%\""
  },
  {
    "objectID": "posts/2023-05-16_dingoes/post.html#south-australia",
    "href": "posts/2023-05-16_dingoes/post.html#south-australia",
    "title": "An exploration of dingo observations in the ALA",
    "section": "South Australia",
    "text": "South Australia\nLet’s do the same as above to make a map of South Australia.\nWe’ll also include a map of where the Dog Fence is within South Australia to compare observations on either side of the fence. We obtained a shapefile of the Dog Fence by contacting the Department of Primary Industries and Regions.\n\ndog_fence &lt;- st_read(here(\"posts\",\n                          \"data\",                    \n                          \"Dog Fence\",\n                          \"Dog_Fence.shp\"),\n                     quiet = TRUE) |&gt;\n  ms_simplify(keep = 0.1) |&gt;\n  st_transform(crs = st_crs(\"WGS84\")) |&gt;\n  st_make_valid()\n\nThe Dog Fence is labelled in our map below. There are noticeably fewer observations recorded of dingoes on the southern side of the fence, and those that are recorded appear to be mostly inside protected areas.\n\n\nCode\n# filter to SA\ncapad_sa &lt;- capad |&gt;\n  filter(STATE == \"SA\")\n\n# download dingo observations in SA\ndingo_obs_sa &lt;- galah_call() |&gt;\n  galah_identify(\"canis familiaris\") |&gt;\n  galah_filter(raw_vernacularName == c(\"Dingo\", \"dingo\"),\n               cl22 == \"South Australia\") |&gt;\n  atlas_occurrences() |&gt;\n  drop_na() # filter any NA values out\n\n# Start and end points of arrow\narrow &lt;- \n  tibble(\n    x1 = c(132.4),\n    x2 = c(134),\n    y1 = c(-34),\n    y2 = c(-32.2))\n\n# make map\nsa_plot &lt;- ggplot() +\n  geom_sf(data = ozmap_states |&gt; filter(NAME == \"South Australia\"), \n          fill = \"#F8FBEF\", \n          colour = \"grey60\", \n          linewidth = 0.5) +\n  geom_pointdensity(data = dingo_obs_sa,\n                    mapping = aes(x = decimalLongitude,\n                                  y = decimalLatitude),\n                    size = 2.4, \n                    alpha = 0.6) +\n  geom_sf(data = capad_sa, \n          fill = \"#1F901F\", \n          colour = \"#1F901F\", \n          linewidth = 0.5, \n          alpha = 0.2, \n          linetype = \"dashed\") +\n  geom_sf(data = dog_fence, color = \"#F0A202\", linewidth = 1.8) +\n  geom_curve(\n    data = arrow, aes(x = x1, y = y1, xend = x2, yend = y2),\n    arrow = arrow(length = unit(0.08, \"inch\")),\n    colour = \"#392704\",\n    linewidth = 1.5,\n    curvature = 0.3) +\n  annotate(\"text\", x = 130.9, y = -34, label = \"Dog Fence\", size = 5.5, colour = \"#EFA81A\") +\n  scale_color_viridis(option = \"D\", \n                      direction = -1,\n                      begin = 0.0,\n                      end = 0.4,\n                      guide = guide_colorbar(title = (\"Number of overlapping observations\"),\n                                     title.position = \"top\",\n                                     title.hjust = 0.5)) +\n  theme_void() +\n  theme(legend.position = \"bottom\",\n        legend.title = element_text(face = \"bold\"),\n        legend.key.width = unit(15, 'mm'),\n        plot.margin = unit(c(1,0,1,0),\"cm\"))\n\n# add title\nsa_plot +\n  ggnewscale::new_scale_color() +\n  scale_colour_manual(values = dingo_palette) +\n  labs(\n    title = glue(\n      \"&lt;span style='color:{dingo_palette$obs}'&gt;Dingo observations&lt;/span&gt; in \n      &lt;span style='color:{dingo_palette$protected}'&gt;**protected areas**&lt;/span&gt;\"),\n    subtitle = \"South Australia\") +\n  theme(plot.title = element_markdown(face = \"bold\", size = 16, hjust = 0.5),\n        plot.subtitle = element_markdown(hjust = 0.5, size = 15))\n\n\n\n\n\n\n\n\n\nBy comparing the number of records in CAPAD areas to the total observations in South Australia, we find that around 4 in 10 dingo observations are recorded inside of protected areas.\n\n\nCode\n# Download dingo record counts inside CAPAD areas\ndingo_capad_sa &lt;- galah_call() |&gt;\n  galah_identify(\"canis familiaris\") |&gt;\n  galah_filter(raw_vernacularName == c(\"Dingo\", \"dingo\"),\n               cl22 == \"South Australia\") |&gt;\n  galah_group_by(cl11033) |&gt; # capad\n  atlas_counts() |&gt;\n  drop_na() # filter any NA values out\n\n# Proportion inside vs outside of protected areas\nin_protected &lt;- dingo_capad_sa |&gt; summarise(total = sum(count))\nout_of_protected &lt;- nrow(dingo_obs_sa)\n\npaste(round(in_protected / out_of_protected * 100, 2), \"%\", sep = \"\")\n\n\n[1] \"39.14%\"\n\n\nOverall, in the Northern Territory and South Australia, the number of dingo observations is fairly comparable between between those made inside and outside of nationally protected areas. We also saw how few observations are on the southern side of the Dog Fence in South Australia."
  },
  {
    "objectID": "posts/2023-05-16_dingoes/post.html#footnotes",
    "href": "posts/2023-05-16_dingoes/post.html#footnotes",
    "title": "An exploration of dingo observations in the ALA",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSome research suggests dingoes might not always benefit mammal species richness.↩︎\nHowever, all wild dogs in Australia possess some percentage of dingo genes.↩︎\nIn South Australia, inside the Dog Fence landholders have a legal responsibility to control wild dogs—including dingoes—on their properties, whereas outside of the Dog Fence dingoes are listed as unprotected native wildlife.↩︎"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n\n\n\n\n  \n\n\n\n\nAn exploration of dingo observations in the ALA\n\n\n\n\n\nDingoes are the subject of ongoing debate about whether they should be considered a protected species or a pest species. Here we explore dingo observations in the ALA to understand how differing attitudes affect dingo data, plotting spatial and temporal trends using {ggplot2}.\n\n\n\n\n\n\nMay 16, 2023\n\n\nAmos Smith, Dax Kellie\n\n\n23 min\n\n\n\n\n\n\n  \n\n\n\n\nPlotting invasive species distributions with alpha shapes and choropleth maps in Python\n\n\n\n\n\nInvasive and introduced species can expand quickly into new habitats, altering ecosystems. In this post we use Python’s {galah}, {alphashape} and {GeoPandas} packages to visualise the growing distribution of Rhinella marina (cane toads) and the expanding range of Pittisporum undulatum in Australia.\n\n\n\n\n\n\nApr 28, 2023\n\n\nCaitlin Ramsay, Amanda Buyan, Dax Kellie\n\n\n13 min\n\n\n\n\n\n\n  \n\n\n\n\nQuantifying species range and overlap with fire-burned areas using concave hulls\n\n\n\n\n\nCalculating range overlap is an efficient way to estimate the impact of natural disasters on biodiversity. Here we’ll use curated datasets to compute concave hulls to visualise the spatial distribution of Apidae (Bees) and Daviesia (Bitterpeas) and their overlap with burned areas of the Black Summer fires of 2019-2020.\n\n\n\n\n\n\nApr 11, 2023\n\n\nFonti Kar, Margot Schneider\n\n\n25 min\n\n\n\n\n\n\n  \n\n\n\n\nMake a highlighted time-series plot\n\n\n\n\n\nTime-series analyses can be handy for seeing trends over time, and exploring how trends relate to major events. Here, we show how to create an exploratory time-series plot comparing observations of waterbirds prior to and during the COVID-19 pandemic.\n\n\n\n\n\n\nApr 3, 2023\n\n\nThai Rushbrook, Olivia Torresan, Dax Kellie\n\n\n14 min\n\n\n\n\n\n\n  \n\n\n\n\nAnimated species distribution maps with {gifski}\n\n\n\n\n\nOne useful way to see changes in a species’ habitat range over time is by using animation to view multiple distributions in succession. Here we will model the distribution of Nudibranchia across Australia each month to create an animated GIF of its distribution over a year.\n\n\n\n\n\n\nMar 14, 2023\n\n\nStephanie Woolley, Olivia Torresan, Dax Kellie\n\n\n20 min\n\n\n\n\n\n\n  \n\n\n\n\nCounting points in multipolygon shapefiles for choropleth mapping\n\n\n\n\n\nChoropleth maps are an excellent way to visualise numbers of observations, but when using point data, calculating the number of points in each polygon can be difficult when using shapefiles. Here we demonstrate how to extract and summarise the number of points in each polygon to create a choropleth map.\n\n\n\n\n\n\nFeb 6, 2023\n\n\nOlivia Torresan, Dax Kellie\n\n\n10 min\n\n\n\n\n\n\n  \n\n\n\n\nConvex and alpha hulls for conservation mapping\n\n\n\n\n\nConvex hulls and alpha hulls are wonderful alternatives for visualising species distributions when a species has very few existing observations. Here, we will show you how to create these spatial polygons using data from the ALA.\n\n\n\n\n\n\nOct 20, 2022\n\n\nMargot Schneider, Fonti Kar\n\n\n15 min\n\n\n\n\n\n\n  \n\n\n\n\nQuantify geographic sampling bias with {sampbias}\n\n\n\n\n\nHuman biases play a large role in the data we collect about species. Here we show a simple method to quantify the bias of roads, cities, rivers and airports on species observations of legless lizards in the Northern Territory\n\n\n\n\n\n\nAug 8, 2022\n\n\nDax Kellie\n\n\n11 min\n\n\n\n\n\n\n  \n\n\n\n\nMultiple colour scales in choropleth maps with {ggnewscale}\n\n\n\n\n\nUsing multiple colour scales can be a great way to visually differentiate between geographic categories on a map. Here, we demonstrate this by creating a choropleth map to represent the density of plant records from the ALA across bioregions in Australia, and add multiple colour scales to differentiate marine and terrestrial records\n\n\n\n\n\n\nMay 31, 2022\n\n\nShandiya Balasubramaniam\n\n\n10 min\n\n\n\n\n\n\n  \n\n\n\n\nDownload plant species data by hexagon to make a 3D hex map\n\n\n\n\n\nMaking plots eye-catching can be useful for science communication. Here, we show how to make 3D plots in R with the rayshader package by visualising the number of species identified from ALA observations since 2020\n\n\n\n\n\n\nMay 23, 2022\n\n\nDax Kellie\n\n\n12 min\n\n\n\n\n\n\n  \n\n\n\n\nSunburst plots for taxonomic data\n\n\n\n\n\nSince version 1.3.1 of {galah}, it has been possible to download taxonomic data using a ‘tree’ format from the {data.tree} package. Here I’ll demonstrate some ideas for plotting these trees using circular diagrams.\n\n\n\n\n\n\nFeb 17, 2022\n\n\nMartin Westgate\n\n\n8 min\n\n\n\n\n\n\n  \n\n\n\n\nHex maps for species occurrence data\n\n\n\n\n\nThere are hundreds of color palettes in the R ecosystem, but sometimes we might want to use colors from a specific image. Here I show how to use the paletter package to create a color palette for the 2020 Eucalypt of the Year: the Western Australian Gimlet.\n\n\n\n\n\n\nMar 1, 2021\n\n\nMatilda Stevenson, Dax Kellie, Martin Westgate\n\n\n8 min\n\n\n\n\n\n\n  \n\n\n\n\nCreating a color palette from an image\n\n\n\n\n\nThere are hundreds of color palettes in the R ecosystem, but sometimes we might want to use colors from a specific image. Here I show how to use the paletter package to create a color palette for the 2020 Eucalypt of the Year: the Western Australian Gimlet.\n\n\n\n\n\n\nJan 3, 2021\n\n\nMartin Westgate\n\n\n5 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "research/highlights/2023-03-21_peanuts/paper.html",
    "href": "research/highlights/2023-03-21_peanuts/paper.html",
    "title": "Changing farming climates: the future of growing peanuts",
    "section": "",
    "text": "Arachis hypogaea L. (Fagg, M. CC BY 3.0)\n\n\nCitation\n\n\nH Haerani, A Apan, T Nguyen-Huy & B Basnet (2023) Modelling future spatial distribution of peanut crops in Australia under climate change scenarios. Geospatial Information Science https:://doi.org/10.1080/10095020.2022.2155255\n\n\n\nPage info\nPrepared by Olivia Torresan, Margot Schneider\n\n\n\n\n\nPeanuts are one of the richest sources of dietary protein - topping meat, dairy, eggs, and fish. They are also non-perishable, able to be used by global aid industries in the fight against famine and crisis food shortages. Ensuring we have a ready supply of plant-based protein like peanuts is important. Both agriculturalists and top export regions are likely to bear the brunt of holding a steady supply.\nUsing nearly 2,000 geographical occurrence data points from the Atlas of Living Australia (ALA) and the Global Biodiversity Information Facility (GBIF) alongside modelled climate change scenarios, Haerani et al. (2023) infer a global distribution of peanut crops under a changing climate.\nThey find that in the next century, suitable peanut growing regions are set to shrink substantially along the east and west coast, with northern New South Wales and south-east Queensland at the greatest loss by the year 2100."
  },
  {
    "objectID": "research/highlights/2023-05-10_koalas/paper.html",
    "href": "research/highlights/2023-05-10_koalas/paper.html",
    "title": "Rapid loss of genetic diversity in Koalas from urbanisation",
    "section": "",
    "text": "Phascolarctos cinereus (Nathaniel Xggum CC BY NC 3.0)\n\n\nCitation\n\n\nHohwieler Katrin R., de Villiers Deidre L., Cristescu Romane, Celine H. Frere (2023) Genetic erosion detected in a specialist mammal living in a fast-developing environment. Conservation Science and Practice https:://doi.org/10.1111/csp2.12738\n\n\n\nPage info\nPrepared by Olivia Torresan, Margot Schneider\n\n\n\n\n\nHabitat fragmentation—when a large habitat is divided into smaller isolated patches of habitat—is a major threat to species survival. Usually caused by habitat destruction, habitat fragmentation can separate populations from the larger group of individuals.\nCompared to larger populations, fragmented populations are more likely to inbreed, reducing their genetic diversity. Genetic diversity is important for species. It improves their resilience to disease and their ability to adapt to changing environmental conditions. Without detection or management, fragmentation heightens species extinction risk.\nWith the help of ALA data, Hohwieler and others (2022) assessed the genetic diversity of a Queensland koala population by comparing physical samples (ear biopsy specimens and scats) between two generations (2006 vs. 2018).\nThe authors found a decline in diversity that correlated with accelerating urbanisation, traffic increases and habitat loss. Supported by this evidence, the authors call for stronger requirements of genetic diversity guidelines when determining species’ and ecosystems’ critical status by the International Union for Conservation (IUCN)."
  },
  {
    "objectID": "research/highlights/2023-05-15_JEV/paper.html",
    "href": "research/highlights/2023-05-15_JEV/paper.html",
    "title": "Mapping transmission risk: Japanese Encephalitis Virus",
    "section": "",
    "text": "Culex (Culex) sitiens (Nick Lambert CC BY NC SA 3.0)\n\n\nCitation\n\n\nFurlong, M., Adamu, A. M., Hoskins, A., Russell, T. L., Gummow, B., Golchin, M., Hickson, R. I., & Horwood, P. F. (2023) Japanese Encephalitis Enzootic and Epidemic Risks across Australia. Viruses https://doi.org/10.3390/v15020450\n\n\n\nPage info\nPrepared by Olivia Torresan, Margot Schneider\n\n\n\n\n\nJapanese encephalitis virus is a blood-borne virus spread via mosquitos. It is often considered a rural disease, present in an animal populations and able to infect humans that interact closely animal hosts of the virus (often pigs and waterbirds). Urbanisation and agricultural production increase the risk that humans contract the virus.\nUntil recently Japanese encephalitis was thought to be geographically restricted to Northern Australia, but in 2022, it was found across all the eastern states of Australia and declared nationally significant.\nFurlong and others (2023) used ALA data to obtain occurrence records of both mosquitos and waterbirds. Using ecological niche models, they found the highest risk of human exposure to the virus in coastal Australia—sprawling across the Great Dividing Range and the Murray-Darling Basin. The authors predict that Japanese encephalitis will establish an endemic circulation in Australia, increasing risks to human health."
  },
  {
    "objectID": "research/highlights/2023-05-15_microfossils/paper.html",
    "href": "research/highlights/2023-05-15_microfossils/paper.html",
    "title": "Citizen scientists uncover environmental history with pollen & spore fossils",
    "section": "",
    "text": "Araucaria bidwillii (Michael Hains CC BY 3.0)\n\n\nCitation\n\n\nDjokic, T., Frese, M., Woods, A., Dettmann, M., Flemons, P., Brink, F., & McCurry, M. R. (2023) Inferring the age and environmental characteristics of fossil sites using citizen science. PLOS ONE https://doi.org/10.1371/journal.pone.0284388\n\n\n\nPage info\nPrepared by Olivia Torresan, Margot Schneider\n\n\n\n\n\nMicrofossils are the fossilized remains of bacteria, protists, fungi, animals and plants. The most common way to extract and analyse microfossils is by using a compatible acid to dissolve the rock they are preserved in while leaving the fossil intact. In some cases, though, this method does not work. If the rock matrix and the fossils are too compositionally similar, for instance, the choice of acid can degrade the fossil or reduce its quality.\nFaced with this problem, Djokic and others (2023) used citizen science to analyse images of pollen and spore microfossils from McGrath’s Flat near Gulgong in the Central Tablelands (NSW). Analysing images of microfossils is an incredibly time and resource-consuming feat. A professional scientist usually needs around 6 hours to locate and image 50 microfossils (not including analysis or identification).\nUsing images hosted by Atlas of Living Australia’s online volunteering platform DigiVol, 250 citizen scientists analysed 25,000+ images at three times this pace (!), successfully identifying 300 pollen and spores from the Miocene age (11–20 million-years-ago). The authors hope to encourage other researchers to use the power of citizen science for fossil identification."
  },
  {
    "objectID": "research/highlights.html",
    "href": "research/highlights.html",
    "title": "Research highlights",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "software/software.html",
    "href": "software/software.html",
    "title": "Software",
    "section": "",
    "text": "galah\n{galah} is an R and Python interface to biodiversity data hosted by the Atlas of Living Australia (ALA). It enables users to locate and download species occurrence records (observations, specimens, eDNA records, etc.), taxonomic information, or associated media such as images or sounds, and to restrict their queries to particular taxa or locations.  Visit the {galah} website to learn more about how to use {galah} If you have any questions, comments, or spot any bugs, email us or report an issue on our GitHub page\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npotions\n{potions} makes options management in R—usually edited using base::options() and related functions—as easy as possible. It uses a minimalist workflow to store and retrieve information with three core functions: brew(), pour() and drain().  Visit the {potions} website to learn more about how to use {potions} If you have any questions, comments, or spot any bugs, email us or report an issue on our GitHub page"
  }
]